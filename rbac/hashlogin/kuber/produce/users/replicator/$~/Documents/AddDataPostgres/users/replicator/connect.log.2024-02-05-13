[2024-02-05 13:03:05,425] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1090)
[2024-02-05 13:03:10,336] INFO [Producer clientId=connect-cluster--offsets] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1090)
[2024-02-05 13:03:24,977] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1090)
[2024-02-05 13:03:30,085] INFO [Producer clientId=connect-cluster--statuses] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1090)
[2024-02-05 13:03:40,920] INFO [Consumer clientId=connect-cluster--configs, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1090)
[2024-02-05 13:03:42,792] INFO [Producer clientId=connect-cluster--configs] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1090)
[2024-02-05 13:03:52,334] INFO [Worker clientId=connect-1, groupId=connect-cluster] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1090)
[2024-02-05 13:03:55,655] INFO [AdminClient clientId=connect-cluster--shared-admin] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient:1090)
[2024-02-05 13:03:55,657] INFO [AdminClient clientId=connect-cluster--shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1090)
[2024-02-05 13:03:56,116] INFO [AdminClient clientId=connect-cluster--shared-admin] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient:1090)
[2024-02-05 13:04:37,177] INFO [AdminClient clientId=connect-cluster--shared-admin] Node 11 disconnected. (org.apache.kafka.clients.NetworkClient:1090)
[2024-02-05 13:04:37,178] INFO [AdminClient clientId=connect-cluster--shared-admin] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient:1090)
[2024-02-05 13:04:37,179] INFO [AdminClient clientId=connect-cluster--shared-admin] Node 6 disconnected. (org.apache.kafka.clients.NetworkClient:1090)
[2024-02-05 13:04:37,184] INFO [AdminClient clientId=connect-cluster--shared-admin] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient:1090)
[2024-02-05 13:04:37,185] INFO [AdminClient clientId=connect-cluster--shared-admin] Node 8 disconnected. (org.apache.kafka.clients.NetworkClient:1090)
[2024-02-05 13:04:37,186] INFO [AdminClient clientId=connect-cluster--shared-admin] Node 10 disconnected. (org.apache.kafka.clients.NetworkClient:1090)
[2024-02-05 13:04:37,398] INFO [AdminClient clientId=connect-cluster--shared-admin] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient:1090)
[2024-02-05 13:08:55,189] INFO [AdminClient clientId=connect-cluster--shared-admin] Node 9 disconnected. (org.apache.kafka.clients.NetworkClient:1090)
[2024-02-05 13:13:55,780] INFO [AdminClient clientId=connect-cluster--shared-admin] Node 7 disconnected. (org.apache.kafka.clients.NetworkClient:1090)
[2024-02-05 13:18:59,049] INFO [AdminClient clientId=connect-cluster--shared-admin] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient:1090)
[2024-02-05 13:24:03,219] INFO [AdminClient clientId=connect-cluster--shared-admin] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:1090)
[2024-02-05 13:29:07,966] INFO [AdminClient clientId=connect-cluster--shared-admin] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient:1090)
[2024-02-05 13:34:12,853] INFO [AdminClient clientId=connect-cluster--shared-admin] Node 6 disconnected. (org.apache.kafka.clients.NetworkClient:1090)
[2024-02-05 13:35:18,908] INFO [Worker clientId=connect-1, groupId=connect-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2284)
[2024-02-05 13:42:52,460] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2024-02-05 13:42:52,466] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:369)
[2024-02-05 13:42:52,478] INFO Stopped http_8083@4def42c3{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:383)
[2024-02-05 13:42:52,479] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:149)
[2024-02-05 13:42:52,494] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:386)
[2024-02-05 13:42:52,494] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder stopping (org.apache.kafka.connect.runtime.distributed.DistributedHerder:804)
[2024-02-05 13:42:52,495] INFO [Worker clientId=connect-1, groupId=connect-cluster] Stopping connectors and tasks that are still assigned to this worker. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:767)
[2024-02-05 13:42:52,498] INFO [Worker clientId=connect-1, groupId=connect-cluster] Member connect-1-8b050ce8-ac93-41e2-81af-9e740fc79ac4 sending LeaveGroup request to coordinator b6-pkc-4r087.us-west2.gcp.confluent.cloud:9092 (id: 2147483641 rack: null) due to the consumer is being closed (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1133)
[2024-02-05 13:42:52,499] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1025)
[2024-02-05 13:42:52,501] WARN [Worker clientId=connect-1, groupId=connect-cluster] Close timed out with 1 pending requests to coordinator, terminating client connections (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1110)
[2024-02-05 13:42:52,502] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:42:52,502] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:42:52,503] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:42:52,510] INFO App info kafka.connect for connect-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:42:52,511] INFO Stopping KafkaBasedLog for topic connect-statuses (org.apache.kafka.connect.util.KafkaBasedLog:343)
[2024-02-05 13:42:52,511] INFO [Producer clientId=connect-cluster--statuses] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1311)
[2024-02-05 13:42:52,514] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:42:52,515] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:42:52,515] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:42:52,515] INFO App info kafka.producer for connect-cluster--statuses unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:42:52,518] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1025)
[2024-02-05 13:42:52,518] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1072)
[2024-02-05 13:42:52,836] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:42:52,837] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:42:52,837] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:42:52,850] INFO App info kafka.consumer for connect-cluster--statuses unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:42:52,851] INFO Stopped KafkaBasedLog for topic connect-statuses (org.apache.kafka.connect.util.KafkaBasedLog:375)
[2024-02-05 13:42:52,851] INFO Closing KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:399)
[2024-02-05 13:42:52,852] INFO Stopping KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:343)
[2024-02-05 13:42:52,854] INFO [Producer clientId=connect-cluster--configs] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1311)
[2024-02-05 13:42:52,866] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:42:52,867] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:42:52,871] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:42:52,879] INFO App info kafka.producer for connect-cluster--configs unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:42:52,881] INFO [Consumer clientId=connect-cluster--configs, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1025)
[2024-02-05 13:42:52,882] INFO [Consumer clientId=connect-cluster--configs, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1072)
[2024-02-05 13:42:53,894] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:42:53,895] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:42:53,896] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:42:53,898] INFO App info kafka.consumer for connect-cluster--configs unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:42:53,898] INFO Stopped KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:375)
[2024-02-05 13:42:53,898] INFO Closed KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:412)
[2024-02-05 13:42:53,898] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:289)
[2024-02-05 13:42:53,899] INFO Stopping KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:295)
[2024-02-05 13:42:53,899] INFO Stopping KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:343)
[2024-02-05 13:42:53,900] INFO [Producer clientId=connect-cluster--offsets] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1311)
[2024-02-05 13:42:53,902] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:42:53,902] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:42:53,902] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:42:53,903] INFO App info kafka.producer for connect-cluster--offsets unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:42:53,903] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1025)
[2024-02-05 13:42:53,903] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1072)
[2024-02-05 13:42:55,687] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:42:55,688] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:42:55,689] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:42:55,704] INFO App info kafka.consumer for connect-cluster--offsets unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:42:55,704] INFO Stopped KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:375)
[2024-02-05 13:42:55,705] INFO Stopped KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:303)
[2024-02-05 13:42:55,706] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:42:55,706] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:42:55,707] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:42:55,709] INFO App info kafka.connect for 127.0.1.1:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:42:55,710] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:312)
[2024-02-05 13:42:55,721] INFO [AdminClient clientId=connect-cluster--shared-admin] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient:1090)
[2024-02-05 13:42:55,723] INFO App info kafka.admin.client for connect-cluster--shared-admin unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:42:55,733] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:42:55,734] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:42:55,734] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:42:55,734] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:374)
[2024-02-05 13:42:55,735] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:824)
[2024-02-05 13:42:55,736] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
[2024-02-05 13:43:00,797] INFO Kafka Connect worker initializing ... (org.apache.kafka.connect.cli.AbstractConnectCli:121)
[2024-02-05 13:43:00,812] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=/home/sumo/Downloads/confluent-7.5.3/bin/../logs, -Dlog4j.configuration=file:/etc/kafka/connect-log4j.properties, -Dlog4j.config.dir=/etc/kafka
	jvm.spec = Ubuntu, OpenJDK 64-Bit Server VM, 11.0.21, 11.0.21+9-post-Ubuntu-0ubuntu120.04
	jvm.classpath = /home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jackson-datatype-jsr310-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/aws-java-sdk-kms-1.12.268.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/javax-websocket-server-impl-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/websocket-client-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jboss-logging-3.3.2.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/pcollections-4.0.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/netty-transport-native-unix-common-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jackson-dataformat-properties-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/paranamer-2.8.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/netty-tcnative-boringssl-static-2.0.61.Final-osx-x86_64.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/audience-annotations-0.12.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jetty-servlets-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jackson-module-jaxb-annotations-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jetty-plus-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/kotlin-stdlib-common-1.8.20.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/netty-handler-proxy-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/failureaccess-1.0.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/kafka-client-plugins-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jakarta.el-3.0.4.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/logredactor-metrics-1.0.12.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/netty-codec-http2-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/google-http-client-apache-v2-1.41.7.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/events-schema-0.187.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/http2-server-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/snakeyaml-2.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/proto-google-common-protos-2.22.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/netty-tcnative-boringssl-static-2.0.61.Final-osx-aarch_64.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/hibernate-validator-6.1.7.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/kafka-protobuf-types-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jackson-dataformat-csv-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/websocket-api-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/netty-transport-native-epoll-4.1.100.Final-linux-x86_64.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jetty-util-ajax-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/netty-codec-redis-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/opencensus-api-0.31.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/netty-transport-rxtx-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/aws-java-sdk-sts-1.12.268.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/ion-java-1.0.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jackson-module-scala_2.13-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/kotlin-scripting-compiler-embeddable-1.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/javax.servlet-api-4.0.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/api-asn1-ber-2.1.4.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jakarta.validation-api-2.0.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/kotlin-reflect-1.8.21.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/kafka-protobuf-provider-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/common-config-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/google-http-client-jackson2-1.41.7.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/kafka-connect-avro-data-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/re2j-1.6.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jetty-server-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/api-util-2.1.4.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/kotlin-stdlib-jdk7-1.8.20.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/netty-transport-sctp-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/kafka_2.13-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/aws-java-sdk-core-1.12.268.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/zookeeper-jute-3.8.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/classmate-1.3.4.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/commons-validator-1.7.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/netty-all-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jetty-servlet-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/zookeeper-3.8.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/kafka-metadata-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/netty-codec-stomp-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/wire-schema-jvm-4.8.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/cel-core-0.3.5.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jersey-server-2.36.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/proto-google-iam-v1-1.3.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/kotlin-script-runtime-1.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jackson-jaxrs-base-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/netty-resolver-dns-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/javax.ws.rs-api-2.1.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jakarta.activation-api-1.2.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/annotations-13.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/netty-resolver-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/kotlin-scripting-compiler-impl-embeddable-1.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/google-api-client-1.34.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/protobuf-java-util-3.19.6.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/google-api-services-cloudkms-v1-rev108-1.25.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/google-http-client-appengine-1.41.7.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jackson-datatype-jdk8-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/netty-tcnative-boringssl-static-2.0.61.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/authorizer-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/aws-java-sdk-s3-1.12.268.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/avro-1.11.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/http2-common-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/google-http-client-1.41.7.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/kafka-schema-serializer-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/netty-resolver-dns-native-macos-4.1.100.Final-osx-x86_64.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/commons-collections4-4.4.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/wire-runtime-jvm-4.8.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/bc-fips-1.0.2.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/kotlin-stdlib-1.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jersey-bean-validation-2.36.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/netty-transport-native-kqueue-4.1.100.Final-osx-aarch_64.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/netty-codec-dns-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jersey-container-servlet-2.36.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/confluent-connect-secret-registry-plugin-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/kafka-secret-registry-client-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/kafka-protobuf-serializer-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/netty-codec-mqtt-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/api-asn1-api-2.1.4.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/everit-json-schema-1.14.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/netty-transport-native-epoll-4.1.100.Final-linux-aarch_64.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jersey-client-2.36.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jetty-webapp-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/google-auth-library-credentials-1.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/javax.websocket-api-1.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/mbknor-jackson-jsonschema_2.13-1.0.39.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/netty-buffer-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/netty-transport-classes-kqueue-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/confluent-licensing-new-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jackson-dataformat-yaml-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/error_prone_annotations-2.18.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/javax.websocket-client-api-1.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/gson-2.9.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/httpclient-4.5.13.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/auto-value-annotations-1.9.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/auto-service-annotations-1.0-rc7.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jetty-annotations-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/json-20231013.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/kafka-replication-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/scala-reflect-2.13.10.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/metrics-core-2.2.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/netty-transport-native-kqueue-4.1.100.Final-osx-x86_64.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jetty-io-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/okio-jvm-3.4.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/netty-transport-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/netty-tcnative-boringssl-static-2.0.61.Final-linux-x86_64.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/netty-common-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/kafka-avro-serializer-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/bctls-fips-1.0.13.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/api-i18n-2.1.4.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/bcpkix-fips-1.0.6.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/broker-plugins-7.5.3-ce-test.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/hk2-api-2.6.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jackson-module-parameter-names-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/netty-handler-ssl-ocsp-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/google-cloud-storage-2.6.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/opencensus-contrib-http-util-0.31.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/netty-codec-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/swagger-annotations-2.1.10.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/websocket-servlet-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jetty-security-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jose4j-0.9.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/json-smart-2.4.10.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/httpcore-4.4.13.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/websocket-common-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/threetenbp-1.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/cel-generated-antlr-0.3.5.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/kotlin-stdlib-jdk8-1.8.20.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/kafka-secret-registry-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/handy-uri-templates-2.1.8.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/commons-logging-1.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/scala-logging_2.13-3.9.4.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/kafka-schema-converter-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/auto-service-1.0-rc7.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/kafka-group-coordinator-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/scala-java8-compat_2.13-1.0.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/google-oauth-client-1.33.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/security-extensions-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/commons-cli-1.4.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/rest-utils-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/netty-codec-smtp-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/netty-codec-memcache-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/validation-api-2.0.1.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/netty-codec-haproxy-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/netty-tcnative-boringssl-static-2.0.61.Final-linux-aarch_64.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/rest-authorizer-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/netty-tcnative-classes-2.0.61.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jetty-http-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/kafka-connect-protobuf-converter-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/google-cloud-core-2.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/auth-metadata-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/javassist-3.25.0-GA.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jbcrypt-0.4.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/kafka-tools-api-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/kafka-json-schema-provider-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/cel-generated-pb-0.3.5.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/asm-commons-9.6.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/osgi-resource-locator-1.0.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/flatbuffers-java-2.0.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/kafka-json-schema-serializer-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/activation-1.1.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/netty-codec-xml-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/metrics-core-4.1.12.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/minimal-json-0.9.5.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/netty-codec-socks-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jersey-hk2-2.36.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/netty-handler-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/google-api-services-storage-v1-rev20220401-1.32.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jetty-alpn-server-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/kotlin-scripting-common-1.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/scala-library-2.13.10.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/commons-io-2.11.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/joda-time-2.10.8.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/commons-codec-1.13.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/scala-collection-compat_2.13-2.10.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/commons-pool2-2.11.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jetty-continuation-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/kafka-connect-json-schema-converter-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jackson-jaxrs-json-provider-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/common-utils-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jersey-common-2.36.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/kafka-storage-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/netty-resolver-dns-native-macos-4.1.100.Final-osx-aarch_64.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jetty-util-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/auto-common-0.10.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/netty-transport-classes-epoll-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/javax.annotation-api-1.3.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jackson-annotations-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/javax-websocket-client-impl-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/asm-9.6.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/caffeine-2.9.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jakarta.el-api-4.0.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/nimbus-jose-jwt-9.24.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/netty-resolver-dns-classes-macos-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/confluent-connect-security-plugin-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jetty-alpn-conscrypt-server-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jcip-annotations-1.0-1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/kafka-json-serializer-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jetty-jmx-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/kafka-server-common-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/hk2-locator-2.6.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/aopalliance-repackaged-2.6.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/gax-httpjson-0.101.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jetty-jaas-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/kafka-raft-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/http2-hpack-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/org.apache.servicemix.bundles.antlr-2.7.7_5.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/google-http-client-gson-1.41.7.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/commons-collections-3.2.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jmespath-java-1.12.268.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/asm-tree-9.6.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/netty-tcnative-boringssl-static-2.0.61.Final-windows-x86_64.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jackson-dataformat-cbor-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jackson-datatype-guava-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jakarta.ws.rs-api-2.1.6.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jakarta.inject-2.6.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/confluent-security-plugins-common-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/classgraph-4.8.21.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jopt-simple-5.0.4.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jackson-datatype-joda-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/agrona-1.15.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/tink-gcpkms-1.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/javapoet-1.13.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/netty-codec-http-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/argparse4j-0.7.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/rbac-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jackson-core-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/kafka-storage-api-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/confluent-serializers-new-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/j2objc-annotations-2.8.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jsr305-3.0.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/netty-transport-udt-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/gax-2.16.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/commons-digester-2.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/protobuf-java-3.19.6.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/grpc-context-1.45.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/hk2-utils-2.6.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jetty-alpn-java-server-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/mina-core-2.2.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/conscrypt-openjdk-uber-2.5.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jetty-xml-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jakarta.xml.bind-api-2.3.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/google-auth-library-oauth2-http-1.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/kafka-connect-avro-converter-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/checker-qual-3.33.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/internal-rest-server-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/google-cloud-core-http-2.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/kotlinpoet-1.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/kotlin-scripting-jvm-1.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/api-common-2.1.5.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/guava-32.0.1-jre.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jakarta.annotation-api-1.3.5.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/websocket-server-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/api-ldap-model-2.1.4.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/commons-lang3-3.12.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/commons-compress-1.21.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/accessors-smart-2.4.9.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/kafka-schema-registry-client-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/tink-1.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/logredactor-1.0.12.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jetty-jndi-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jersey-container-servlet-core-2.36.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-security/connect/jetty-client-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/jackson-datatype-jsr310-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/logging-interceptor-4.9.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/aws-java-sdk-kms-1.12.268.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/pcollections-4.0.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/netty-transport-native-unix-common-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/snappy-java-1.1.10.5.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/jackson-dataformat-properties-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/paranamer-2.8.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/netty-tcnative-boringssl-static-2.0.61.Final-osx-x86_64.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/audience-annotations-0.12.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/jetty-servlets-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/jackson-module-jaxb-annotations-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/netty-handler-proxy-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/failureaccess-1.0.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/kafka-client-plugins-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/swagger-annotations-1.6.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/netty-codec-http2-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/trogdor-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/google-http-client-apache-v2-1.41.7.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/events-schema-0.187.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/simpleclient_tracer_otel_agent-0.12.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/snakeyaml-2.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/netty-tcnative-boringssl-static-2.0.61.Final-osx-aarch_64.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/connector-datapreview-extension-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/simpleclient_common-0.12.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/opencensus-proto-0.2.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/jackson-dataformat-csv-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/netty-transport-native-epoll-4.1.100.Final-linux-x86_64.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/jetty-util-ajax-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/kafka-clients-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/httpcore-4.4.16.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/simpleclient-0.12.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/kafka-streams-examples-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/netty-codec-redis-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/opencensus-api-0.31.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/error_prone_annotations-2.19.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/cloudevents-kafka-2.3.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/netty-transport-rxtx-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/oauth2-oidc-sdk-9.35.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/jackson-databind-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/classgraph-4.8.150.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/azure-storage-blob-12.12.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/jna-5.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/aws-java-sdk-sts-1.12.268.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/slf4j-api-1.7.30.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/ion-java-1.0.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/jackson-module-scala_2.13-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/jakarta.validation-api-2.0.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/google-http-client-jackson2-1.41.7.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/bc-fips-1.0.2.4.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/jetty-server-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/netty-transport-sctp-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/azure-core-http-netty-1.12.8.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/kafka_2.13-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/okhttp-4.9.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/reactor-core-3.4.26.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/aws-java-sdk-core-1.12.268.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/zookeeper-jute-3.8.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/connect-runtime-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/woodstox-core-6.5.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/stax2-api-4.2.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/proto-google-common-protos-2.8.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/netty-all-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/joda-time-2.9.9.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/cloudevents-api-2.3.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/jetty-servlet-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/zookeeper-3.8.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/confluent-resource-names-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/kafka-metadata-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/netty-codec-stomp-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/simpleclient_httpserver-0.12.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/connect-transforms-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/cel-core-0.3.5.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/kafka-log4j-appender-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/proto-google-iam-v1-1.3.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/jackson-jaxrs-base-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/cloudevents-protobuf-2.3.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/commons-codec-1.15.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/netty-resolver-dns-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/javassist-3.29.2-GA.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/jersey-container-servlet-2.39.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/javax.ws.rs-api-2.1.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/jakarta.activation-api-1.2.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/annotations-13.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/connect-api-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/connect-basic-auth-extension-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/slf4j-api-1.7.21.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/netty-resolver-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/telemetry-client-3.801.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/telemetry-events-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/confluent-audit-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/google-api-client-1.34.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/protobuf-java-util-3.19.6.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/google-api-services-cloudkms-v1-rev108-1.25.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/simpleclient_tracer_common-0.12.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/google-http-client-appengine-1.41.7.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/jackson-datatype-jdk8-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/simpleclient_tracer_otel-0.12.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/netty-tcnative-boringssl-static-2.0.61.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/authorizer-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/aws-java-sdk-s3-1.12.268.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/jersey-hk2-2.39.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/jline-3.22.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/google-http-client-1.41.7.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/netty-resolver-dns-native-macos-4.1.100.Final-osx-x86_64.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/reflections-0.9.12.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/commons-collections4-4.4.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/kotlin-stdlib-1.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/netty-transport-native-kqueue-4.1.100.Final-osx-aarch_64.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/netty-codec-dns-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/swagger-integration-2.2.8.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/netty-codec-mqtt-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/netty-transport-native-epoll-4.1.100.Final-linux-aarch_64.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/netty-transport-native-epoll-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/commons-lang3-3.11.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/google-auth-library-credentials-1.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/kotlin-stdlib-jdk8-1.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/netty-buffer-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/swagger-annotations-2.2.8.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/netty-transport-classes-kqueue-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/opentelemetry-proto-0.19.0-alpha.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/confluent-licensing-new-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/jackson-dataformat-yaml-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/telemetry-events-api-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/gson-2.9.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/jackson-dataformat-xml-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/connect-json-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/gson-fire-1.8.5.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/auto-value-annotations-1.9.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/auto-service-annotations-1.0-rc7.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/slf4j-reload4j-1.7.36.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/kafka-replication-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/scala-reflect-2.13.10.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/lz4-java-1.8.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/plexus-utils-3.3.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/metrics-core-2.2.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/netty-transport-native-kqueue-4.1.100.Final-osx-x86_64.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/swagger-jaxrs2-2.2.8.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/jetty-io-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/asm-9.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/reactor-netty-core-1.0.26.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/netty-transport-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/netty-tcnative-boringssl-static-2.0.61.Final-linux-x86_64.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/netty-common-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/jcip-annotations-1.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/bctls-fips-1.0.13.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/client-java-proto-14.0.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/azure-core-1.35.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/bcpkix-fips-1.0.6.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/hk2-api-2.6.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/netty-handler-ssl-ocsp-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/google-cloud-storage-2.6.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/opencensus-contrib-http-util-0.31.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/kafka-streams-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/netty-codec-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/jetty-security-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/jose4j-0.9.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/json-smart-2.4.10.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/slf4j-api-1.7.36.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/threetenbp-1.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/cel-generated-antlr-0.3.5.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/client-java-14.0.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/azure-storage-internal-avro-12.0.5.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/zstd-jni-1.5.5-1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/commons-logging-1.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/scala-logging_2.13-3.9.4.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/auto-service-1.0-rc7.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/connect-ce-logs-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/kafka-group-coordinator-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/cloudevents-core-2.3.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/scala-java8-compat_2.13-1.0.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/google-oauth-client-1.33.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/security-extensions-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/commons-cli-1.4.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/netty-codec-smtp-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/netty-codec-memcache-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/httpclient-4.5.14.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/netty-codec-haproxy-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/netty-tcnative-boringssl-static-2.0.61.Final-linux-aarch_64.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/reactive-streams-1.0.4.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/rest-authorizer-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/azure-storage-common-12.12.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/netty-tcnative-classes-2.0.61.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/jersey-container-servlet-core-2.39.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/jetty-http-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/google-cloud-core-2.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/auth-metadata-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/javax.servlet-api-3.1.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/jbcrypt-0.4.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/kotlin-stdlib-common-1.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/kafka-tools-api-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/reload4j-1.2.25.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/cel-generated-pb-0.3.5.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/connect-mirror-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/content-type-2.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/osgi-resource-locator-1.0.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/flatbuffers-java-2.0.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/kafka-shell-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/activation-1.1.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/netty-codec-xml-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/metrics-core-4.1.12.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/netty-codec-socks-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/netty-handler-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/auth-providers-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/google-api-services-storage-v1-rev20220401-1.32.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/telemetry-api-3.801.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/scala-library-2.13.10.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/commons-io-2.11.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/kafka-streams-test-utils-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/kotlin-stdlib-jdk7-1.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/scala-collection-compat_2.13-2.10.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/commons-pool2-2.11.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/jetty-continuation-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/kafka-tools-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/jackson-jaxrs-json-provider-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/kafka-storage-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/netty-resolver-dns-native-macos-4.1.100.Final-osx-aarch_64.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/azure-identity-1.7.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/jetty-util-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/connect-mirror-client-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/auto-common-0.10.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/netty-transport-classes-epoll-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/javax.annotation-api-1.3.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/msal4j-1.13.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/maven-artifact-3.8.8.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/jackson-annotations-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/annotations-3.0.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/jersey-common-2.39.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/jersey-server-2.39.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/nimbus-jose-jwt-9.24.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/netty-resolver-dns-classes-macos-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/swagger-models-2.2.8.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/jcip-annotations-1.0-1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/kafka-server-common-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/hk2-locator-2.6.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/broker-plugins-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/msal4j-persistence-extension-1.1.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/aopalliance-repackaged-2.6.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/okio-jvm-3.0.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/gax-httpjson-0.101.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/kafka-raft-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/google-http-client-gson-1.41.7.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/client-java-api-14.0.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/kafka.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/jmespath-java-1.12.268.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/netty-tcnative-boringssl-static-2.0.61.Final-windows-x86_64.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/jackson-dataformat-cbor-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/swagger-core-2.2.8.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/lang-tag-1.6.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/jersey-client-2.39.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/ce-sbk_2.13-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/jakarta.ws.rs-api-2.1.6.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/jakarta.inject-2.6.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/commons-math3-3.6.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/jopt-simple-5.0.4.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/agrona-1.15.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/jaxb-api-2.3.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/tink-gcpkms-1.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/netty-codec-http-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/argparse4j-0.7.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/rbac-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/jackson-core-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/kafka-storage-api-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/confluent-serializers-new-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/j2objc-annotations-2.8.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/jsr305-3.0.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/netty-transport-udt-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/gax-2.16.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/jsr305-3.0.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/protobuf-java-3.19.6.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/grpc-context-1.45.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/hk2-utils-2.6.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/jakarta.xml.bind-api-2.3.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/google-auth-library-oauth2-http-1.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/kafka-streams-scala_2.13-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/checker-qual-3.33.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/internal-rest-server-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/google-cloud-core-http-2.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/api-common-2.1.5.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/guava-32.0.1-jre.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/cloudevents-json-jackson-2.3.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/jackson-datatype-protobuf-0.9.11-jackson2.9.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/jakarta.annotation-api-1.3.5.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/reactor-netty-http-1.0.26.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/jna-platform-5.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/commons-compress-1.21.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/accessors-smart-2.4.9.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/rocksdbjni-7.9.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/tink-1.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka/jetty-client-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-common/build-tools-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-common/common-metrics-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-common/common-config-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-common/slf4j-api-1.7.36.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/confluent-common/common-utils-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/jackson-datatype-jsr310-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/netty-transport-native-unix-common-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/netty-tcnative-boringssl-static-2.0.61.Final-osx-x86_64.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/kotlin-stdlib-common-1.8.20.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/netty-handler-proxy-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/failureaccess-1.0.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/grpc-context-1.27.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/logredactor-metrics-1.0.12.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/netty-codec-http2-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/google-auth-library-credentials-1.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/opencensus-contrib-http-util-0.31.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/snakeyaml-2.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/proto-google-common-protos-2.22.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/netty-tcnative-boringssl-static-2.0.61.Final-osx-aarch_64.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/jackson-datatype-protobuf-0.9.13.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/kafka-protobuf-types-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/kafka-streams-json-schema-serde-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/jackson-dataformat-csv-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/netty-transport-native-epoll-4.1.100.Final-linux-x86_64.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/jackson-databind-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/ion-java-1.0.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/kotlin-scripting-compiler-embeddable-1.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/oauth2-oidc-sdk-10.7.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/kotlin-reflect-1.8.21.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/kafka-protobuf-provider-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/auto-service-annotations-1.0.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/kafka-connect-avro-data-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/dek-registry-client-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/re2j-1.6.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/kotlin-stdlib-jdk7-1.8.20.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/azure-security-keyvault-keys-4.6.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/aws-java-sdk-core-1.12.182.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/stax2-api-4.2.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/commons-validator-1.7.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/wire-schema-jvm-4.8.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/google-http-client-apache-v2-1.42.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/kafka-streams-protobuf-serde-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/kotlin-script-runtime-1.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/lang-tag-1.7.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/msal4j-persistence-extension-1.2.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/commons-codec-1.15.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/netty-resolver-dns-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/annotations-13.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/netty-resolver-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/cel-core-0.3.12.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/kotlin-scripting-compiler-impl-embeddable-1.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/protobuf-java-util-3.19.6.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/kafka-schema-registry-client-encryption-hcvault-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/jackson-datatype-jdk8-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/netty-tcnative-boringssl-static-2.0.61.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/google-http-client-gson-1.43.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/woodstox-core-6.5.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/avro-1.11.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/JSONata4Java-2.4.5.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/google-api-client-1.35.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/cel-generated-antlr-0.3.12.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/kafka-schema-serializer-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/netty-resolver-dns-native-macos-4.1.100.Final-osx-x86_64.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/wire-runtime-jvm-4.8.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/kotlin-stdlib-1.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/httpcore-4.4.15.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/netty-codec-dns-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/kafka-protobuf-serializer-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/everit-json-schema-1.14.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/agrona-1.17.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/jmespath-java-1.12.182.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/mbknor-jackson-jsonschema_2.13-1.0.39.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/netty-buffer-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/netty-transport-classes-kqueue-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/tink-awskms-1.9.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/kafka-schema-registry-client-encryption-aws-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/jackson-dataformat-yaml-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/error_prone_annotations-2.18.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/gson-2.9.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/kafka-schema-rules-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/jackson-dataformat-xml-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/commons-text-1.10.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/httpclient-4.5.13.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/auto-value-annotations-1.9.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/kafka-streams-7.5.3-ccs.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/json-20231013.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/protoparser-4.0.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/netty-transport-native-kqueue-4.1.100.Final-osx-x86_64.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/nimbus-jose-jwt-9.30.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/asm-9.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/okio-jvm-3.4.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/netty-transport-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/netty-tcnative-boringssl-static-2.0.61.Final-linux-x86_64.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/netty-common-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/kafka-avro-serializer-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/google-api-services-cloudkms-v1-rev20221107-2.0.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/jackson-module-parameter-names-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/netty-codec-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/swagger-annotations-2.1.10.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/json-smart-2.4.10.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/kafka-schema-registry-client-encryption-tink-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/azure-core-1.41.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/slf4j-api-1.7.36.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/kotlin-stdlib-jdk8-1.8.20.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/handy-uri-templates-2.1.8.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/commons-logging-1.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/kafka-schema-converter-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/cel-jackson-0.3.12.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/google-http-client-1.43.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/validation-api-2.0.1.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/netty-tcnative-boringssl-static-2.0.61.Final-linux-aarch_64.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/tink-1.12.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/reactive-streams-1.0.4.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/netty-tcnative-classes-2.0.61.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/reactor-core-3.4.30.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/kafka-connect-protobuf-converter-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/jna-5.13.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/kafka-json-schema-provider-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/commons-beanutils-1.9.4.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/content-type-2.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/kafka-json-schema-serializer-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/opencensus-api-0.31.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/minimal-json-0.9.5.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/tink-gcpkms-1.9.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/kafka-schema-registry-client-encryption-azure-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/netty-codec-socks-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/netty-handler-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/kotlin-scripting-common-1.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/scala-library-2.13.10.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/google-auth-library-oauth2-http-1.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/joda-time-2.10.8.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/jackson-dataformat-protobuf-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/kafka-connect-json-schema-converter-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/cel-generated-pb-0.3.12.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/netty-transport-classes-epoll-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/jackson-annotations-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/kafka-schema-registry-client-encryption-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/annotations-3.0.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/kafka-schema-registry-client-encryption-gcp-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/aws-java-sdk-kms-1.12.182.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/netty-resolver-dns-classes-macos-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/antlr4-runtime-4.13.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/reactor-netty-core-1.0.33.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/google-oauth-client-1.34.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/jcip-annotations-1.0-1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/kafka-json-serializer-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/vault-java-driver-5.4.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/commons-collections-3.2.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/picocli-4.7.5.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/netty-tcnative-boringssl-static-2.0.61.Final-windows-x86_64.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/reactor-netty-http-1.0.33.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/jackson-dataformat-cbor-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/azure-json-1.0.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/jackson-datatype-guava-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/msal4j-1.13.8.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/classgraph-4.8.21.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/jackson-datatype-joda-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/javapoet-1.13.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/netty-codec-http-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/jackson-core-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/kafka-streams-avro-serde-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/j2objc-annotations-2.8.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/jsr305-3.0.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/commons-digester-2.1.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/protobuf-java-3.19.6.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/azure-identity-1.9.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/kafka-connect-avro-converter-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/checker-qual-3.33.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/kotlinpoet-1.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/kotlin-scripting-jvm-1.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/guava-32.0.1-jre.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/jna-platform-5.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/commons-lang3-3.12.0.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/commons-compress-1.21.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/accessors-smart-2.4.9.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/kafka-schema-registry-client-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/rocksdbjni-7.9.2.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/cel-tools-0.3.12.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/azure-core-http-netty-1.13.5.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/kafka-serde-tools/logredactor-1.0.12.jar:/home/sumo/Downloads/confluent-7.5.3/share/java/monitoring-interceptors/monitoring-interceptors-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../ce-broker-plugins/build/libs/*:/home/sumo/Downloads/confluent-7.5.3/bin/../ce-broker-plugins/build/dependant-libs/*:/home/sumo/Downloads/confluent-7.5.3/bin/../ce-auth-providers/build/libs/*:/home/sumo/Downloads/confluent-7.5.3/bin/../ce-auth-providers/build/dependant-libs/*:/home/sumo/Downloads/confluent-7.5.3/bin/../ce-rest-server/build/libs/*:/home/sumo/Downloads/confluent-7.5.3/bin/../ce-rest-server/build/dependant-libs/*:/home/sumo/Downloads/confluent-7.5.3/bin/../ce-audit/build/libs/*:/home/sumo/Downloads/confluent-7.5.3/bin/../ce-audit/build/dependant-libs/*:/home/sumo/Downloads/confluent-7.5.3/bin/../ce-authorizer/build/libs/*:/home/sumo/Downloads/confluent-7.5.3/bin/../ce-authorizer/build/dependant-libs/*:/home/sumo/Downloads/confluent-7.5.3/bin/../ce-licensing/build/libs/*:/home/sumo/Downloads/confluent-7.5.3/bin/../ce-licensing/build/dependant-libs/*:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/jackson-datatype-jsr310-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/logging-interceptor-4.9.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/aws-java-sdk-kms-1.12.268.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/pcollections-4.0.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/netty-transport-native-unix-common-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/snappy-java-1.1.10.5.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/jackson-dataformat-properties-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/paranamer-2.8.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/netty-tcnative-boringssl-static-2.0.61.Final-osx-x86_64.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/audience-annotations-0.12.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/jetty-servlets-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/netty-handler-proxy-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/failureaccess-1.0.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/kafka-client-plugins-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/swagger-annotations-1.6.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/netty-codec-http2-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/trogdor-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/google-http-client-apache-v2-1.41.7.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/events-schema-0.187.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/simpleclient_tracer_otel_agent-0.12.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/snakeyaml-2.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/netty-tcnative-boringssl-static-2.0.61.Final-osx-aarch_64.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/connector-datapreview-extension-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/simpleclient_common-0.12.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/opencensus-proto-0.2.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/jackson-dataformat-csv-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/netty-transport-native-epoll-4.1.100.Final-linux-x86_64.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/jetty-util-ajax-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/kafka-clients-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/httpcore-4.4.16.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/simpleclient-0.12.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/kafka-streams-examples-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/netty-codec-redis-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/opencensus-api-0.31.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/error_prone_annotations-2.19.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/cloudevents-kafka-2.3.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/netty-transport-rxtx-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/oauth2-oidc-sdk-9.35.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/jackson-databind-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/classgraph-4.8.150.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/azure-storage-blob-12.12.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/jna-5.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/aws-java-sdk-sts-1.12.268.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/slf4j-api-1.7.30.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/ion-java-1.0.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/jackson-module-scala_2.13-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/jakarta.validation-api-2.0.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/google-http-client-jackson2-1.41.7.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/bc-fips-1.0.2.4.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/jetty-server-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/netty-transport-sctp-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/azure-core-http-netty-1.12.8.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/kafka_2.13-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/okhttp-4.9.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/reactor-core-3.4.26.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/aws-java-sdk-core-1.12.268.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/zookeeper-jute-3.8.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/connect-runtime-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/woodstox-core-6.5.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/stax2-api-4.2.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/proto-google-common-protos-2.8.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/netty-all-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/joda-time-2.9.9.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/cloudevents-api-2.3.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/jetty-servlet-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/zookeeper-3.8.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/confluent-resource-names-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/kafka-metadata-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/netty-codec-stomp-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/simpleclient_httpserver-0.12.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/connect-transforms-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/cel-core-0.3.5.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/kafka-log4j-appender-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/proto-google-iam-v1-1.3.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/jackson-jaxrs-base-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/cloudevents-protobuf-2.3.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/commons-codec-1.15.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/netty-resolver-dns-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/javassist-3.29.2-GA.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/jersey-container-servlet-2.39.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/javax.ws.rs-api-2.1.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/jakarta.activation-api-1.2.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/annotations-13.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/connect-api-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/connect-basic-auth-extension-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/slf4j-api-1.7.21.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/netty-resolver-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/telemetry-client-3.801.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/telemetry-events-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/confluent-audit-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/google-api-client-1.34.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/protobuf-java-util-3.19.6.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/google-api-services-cloudkms-v1-rev108-1.25.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/simpleclient_tracer_common-0.12.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/google-http-client-appengine-1.41.7.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/jackson-datatype-jdk8-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/simpleclient_tracer_otel-0.12.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/netty-tcnative-boringssl-static-2.0.61.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/authorizer-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/aws-java-sdk-s3-1.12.268.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/jersey-hk2-2.39.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/jline-3.22.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/google-http-client-1.41.7.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/netty-resolver-dns-native-macos-4.1.100.Final-osx-x86_64.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/reflections-0.9.12.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/commons-collections4-4.4.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/kotlin-stdlib-1.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/netty-transport-native-kqueue-4.1.100.Final-osx-aarch_64.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/netty-codec-dns-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/swagger-integration-2.2.8.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/netty-codec-mqtt-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/netty-transport-native-epoll-4.1.100.Final-linux-aarch_64.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/netty-transport-native-epoll-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/commons-lang3-3.11.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/google-auth-library-credentials-1.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/kotlin-stdlib-jdk8-1.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/netty-buffer-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/swagger-annotations-2.2.8.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/netty-transport-classes-kqueue-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/opentelemetry-proto-0.19.0-alpha.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/confluent-licensing-new-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/jackson-dataformat-yaml-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/telemetry-events-api-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/gson-2.9.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/jackson-dataformat-xml-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/connect-json-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/gson-fire-1.8.5.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/auto-value-annotations-1.9.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/auto-service-annotations-1.0-rc7.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/slf4j-reload4j-1.7.36.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/kafka-replication-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/scala-reflect-2.13.10.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/lz4-java-1.8.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/plexus-utils-3.3.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/metrics-core-2.2.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/netty-transport-native-kqueue-4.1.100.Final-osx-x86_64.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/swagger-jaxrs2-2.2.8.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/jetty-io-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/asm-9.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/reactor-netty-core-1.0.26.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/netty-transport-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/netty-tcnative-boringssl-static-2.0.61.Final-linux-x86_64.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/netty-common-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/jcip-annotations-1.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/bctls-fips-1.0.13.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/client-java-proto-14.0.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/azure-core-1.35.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/bcpkix-fips-1.0.6.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/hk2-api-2.6.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/netty-handler-ssl-ocsp-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/google-cloud-storage-2.6.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/opencensus-contrib-http-util-0.31.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/kafka-streams-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/netty-codec-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/jetty-security-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/jose4j-0.9.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/json-smart-2.4.10.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/slf4j-api-1.7.36.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/threetenbp-1.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/cel-generated-antlr-0.3.5.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/client-java-14.0.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/azure-storage-internal-avro-12.0.5.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/zstd-jni-1.5.5-1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/commons-logging-1.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/scala-logging_2.13-3.9.4.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/auto-service-1.0-rc7.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/connect-ce-logs-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/kafka-group-coordinator-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/cloudevents-core-2.3.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/scala-java8-compat_2.13-1.0.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/google-oauth-client-1.33.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/security-extensions-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/commons-cli-1.4.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/netty-codec-smtp-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/netty-codec-memcache-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/httpclient-4.5.14.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/netty-codec-haproxy-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/netty-tcnative-boringssl-static-2.0.61.Final-linux-aarch_64.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/reactive-streams-1.0.4.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/rest-authorizer-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/azure-storage-common-12.12.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/netty-tcnative-classes-2.0.61.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/jersey-container-servlet-core-2.39.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/jetty-http-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/google-cloud-core-2.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/auth-metadata-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/jbcrypt-0.4.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/kotlin-stdlib-common-1.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/kafka-tools-api-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/reload4j-1.2.25.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/cel-generated-pb-0.3.5.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/connect-mirror-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/content-type-2.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/osgi-resource-locator-1.0.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/flatbuffers-java-2.0.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/kafka-shell-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/activation-1.1.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/netty-codec-xml-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/metrics-core-4.1.12.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/netty-codec-socks-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/netty-handler-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/auth-providers-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/google-api-services-storage-v1-rev20220401-1.32.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/telemetry-api-3.801.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/scala-library-2.13.10.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/commons-io-2.11.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/kafka-streams-test-utils-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/kotlin-stdlib-jdk7-1.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/scala-collection-compat_2.13-2.10.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/commons-pool2-2.11.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/jetty-continuation-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/kafka-tools-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/kafka-storage-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/netty-resolver-dns-native-macos-4.1.100.Final-osx-aarch_64.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/azure-identity-1.7.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/jetty-util-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/connect-mirror-client-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/auto-common-0.10.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/netty-transport-classes-epoll-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/javax.annotation-api-1.3.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/msal4j-1.13.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/maven-artifact-3.8.8.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/jackson-annotations-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/annotations-3.0.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/jersey-common-2.39.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/jersey-server-2.39.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/nimbus-jose-jwt-9.24.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/netty-resolver-dns-classes-macos-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/swagger-models-2.2.8.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/jcip-annotations-1.0-1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/kafka-server-common-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/hk2-locator-2.6.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/broker-plugins-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/msal4j-persistence-extension-1.1.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/aopalliance-repackaged-2.6.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/okio-jvm-3.0.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/gax-httpjson-0.101.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/kafka-raft-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/google-http-client-gson-1.41.7.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/client-java-api-14.0.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/kafka.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/jmespath-java-1.12.268.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/netty-tcnative-boringssl-static-2.0.61.Final-windows-x86_64.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/jackson-dataformat-cbor-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/swagger-core-2.2.8.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/lang-tag-1.6.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/jersey-client-2.39.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/ce-sbk_2.13-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/jakarta.ws.rs-api-2.1.6.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/jakarta.inject-2.6.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/commons-math3-3.6.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/jopt-simple-5.0.4.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/agrona-1.15.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/jaxb-api-2.3.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/tink-gcpkms-1.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/netty-codec-http-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/argparse4j-0.7.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/rbac-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/jackson-core-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/kafka-storage-api-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/confluent-serializers-new-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/j2objc-annotations-2.8.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/jsr305-3.0.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/netty-transport-udt-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/gax-2.16.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/jsr305-3.0.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/protobuf-java-3.19.6.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/grpc-context-1.45.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/hk2-utils-2.6.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/jakarta.xml.bind-api-2.3.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/google-auth-library-oauth2-http-1.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/kafka-streams-scala_2.13-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/checker-qual-3.33.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/internal-rest-server-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/google-cloud-core-http-2.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/api-common-2.1.5.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/guava-32.0.1-jre.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/cloudevents-json-jackson-2.3.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/jackson-datatype-protobuf-0.9.11-jackson2.9.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/jakarta.annotation-api-1.3.5.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/reactor-netty-http-1.0.26.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/jna-platform-5.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/commons-compress-1.21.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/accessors-smart-2.4.9.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/rocksdbjni-7.9.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/tink-1.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka/jetty-client-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/jackson-datatype-jsr310-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/websocket-client-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/jcommander-1.78.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/pcollections-4.0.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/api-util-1.0.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/netty-transport-native-unix-common-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/snappy-java-1.1.10.5.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/netty-handler-proxy-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/kafka-client-plugins-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/jakarta.el-3.0.4.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/events-schema-0.187.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/auditlog-emitter-1.4.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/snakeyaml-2.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/rbac-api-server-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/netty-transport-native-epoll-4.1.100.Final-linux-x86_64.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/kafka-clients-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/javax.servlet-api-4.0.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/jakarta.validation-api-2.0.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/bc-fips-1.0.2.4.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/re2j-1.6.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/cloudevents-core-2.4.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/jsonassert-1.5.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/connect-runtime-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/confluent-resource-names-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/kafka-metadata-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/telemetry-events-7.3.0-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/connect-transforms-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/auto-value-annotations-1.8.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/cel-core-0.3.5.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/jul-to-slf4j-1.7.36.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/kafka-log4j-appender-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/jersey-server-2.36.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/testng-7.5.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/cloudevents-protobuf-2.3.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/commons-codec-1.15.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/api-asn1-ber-1.0.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/javax.ws.rs-api-2.1.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/confluent-audit-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/protobuf-java-util-3.19.6.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/jackson-datatype-jdk8-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/authorizer-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/reflections-0.9.12.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/jersey-bean-validation-2.36.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/telemetry-client-3.282.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/telemetry-api-3.282.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/jersey-client-2.36.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/netty-buffer-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/rbac-common-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/swagger-annotations-2.2.8.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/netty-transport-classes-kqueue-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/connect-api-7.5.3-ccs.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/jackson-dataformat-yaml-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/telemetry-events-api-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/gson-2.9.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/lz4-java-1.8.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/plexus-utils-3.3.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/metrics-core-2.2.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/mina-core-2.0.22.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/netty-transport-native-kqueue-4.1.100.Final-osx-x86_64.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/netty-transport-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/ce-kafka-http-server-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/netty-common-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/bctls-fips-1.0.13.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/bcpkix-fips-1.0.6.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/jetty-security-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/jose4j-0.9.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/cel-generated-antlr-0.3.5.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/zstd-jni-1.5.5-1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/concurrent-trees-2.6.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/connect-ce-logs-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/security-extensions-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/cloudevents-kafka-2.4.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/rest-authorizer-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/auth-metadata-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/argparse4j-0.8.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/jbcrypt-0.4.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/kafka-tools-api-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/jquery-3.5.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/cel-generated-pb-0.3.5.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/osgi-resource-locator-1.0.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/logredactor-metrics-1.0.11.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/api-ldap-model-1.0.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/minimal-json-0.9.5.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/netty-codec-socks-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/android-json-0.0.20131108.vaadin1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/api-i18n-1.0.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/auth-providers-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/commons-io-2.11.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/logredactor-1.0.11.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/kafka-tools-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/common-utils-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/jersey-common-2.36.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/jetty-util-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/netty-transport-classes-epoll-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/javax.annotation-api-1.3.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/maven-artifact-3.8.8.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/annotations-3.0.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/jakarta.el-api-4.0.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/commons-lang-2.6.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/kafka-server-common-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/kafka-raft-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/org.apache.servicemix.bundles.antlr-2.7.7_5.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/commons-collections-3.2.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/cp-sso-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/auditlog-emitter-common-1.4.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/connect-json-7.5.3-ccs.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/api-asn1-api-1.0.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/jakarta.ws.rs-api-2.1.6.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/jakarta.inject-2.6.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/confluent-security-plugins-common-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/jopt-simple-5.0.4.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/agrona-1.15.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/jaxb-api-2.3.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/netty-codec-http-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/rbac-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/jackson-core-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/jetty-proxy-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/cloudevents-api-2.4.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/protobuf-java-3.19.6.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/cloudevents-json-jackson-2.3.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/jackson-datatype-protobuf-0.9.11-jackson2.9.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/jakarta.annotation-api-1.3.5.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/commons-lang3-3.12.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-metadata-service/jetty-client-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/javax-websocket-server-impl-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/websocket-client-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/jboss-logging-3.3.2.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/snappy-java-1.1.10.5.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/jetty-servlets-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/jackson-module-jaxb-annotations-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/jetty-plus-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/failureaccess-1.0.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/jakarta.el-3.0.4.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/http2-server-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/hibernate-validator-6.1.7.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/websocket-api-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/jetty-util-ajax-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/jackson-databind-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/api-asn1-ber-2.1.4.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/jakarta.validation-api-2.0.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/jetty-server-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/api-util-2.1.4.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/classmate-1.3.4.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/jetty-servlet-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/jersey-server-2.36.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/jackson-jaxrs-base-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/commons-codec-1.15.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/jakarta.activation-api-1.2.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/http2-common-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/commons-collections4-4.4.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/jersey-bean-validation-2.36.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/jersey-container-servlet-2.36.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/api-asn1-api-2.1.4.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/jersey-client-2.36.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/jetty-webapp-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/javax.websocket-api-1.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/error_prone_annotations-2.18.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/javax.websocket-client-api-1.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/jetty-annotations-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/lz4-java-1.8.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/jetty-io-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/kafka-clients-7.5.3-ccs.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/api-i18n-2.1.4.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/hk2-api-2.6.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/websocket-servlet-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/jetty-security-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/websocket-common-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/zstd-jni-1.5.5-1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/rest-utils-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/jetty-http-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/javassist-3.25.0-GA.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/javax.servlet-api-3.1.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/asm-commons-9.6.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/osgi-resource-locator-1.0.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/activation-1.1.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/jersey-hk2-2.36.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/jetty-alpn-server-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/jetty-continuation-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/jackson-jaxrs-json-provider-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/jersey-common-2.36.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/jetty-util-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/javax.annotation-api-1.3.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/jackson-annotations-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/javax-websocket-client-impl-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/asm-9.6.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/caffeine-2.9.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/jakarta.el-api-4.0.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/jetty-alpn-conscrypt-server-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/jetty-jmx-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/hk2-locator-2.6.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/aopalliance-repackaged-2.6.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/jetty-jaas-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/http2-hpack-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/org.apache.servicemix.bundles.antlr-2.7.7_5.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/asm-tree-9.6.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/jakarta.ws.rs-api-2.1.6.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/jakarta.inject-2.6.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/jackson-core-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/j2objc-annotations-2.8.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/jsr305-3.0.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/hk2-utils-2.6.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/jetty-alpn-java-server-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/mina-core-2.2.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/conscrypt-openjdk-uber-2.5.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/jetty-xml-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/jakarta.xml.bind-api-2.3.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/checker-qual-3.33.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/guava-32.0.1-jre.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/jakarta.annotation-api-1.3.5.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/websocket-server-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/api-ldap-model-2.1.4.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/commons-lang3-3.12.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/jetty-jndi-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/jersey-container-servlet-core-2.36.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/rest-utils/jetty-client-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-common/build-tools-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-common/common-metrics-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-common/common-config-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-common/slf4j-api-1.7.36.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-common/common-utils-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/javax-websocket-server-impl-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/websocket-client-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/jboss-logging-3.3.2.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/snappy-java-1.1.10.5.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/jetty-servlets-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/jackson-module-jaxb-annotations-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/jetty-plus-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/failureaccess-1.0.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/jakarta.el-3.0.4.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/http2-server-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/hibernate-validator-6.1.7.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/websocket-api-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/jetty-util-ajax-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/kafka-clients-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/jackson-databind-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/api-asn1-ber-2.1.4.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/jakarta.validation-api-2.0.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/jetty-server-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/api-util-2.1.4.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/classmate-1.3.4.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/jetty-servlet-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/jersey-server-2.36.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/jackson-jaxrs-base-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/commons-codec-1.15.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/jakarta.activation-api-1.2.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/http2-common-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/commons-collections4-4.4.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/jersey-bean-validation-2.36.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/jersey-container-servlet-2.36.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/api-asn1-api-2.1.4.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/jersey-client-2.36.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/jetty-webapp-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/javax.websocket-api-1.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/telemetry-events-api-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/error_prone_annotations-2.18.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/javax.websocket-client-api-1.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/jetty-annotations-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/lz4-java-1.8.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/jetty-io-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/ce-kafka-http-server-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/api-i18n-2.1.4.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/hk2-api-2.6.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/websocket-servlet-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/jetty-security-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/websocket-common-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/slf4j-api-1.7.36.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/zstd-jni-1.5.5-1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/rest-utils-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/jetty-http-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/javassist-3.25.0-GA.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/javax.servlet-api-3.1.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/asm-commons-9.6.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/osgi-resource-locator-1.0.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/activation-1.1.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/jersey-hk2-2.36.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/jetty-alpn-server-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/jetty-continuation-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/jackson-jaxrs-json-provider-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/common-utils-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/jersey-common-2.36.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/jetty-util-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/javax.annotation-api-1.3.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/jackson-annotations-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/javax-websocket-client-impl-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/asm-9.6.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/caffeine-2.9.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/jakarta.el-api-4.0.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/jetty-alpn-conscrypt-server-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/jetty-jmx-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/hk2-locator-2.6.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/aopalliance-repackaged-2.6.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/jetty-jaas-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/http2-hpack-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/org.apache.servicemix.bundles.antlr-2.7.7_5.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/asm-tree-9.6.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/jakarta.ws.rs-api-2.1.6.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/jakarta.inject-2.6.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/jackson-core-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/j2objc-annotations-2.8.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/jsr305-3.0.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/hk2-utils-2.6.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/jetty-alpn-java-server-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/mina-core-2.2.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/conscrypt-openjdk-uber-2.5.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/jetty-xml-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/jakarta.xml.bind-api-2.3.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/checker-qual-3.33.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/guava-32.0.1-jre.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/jakarta.annotation-api-1.3.5.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/websocket-server-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/api-ldap-model-2.1.4.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/commons-lang3-3.12.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/jetty-jndi-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/jersey-container-servlet-core-2.36.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-http-server/jetty-client-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-rest-servlet/ce-kafka-rest-servlet-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-rest-extensions/snappy-java-1.1.10.5.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-rest-extensions/kafka-clients-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-rest-extensions/javax.ws.rs-api-2.1.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-rest-extensions/telemetry-events-api-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-rest-extensions/lz4-java-1.8.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-rest-extensions/slf4j-api-1.7.36.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-rest-extensions/zstd-jni-1.5.5-1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-rest-extensions/ce-kafka-rest-extensions-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-rest-extensions/common-utils-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/jackson-datatype-jsr310-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/netty-transport-native-unix-common-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/snappy-java-1.1.10.5.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/paranamer-2.8.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/audience-annotations-0.12.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/failureaccess-1.0.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/logredactor-metrics-1.0.12.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/snakeyaml-2.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/proto-google-common-protos-2.22.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/kafka-protobuf-types-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/jackson-dataformat-csv-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/jackson-module-scala_2.13-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/kotlin-scripting-compiler-embeddable-1.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/kotlin-reflect-1.8.21.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/kafka-protobuf-provider-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/common-config-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/re2j-1.6.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/kotlin-stdlib-jdk7-1.8.20.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/zookeeper-jute-3.8.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/commons-validator-1.7.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/zookeeper-3.8.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/wire-schema-jvm-4.8.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/kotlin-script-runtime-1.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/annotations-13.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/netty-resolver-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/kotlin-scripting-compiler-impl-embeddable-1.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/protobuf-java-util-3.19.6.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/kafka_2.13-7.5.3-ccs.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/jackson-datatype-jdk8-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/vavr-match-0.10.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/avro-1.11.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/kafka-schema-serializer-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/wire-runtime-jvm-4.8.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/kotlin-stdlib-1.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/kafka-protobuf-serializer-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/everit-json-schema-1.14.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/netty-transport-native-epoll-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/mbknor-jackson-jsonschema_2.13-1.0.39.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/netty-buffer-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/error_prone_annotations-2.18.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/gson-2.9.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/kafka-tools-api-7.5.3-ccs.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/json-20231013.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/scala-reflect-2.13.10.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/lz4-java-1.8.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/metrics-core-2.2.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/resilience4j-core-1.7.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/kafka-rest-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/okio-jvm-3.4.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/netty-transport-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/netty-common-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/kafka-avro-serializer-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/kafka-clients-7.5.3-ccs.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/jackson-module-parameter-names-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/netty-codec-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/swagger-annotations-2.1.10.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/jose4j-0.9.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/kotlin-stdlib-jdk8-1.8.20.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/kafka-storage-7.5.3-ccs.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/zstd-jni-1.5.5-1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/handy-uri-templates-2.1.8.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/commons-logging-1.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/scala-logging_2.13-3.9.4.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/scala-java8-compat_2.13-1.0.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/commons-cli-1.4.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/auto-value-annotations-1.7.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/validation-api-2.0.1.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/kafka-server-common-7.5.3-ccs.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/kafka-storage-api-7.5.3-ccs.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/kotlin-stdlib-common-1.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/resilience4j-ratelimiter-1.7.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/kafka-json-schema-provider-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/kafka-json-schema-serializer-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/minimal-json-0.9.5.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/netty-handler-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/kotlin-scripting-common-1.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/scala-library-2.13.10.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/commons-io-2.11.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/joda-time-2.10.8.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/scala-collection-compat_2.13-2.10.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/common-utils-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/netty-transport-classes-epoll-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/vavr-0.10.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/kafka-group-coordinator-7.5.3-ccs.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/kafka-json-serializer-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/commons-collections-3.2.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/kafka-raft-7.5.3-ccs.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/kafka-metadata-7.5.3-ccs.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/jackson-datatype-guava-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/classgraph-4.8.21.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/spotbugs-annotations-4.7.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/jopt-simple-5.0.4.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/jackson-datatype-joda-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/javapoet-1.13.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/argparse4j-0.7.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/jackson-core-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/j2objc-annotations-2.8.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/jsr305-3.0.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/commons-digester-2.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/protobuf-java-3.19.6.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/checker-qual-3.33.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/kotlinpoet-1.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/kotlin-scripting-jvm-1.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/guava-32.0.1-jre.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/commons-lang3-3.12.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/commons-compress-1.21.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/kafka-schema-registry-client-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-rest-lib/logredactor-1.0.12.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/ce-kafka-queues/*:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/kafka-queues-lib/*:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/pcollections-4.0.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/netty-transport-native-unix-common-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/snappy-java-1.1.10.5.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/jackson-dataformat-properties-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/jetty-servlets-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/jackson-module-jaxb-annotations-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/netty-handler-proxy-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/failureaccess-1.0.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/kafka-client-plugins-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/logredactor-metrics-1.0.12.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/events-schema-0.187.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/snakeyaml-2.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/netty-transport-native-epoll-4.1.100.Final-linux-x86_64.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/jetty-util-ajax-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/kafka-clients-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/cloudevents-kafka-2.3.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/jackson-databind-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/javax.servlet-api-4.0.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/jakarta.validation-api-2.0.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/re2j-1.6.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/jetty-server-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/connect-runtime-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/cloudevents-api-2.3.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/jetty-servlet-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/confluent-resource-names-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/kafka-metadata-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/connect-transforms-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/cel-core-0.3.5.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/kafka-log4j-appender-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/jersey-server-2.36.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/jackson-jaxrs-base-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/cloudevents-protobuf-2.3.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/javax.ws.rs-api-2.1.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/jakarta.activation-api-1.2.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/connect-api-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/netty-resolver-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/telemetry-client-3.801.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/telemetry-events-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/protobuf-java-util-3.19.6.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/jackson-datatype-jdk8-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/authorizer-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/avro-1.11.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/reflections-0.9.12.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/bc-fips-1.0.2.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/jersey-container-servlet-2.36.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/jersey-client-2.36.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/netty-buffer-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/swagger-annotations-2.2.8.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/netty-transport-classes-kqueue-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/opentelemetry-proto-0.19.0-alpha.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/confluent-licensing-new-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/jackson-dataformat-yaml-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/telemetry-events-api-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/error_prone_annotations-2.18.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/gson-2.9.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/connect-json-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/lz4-java-1.8.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/plexus-utils-3.3.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/metrics-core-2.2.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/netty-transport-native-kqueue-4.1.100.Final-osx-x86_64.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/jetty-io-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/netty-transport-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/netty-common-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/bctls-fips-1.0.13.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/bcpkix-fips-1.0.6.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/broker-plugins-7.5.3-ce-test.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/hk2-api-2.6.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/netty-codec-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/jetty-security-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/jose4j-0.9.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/cel-generated-antlr-0.3.5.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/zstd-jni-1.5.5-1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/connect-ce-logs-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/cloudevents-core-2.3.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/security-extensions-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/rest-authorizer-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/jetty-http-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/auth-metadata-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/javassist-3.25.0-GA.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/jbcrypt-0.4.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/kafka-tools-api-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/cel-generated-pb-0.3.5.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/osgi-resource-locator-1.0.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/activation-1.1.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/metrics-core-4.1.12.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/minimal-json-0.9.5.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/netty-codec-socks-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/jersey-hk2-2.36.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/netty-handler-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/telemetry-api-3.801.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/commons-io-2.11.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/jetty-continuation-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/kafka-tools-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/jackson-jaxrs-json-provider-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/jersey-common-2.36.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/jetty-util-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/netty-transport-classes-epoll-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/javax.annotation-api-1.3.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/maven-artifact-3.8.8.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/jackson-annotations-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/annotations-3.0.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/kafka-server-common-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/hk2-locator-2.6.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/aopalliance-repackaged-2.6.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/kafka-raft-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/jakarta.ws.rs-api-2.1.6.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/jakarta.inject-2.6.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/confluent-security-plugins-common-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/jopt-simple-5.0.4.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/agrona-1.15.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/jaxb-api-2.3.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/netty-codec-http-4.1.100.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/argparse4j-0.7.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/rbac-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/jackson-core-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/confluent-kafka-rest-security-plugin-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/confluent-serializers-new-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/j2objc-annotations-2.8.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/jsr305-3.0.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/protobuf-java-3.19.6.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/hk2-utils-2.6.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/jakarta.xml.bind-api-2.3.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/checker-qual-3.33.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/guava-32.0.1-jre.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/cloudevents-json-jackson-2.3.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/jackson-datatype-protobuf-0.9.11-jackson2.9.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/jakarta.annotation-api-1.3.5.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/commons-lang3-3.12.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/commons-compress-1.21.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/kafka-schema-registry-client-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/logredactor-1.0.12.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/jersey-container-servlet-core-2.36.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/kafka-rest/jetty-client-9.4.53.v20231009.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/jackson-datatype-jsr310-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/snappy-java-1.1.10.5.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/failureaccess-1.0.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/logredactor-metrics-1.0.12.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/snakeyaml-2.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/proto-google-common-protos-2.22.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/kafka-protobuf-types-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/jackson-dataformat-csv-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/kafka-clients-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/jackson-databind-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/kotlin-scripting-compiler-embeddable-1.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/kotlin-reflect-1.8.21.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/kafka-protobuf-provider-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/re2j-1.6.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/kotlin-stdlib-jdk7-1.8.20.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/commons-validator-1.7.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/wire-schema-jvm-4.8.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/kotlin-script-runtime-1.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/annotations-13.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/caffeine-2.8.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/kotlin-scripting-compiler-impl-embeddable-1.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/protobuf-java-util-3.19.6.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/jackson-datatype-jdk8-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/avro-1.11.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/kafka-schema-serializer-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/wire-runtime-jvm-4.8.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/bc-fips-1.0.2.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/kotlin-stdlib-1.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/everit-json-schema-1.14.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/mbknor-jackson-jsonschema_2.13-1.0.39.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/telemetry-events-api-7.5.3-ce.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/error_prone_annotations-2.18.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/gson-2.9.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/json-20231013.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/lz4-java-1.8.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/okio-jvm-3.4.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/kafka-avro-serializer-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/bctls-fips-1.0.13.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/bcpkix-fips-1.0.6.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/jackson-module-parameter-names-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/swagger-annotations-2.1.10.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/kotlin-stdlib-jdk8-1.8.20.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/zstd-jni-1.5.5-1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/handy-uri-templates-2.1.8.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/commons-logging-1.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/validation-api-2.0.1.Final.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/kotlin-stdlib-common-1.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/kafka-json-schema-provider-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/minimal-json-0.9.5.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/kotlin-scripting-common-1.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/scala-library-2.13.10.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/commons-io-2.11.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/joda-time-2.10.8.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/common-utils-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/jackson-annotations-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/confluent-schema-registry-validator-plugin-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/commons-collections-3.2.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/jackson-datatype-guava-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/classgraph-4.8.21.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/jackson-datatype-joda-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/javapoet-1.13.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/jackson-core-2.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/j2objc-annotations-2.8.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/jsr305-3.0.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/commons-digester-2.1.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/protobuf-java-3.19.6.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/checker-qual-3.33.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/kotlinpoet-1.14.2.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/kotlin-scripting-jvm-1.6.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/guava-32.0.1-jre.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/commons-lang3-3.12.0.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/commons-compress-1.21.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/kafka-schema-registry-client-7.5.3.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-security/schema-validator/logredactor-1.0.12.jar:/home/sumo/Downloads/confluent-7.5.3/bin/../support-metrics-client/build/dependant-libs-2.13.10/*:/home/sumo/Downloads/confluent-7.5.3/bin/../support-metrics-client/build/libs/*:/home/sumo/Downloads/confluent-7.5.3/bin/../share/java/confluent-telemetry/confluent-metrics-7.5.3-ce.jar:/usr/share/java/support-metrics-client/*
	os.spec = Linux, amd64, 5.15.0-92-generic
	os.vcpus = 4
 (org.apache.kafka.connect.runtime.WorkerInfo:72)
[2024-02-05 13:43:00,836] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.AbstractConnectCli:127)
[2024-02-05 13:43:00,868] INFO Loading plugin from: /usr/share/java/mysql-connector-java-8.0.20.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:01,329] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/mysql-connector-java-8.0.20.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:01,329] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:01,330] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:01,330] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:01,342] INFO Loading plugin from: /usr/share/java/maven3-resolver-provider.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:01,381] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven3-resolver-provider.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:01,383] INFO Loading plugin from: /usr/share/java/plexus-sec-dispatcher-1.4.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:01,394] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/plexus-sec-dispatcher-1.4.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:01,396] INFO Loading plugin from: /usr/share/java/slf4j-nop-1.7.25.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:01,403] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/slf4j-nop-1.7.25.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:01,405] INFO Loading plugin from: /usr/share/java/maven3-slf4j-provider-3.6.3.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:01,418] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven3-slf4j-provider-3.6.3.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:01,419] INFO Loading plugin from: /usr/share/java/confluent-hub-client (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:01,973] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/confluent-hub-client/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:01,975] INFO Loading plugin from: /usr/share/java/guice-spring-4.2.1.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:01,984] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/guice-spring-4.2.1.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:01,989] INFO Loading plugin from: /usr/share/java/maven-resolver-impl.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:02,023] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven-resolver-impl.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:02,025] INFO Loading plugin from: /usr/share/java/slf4j-jdk14.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:02,031] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/slf4j-jdk14.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:02,032] INFO Loading plugin from: /usr/share/java/maven3-settings-3.6.3.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:02,046] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven3-settings-3.6.3.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:02,048] INFO Loading plugin from: /usr/share/java/guice-throwingproviders-4.2.1.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:02,063] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/guice-throwingproviders-4.2.1.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:02,064] INFO Loading plugin from: /usr/share/java/jul-to-slf4j.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:02,082] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/jul-to-slf4j.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:02,084] INFO Loading plugin from: /usr/share/java/slf4j-api.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:02,095] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/slf4j-api.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:02,096] INFO Loading plugin from: /usr/share/java/maven3-artifact-3.6.3.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:02,108] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven3-artifact-3.6.3.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:02,109] INFO Loading plugin from: /usr/share/java/aopalliance-1.0.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:02,131] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/aopalliance-1.0.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:02,132] INFO Loading plugin from: /usr/share/java/commons-lang3-3.8.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:02,173] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/commons-lang3-3.8.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:02,175] INFO Loading plugin from: /usr/share/java/slf4j-jdk14-1.7.25.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:02,182] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/slf4j-jdk14-1.7.25.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:02,183] INFO Loading plugin from: /usr/share/java/guice-multibindings-4.2.1.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:02,193] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/guice-multibindings-4.2.1.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:02,195] INFO Loading plugin from: /usr/share/java/juh-6.4.7.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:02,245] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/juh-6.4.7.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:02,247] INFO Loading plugin from: /usr/share/java/guava.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:02,448] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/guava.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:02,449] INFO Loading plugin from: /usr/share/java/geronimo-interceptor-3.0-spec.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:02,459] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/geronimo-interceptor-3.0-spec.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:02,460] INFO Loading plugin from: /usr/share/java/maven-resolver-transport-wagon.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:02,475] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven-resolver-transport-wagon.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:02,476] INFO Loading plugin from: /usr/share/java/schema-registry-plugins (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:03,010] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/schema-registry-plugins/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:03,011] INFO Loading plugin from: /usr/share/java/wagon-http-shaded-3.3.4.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:03,130] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/wagon-http-shaded-3.3.4.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:03,131] INFO Loading plugin from: /usr/share/java/maven3-resolver-provider-3.6.3.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:03,141] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven3-resolver-provider-3.6.3.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:03,142] INFO Loading plugin from: /usr/share/java/maven-embedder-3.x.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:03,156] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven-embedder-3.x.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:03,158] INFO Loading plugin from: /usr/share/java/maven3-slf4j-provider.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:03,165] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven3-slf4j-provider.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:03,166] INFO Loading plugin from: /usr/share/java/geronimo-interceptor-3.0-spec-1.0.1.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:03,174] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/geronimo-interceptor-3.0-spec-1.0.1.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:03,175] INFO Loading plugin from: /usr/share/java/juh.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:03,184] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/juh.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:03,188] INFO Loading plugin from: /usr/share/java/maven-resolver-util.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:03,219] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven-resolver-util.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:03,220] INFO Loading plugin from: /usr/share/java/slf4j-jcl.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:03,226] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/slf4j-jcl.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:03,227] INFO Loading plugin from: /usr/share/java/plexus-interpolation-1.26.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:03,234] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/plexus-interpolation-1.26.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:03,235] INFO Loading plugin from: /usr/share/java/jcl-over-slf4j.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:03,240] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/jcl-over-slf4j.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:03,241] INFO Loading plugin from: /usr/share/java/maven-compat-3.x.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:03,278] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven-compat-3.x.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:03,279] INFO Loading plugin from: /usr/share/java/guice-servlet-4.2.1.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:03,293] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/guice-servlet-4.2.1.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:03,294] INFO Loading plugin from: /usr/share/java/guice-no-aop.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:03,333] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/guice-no-aop.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:03,333] INFO Loading plugin from: /usr/share/java/plexus-cipher-1.7.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:03,338] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/plexus-cipher-1.7.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:03,338] INFO Loading plugin from: /usr/share/java/maven3-artifact.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:03,360] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven3-artifact.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:03,361] INFO Loading plugin from: /usr/share/java/slf4j-simple-1.7.25.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:03,371] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/slf4j-simple-1.7.25.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:03,371] INFO Loading plugin from: /usr/share/java/maven-core-3.x.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:03,465] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven-core-3.x.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:03,465] INFO Loading plugin from: /usr/share/java/confluent-common (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:03,474] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/confluent-common/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:03,475] INFO Loading plugin from: /usr/share/java/cdi-api-1.2.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:03,487] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/cdi-api-1.2.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:03,488] INFO Loading plugin from: /usr/share/java/log4j-over-slf4j-1.7.25.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:03,493] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/log4j-over-slf4j-1.7.25.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:03,494] INFO Loading plugin from: /usr/share/java/kafka-connect-replicator (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:10,740] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/kafka-connect-replicator/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:10,740] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:10,741] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:10,742] INFO Added plugin 'io.confluent.connect.replicator.ReplicatorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:10,742] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:10,742] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:10,742] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:10,742] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:10,743] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:10,743] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:10,743] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:10,743] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:10,743] INFO Added plugin 'io.confluent.connect.replicator.util.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:10,743] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:10,743] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:10,744] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:10,744] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:10,744] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:10,744] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:10,744] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:10,744] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:10,745] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:10,745] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:10,745] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:10,745] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:10,745] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:10,745] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:10,745] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:10,746] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:10,746] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:10,746] INFO Added plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:10,746] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:10,746] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:10,746] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:10,746] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:10,747] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:10,747] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:10,747] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:10,747] INFO Added plugin 'org.apache.kafka.connect.transforms.HeaderFrom$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:10,747] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:10,747] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:10,747] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:10,747] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:10,748] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:10,748] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:10,748] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:10,748] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:10,748] INFO Added plugin 'org.apache.kafka.common.config.provider.DirectoryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:10,748] INFO Added plugin 'org.apache.kafka.common.config.provider.EnvVarConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:10,748] INFO Added plugin 'io.confluent.kafka.schemaregistry.client.config.provider.SchemaRegistryConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:10,749] INFO Loading plugin from: /usr/share/java/maven-resolver-transport-file.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:10,762] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven-resolver-transport-file.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:10,763] INFO Loading plugin from: /usr/share/java/maven3-model.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:10,779] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven3-model.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:10,779] INFO Loading plugin from: /usr/share/java/maven-resolver-api.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:10,794] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven-resolver-api.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:10,795] INFO Loading plugin from: /usr/share/java/maven-resolver-util-1.4.1.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:10,828] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven-resolver-util-1.4.1.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:10,828] INFO Loading plugin from: /usr/share/java/maven3-embedder-3.6.3.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:10,838] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven3-embedder-3.6.3.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:10,839] INFO Loading plugin from: /usr/share/java/ksqldb (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:14,888] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/ksqldb/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:14,889] INFO Added plugin 'io.confluent.ksql.serde.protobuf.ProtobufNoSRConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:14,889] INFO Added plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:14,889] INFO Added plugin 'io.confluent.connect.protobuf.ProtobufConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:14,889] INFO Added plugin 'io.confluent.connect.json.JsonSchemaConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:14,890] INFO Loading plugin from: /usr/share/java/wagon-provider-api-3.3.4.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:14,906] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/wagon-provider-api-3.3.4.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:14,907] INFO Loading plugin from: /usr/share/java/hawtjni-runtime.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:14,910] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/hawtjni-runtime.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:14,911] INFO Loading plugin from: /usr/share/java/guice-assistedinject-4.2.1.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:14,916] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/guice-assistedinject-4.2.1.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:14,916] INFO Loading plugin from: /usr/share/java/monitoring-interceptors (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:15,140] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/monitoring-interceptors/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:15,141] INFO Loading plugin from: /usr/share/java/wagon-file.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:15,143] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/wagon-file.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:15,144] INFO Loading plugin from: /usr/share/java/maven3-settings.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:15,148] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven3-settings.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:15,148] INFO Loading plugin from: /usr/share/java/kafka (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:18,250] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/kafka/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:18,250] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:18,250] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:18,250] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:18,250] INFO Added plugin 'io.confluent.connect.rest.datapreview.extension.util.PreviewRecordTransformer' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:18,250] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:18,251] INFO Added plugin 'io.confluent.connect.rest.datapreview.extension.ConnectorDataPreviewRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:18,251] INFO Loading plugin from: /usr/share/java/sisu-inject-0.3.3.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:18,280] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/sisu-inject-0.3.3.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:18,281] INFO Loading plugin from: /usr/share/java/ridl.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:18,296] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/ridl.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:18,297] INFO Loading plugin from: /usr/share/java/maven-resolver-connector-basic.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:18,302] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven-resolver-connector-basic.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:18,303] INFO Loading plugin from: /usr/share/java/libintl.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:18,308] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/libintl.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:18,309] INFO Loading plugin from: /usr/share/java/maven-resolver-connector-basic-1.4.1.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:18,316] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven-resolver-connector-basic-1.4.1.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:18,316] INFO Loading plugin from: /usr/share/java/maven-aether-provider-3.x.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:18,324] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven-aether-provider-3.x.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:18,325] INFO Loading plugin from: /usr/share/java/jansi-native.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:18,329] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/jansi-native.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:18,330] INFO Loading plugin from: /usr/share/java/unoloader-6.4.7.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:18,332] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/unoloader-6.4.7.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:18,333] INFO Loading plugin from: /usr/share/java/maven-settings-builder-3.x.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:18,341] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven-settings-builder-3.x.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:18,343] INFO Loading plugin from: /usr/share/java/maven3-repository-metadata.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:18,346] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven3-repository-metadata.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:18,347] INFO Loading plugin from: /usr/share/java/kafka-rest-bin (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:18,372] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/kafka-rest-bin/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:18,373] INFO Loading plugin from: /usr/share/java/slf4j-migrator.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:18,379] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/slf4j-migrator.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:18,380] INFO Loading plugin from: /usr/share/java/maven3-embedder.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:18,387] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven3-embedder.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:18,388] INFO Loading plugin from: /usr/share/java/plexus-component-annotations-1.5.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:18,391] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/plexus-component-annotations-1.5.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:18,391] INFO Loading plugin from: /usr/share/java/maven3-model-builder-3.6.3.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:18,409] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven3-model-builder-3.6.3.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:18,410] INFO Loading plugin from: /usr/share/java/maven3-plugin-api-3.6.3.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:18,417] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven3-plugin-api-3.6.3.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:18,418] INFO Loading plugin from: /usr/share/java/slf4j-jcl-1.7.25.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:18,420] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/slf4j-jcl-1.7.25.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:18,421] INFO Loading plugin from: /usr/share/java/guice-multibindings.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:18,423] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/guice-multibindings.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:18,424] INFO Loading plugin from: /usr/share/java/confluent-kafka-mqtt (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:19,648] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/confluent-kafka-mqtt/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:19,650] INFO Loading plugin from: /usr/share/java/kafka-rest-lib (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:20,894] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/kafka-rest-lib/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:20,895] INFO Loading plugin from: /usr/share/java/ce-kafka-rest-extensions (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:21,152] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/ce-kafka-rest-extensions/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:21,153] INFO Loading plugin from: /usr/share/java/maven-resolver-transport-classpath.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:21,156] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven-resolver-transport-classpath.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:21,157] INFO Loading plugin from: /usr/share/java/maven-resolver-test-util-1.4.1.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:21,164] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven-resolver-test-util-1.4.1.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:21,165] INFO Loading plugin from: /usr/share/java/plexus-cipher.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:21,168] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/plexus-cipher.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:21,168] INFO Loading plugin from: /usr/share/java/maven3-builder-support-3.6.3.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:21,171] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven3-builder-support-3.6.3.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:21,171] INFO Loading plugin from: /usr/share/java/plexus-classworlds.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:21,177] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/plexus-classworlds.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:21,177] INFO Loading plugin from: /usr/share/java/slf4j-api-1.7.25.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:21,182] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/slf4j-api-1.7.25.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:21,182] INFO Loading plugin from: /usr/share/java/maven-resolver-spi-1.4.1.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:21,187] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven-resolver-spi-1.4.1.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:21,188] INFO Loading plugin from: /usr/share/java/maven-resolver-test-util.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:21,194] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven-resolver-test-util.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:21,194] INFO Loading plugin from: /usr/share/java/geronimo-annotation-1.3-spec.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:21,197] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/geronimo-annotation-1.3-spec.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:21,197] INFO Loading plugin from: /usr/share/java/rest-utils (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:21,753] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/rest-utils/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:21,754] INFO Loading plugin from: /usr/share/java/kafka-serde-tools (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:22,911] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/kafka-serde-tools/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:22,912] INFO Loading plugin from: /usr/share/java/sisu-plexus-0.3.3.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:22,931] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/sisu-plexus-0.3.3.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:22,932] INFO Loading plugin from: /usr/share/java/maven3-builder-support.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:22,935] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven3-builder-support.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:22,935] INFO Loading plugin from: /usr/share/java/jul-to-slf4j-1.7.25.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:22,937] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/jul-to-slf4j-1.7.25.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:22,938] INFO Loading plugin from: /usr/share/java/acl (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:28,181] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/acl/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:28,181] INFO Added plugin 'io.confluent.connect.security.ConnectSecurityExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:28,182] INFO Loading plugin from: /usr/share/java/guava-19.0.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:28,263] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/guava-19.0.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:28,264] INFO Loading plugin from: /usr/share/java/maven3-compat.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:28,283] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven3-compat.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:28,284] INFO Loading plugin from: /usr/share/java/maven-resolver-impl-1.4.1.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:28,305] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven-resolver-impl-1.4.1.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:28,307] INFO Loading plugin from: /usr/share/java/sisu-inject.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:28,336] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/sisu-inject.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:28,336] INFO Loading plugin from: /usr/share/java/guice-jndi.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:28,339] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/guice-jndi.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:28,339] INFO Loading plugin from: /usr/share/java/wagon-provider-api.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:28,343] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/wagon-provider-api.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:28,344] INFO Loading plugin from: /usr/share/java/plexus-utils.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:28,357] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/plexus-utils.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:28,357] INFO Loading plugin from: /usr/share/java/slf4j-simple.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:28,361] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/slf4j-simple.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:28,361] INFO Loading plugin from: /usr/share/java/confluent-telemetry (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:28,972] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/confluent-telemetry/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:28,973] INFO Loading plugin from: /usr/share/java/commons-cli-1.4.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:28,976] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/commons-cli-1.4.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:28,977] INFO Loading plugin from: /usr/share/java/guice-jmx.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:28,979] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/guice-jmx.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:28,980] INFO Loading plugin from: /usr/share/java/guice-assistedinject.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:28,984] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/guice-assistedinject.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:28,985] INFO Loading plugin from: /usr/share/java/slf4j-log4j12.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:28,987] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/slf4j-log4j12.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:28,988] INFO Loading plugin from: /usr/share/java/jansi-1.18.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:28,992] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/jansi-1.18.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:28,992] INFO Loading plugin from: /usr/share/java/jsr305-0.1~+svn49.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:28,996] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/jsr305-0.1~+svn49.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:28,997] INFO Loading plugin from: /usr/share/java/maven-resolver-transport-classpath-1.4.1.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:29,001] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven-resolver-transport-classpath-1.4.1.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:29,002] INFO Loading plugin from: /usr/share/java/wagon-http-shaded.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:29,086] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/wagon-http-shaded.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:29,087] INFO Loading plugin from: /usr/share/java/commons-io-2.6.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:29,095] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/commons-io-2.6.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:29,095] INFO Loading plugin from: /usr/share/java/maven-resolver-spi.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:29,099] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven-resolver-spi.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:29,099] INFO Loading plugin from: /usr/share/java/maven-plugin-api-3.x.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:29,103] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven-plugin-api-3.x.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:29,104] INFO Loading plugin from: /usr/share/java/guice-throwingproviders.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:29,109] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/guice-throwingproviders.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:29,109] INFO Loading plugin from: /usr/share/java/plexus-component-annotations.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:29,111] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/plexus-component-annotations.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:29,112] INFO Loading plugin from: /usr/share/java/maven-resolver-transport-file-1.4.1.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:29,114] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven-resolver-transport-file-1.4.1.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:29,115] INFO Loading plugin from: /usr/share/java/maven3-model-builder.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:29,127] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven3-model-builder.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:29,127] INFO Loading plugin from: /usr/share/java/slf4j-log4j12-1.7.25.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:29,129] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/slf4j-log4j12-1.7.25.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:29,130] INFO Loading plugin from: /usr/share/java/commons-cli.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:29,134] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/commons-cli.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:29,135] INFO Loading plugin from: /usr/share/java/maven3-core-3.6.3.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:29,171] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven3-core-3.6.3.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:29,171] INFO Loading plugin from: /usr/share/java/wagon-file-3.3.4.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:29,174] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/wagon-file-3.3.4.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:29,174] INFO Loading plugin from: /usr/share/java/slf4j-nop.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:29,176] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/slf4j-nop.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:29,177] INFO Loading plugin from: /usr/share/java/log4j-over-slf4j.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:29,180] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/log4j-over-slf4j.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:29,181] INFO Loading plugin from: /usr/share/java/maven-artifact-3.x.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:29,185] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven-artifact-3.x.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:29,186] INFO Loading plugin from: /usr/share/java/schema-registry (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:30,735] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/schema-registry/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:30,735] INFO Loading plugin from: /usr/share/java/jcl-over-slf4j-1.7.25.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:30,738] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/jcl-over-slf4j-1.7.25.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:30,739] INFO Loading plugin from: /usr/share/java/commons-lang3.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:30,757] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/commons-lang3.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:30,757] INFO Loading plugin from: /usr/share/java/guice-no-aop-4.2.1.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:30,780] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/guice-no-aop-4.2.1.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:30,780] INFO Loading plugin from: /usr/share/java/guice-spring.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:30,783] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/guice-spring.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:30,783] INFO Loading plugin from: /usr/share/java/maven-settings-3.x.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:30,786] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven-settings-3.x.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:30,787] INFO Loading plugin from: /usr/share/java/maven-model-builder-3.x.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:30,799] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven-model-builder-3.x.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:30,800] INFO Loading plugin from: /usr/share/java/plexus-component-annotations-2.1.0.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:30,802] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/plexus-component-annotations-2.1.0.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:30,802] INFO Loading plugin from: /usr/share/java/ridl-6.4.7.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:30,813] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/ridl-6.4.7.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:30,814] INFO Loading plugin from: /usr/share/java/guice-jndi-4.2.1.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:30,816] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/guice-jndi-4.2.1.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:30,816] INFO Loading plugin from: /usr/share/java/maven3-core.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:30,853] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven3-core.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:30,853] INFO Loading plugin from: /usr/share/java/maven-shared-utils-3.3.0.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:30,864] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven-shared-utils-3.3.0.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:30,864] INFO Loading plugin from: /usr/share/java/confluent-metadata-service (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:31,839] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/confluent-metadata-service/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:31,840] INFO Loading plugin from: /usr/share/java/guice-grapher.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:31,845] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/guice-grapher.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:31,845] INFO Loading plugin from: /usr/share/java/aopalliance.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:31,848] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/aopalliance.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:31,849] INFO Loading plugin from: /usr/share/java/maven-shared-utils.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:31,859] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven-shared-utils.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:31,860] INFO Loading plugin from: /usr/share/java/maven3-plugin-api.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:31,866] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven3-plugin-api.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:31,866] INFO Loading plugin from: /usr/share/java/maven3-settings-builder.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:31,874] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven3-settings-builder.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:31,874] INFO Loading plugin from: /usr/share/java/maven-resolver-api-1.4.1.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:31,883] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven-resolver-api-1.4.1.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:31,884] INFO Loading plugin from: /usr/share/java/unoloader.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:31,886] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/unoloader.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:31,886] INFO Loading plugin from: /usr/share/java/plexus-sec-dispatcher.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:31,890] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/plexus-sec-dispatcher.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:31,890] INFO Loading plugin from: /usr/share/java/guice-servlet.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:31,899] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/guice-servlet.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:31,899] INFO Loading plugin from: /usr/share/java/sisu-plexus.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:31,920] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/sisu-plexus.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:31,921] INFO Loading plugin from: /usr/share/java/atinject-jsr330-api.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:31,923] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/atinject-jsr330-api.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:31,923] INFO Loading plugin from: /usr/share/java/maven-resolver-provider-3.x.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:31,938] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven-resolver-provider-3.x.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:31,939] INFO Loading plugin from: /usr/share/java/maven-repository-metadata-3.x.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:31,942] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven-repository-metadata-3.x.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:31,942] INFO Loading plugin from: /usr/share/java/jansi.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:31,947] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/jansi.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:31,948] INFO Loading plugin from: /usr/share/java/guice.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:31,987] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/guice.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:31,988] INFO Loading plugin from: /usr/share/java/plexus-utils2-3.3.0.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:31,997] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/plexus-utils2-3.3.0.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:31,997] INFO Loading plugin from: /usr/share/java/plexus-interpolation.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:32,003] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/plexus-interpolation.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:32,003] INFO Loading plugin from: /usr/share/java/atinject-jsr330-api-1.0.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:32,005] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/atinject-jsr330-api-1.0.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:32,006] INFO Loading plugin from: /usr/share/java/guice-grapher-4.2.1.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:32,011] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/guice-grapher-4.2.1.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:32,012] INFO Loading plugin from: /usr/share/java/maven3-model-3.6.3.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:32,020] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven3-model-3.6.3.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:32,020] INFO Loading plugin from: /usr/share/java/java-atk-wrapper.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:32,026] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/java-atk-wrapper.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:32,026] INFO Loading plugin from: /usr/share/java/jansi-native-1.8.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:32,029] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/jansi-native-1.8.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:32,029] INFO Loading plugin from: /usr/share/java/geronimo-annotation-1.3-spec-1.0.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:32,032] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/geronimo-annotation-1.3-spec-1.0.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:32,032] INFO Loading plugin from: /usr/share/java/plexus-classworlds-2.6.0.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:32,037] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/plexus-classworlds-2.6.0.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:32,037] INFO Loading plugin from: /usr/share/java/maven3-repository-metadata-3.6.3.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:32,040] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven3-repository-metadata-3.6.3.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:32,040] INFO Loading plugin from: /usr/share/java/cdi-api.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:32,046] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/cdi-api.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:32,047] INFO Loading plugin from: /usr/share/java/maven-model-3.x.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:32,055] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven-model-3.x.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:32,056] INFO Loading plugin from: /usr/share/java/confluent-security (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:39,267] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/confluent-security/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:39,268] INFO Added plugin 'io.confluent.kafka.secretregistry.client.config.provider.SecretConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:230)
[2024-02-05 13:43:39,269] INFO Loading plugin from: /usr/share/java/jsr305.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:39,273] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/jsr305.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:39,273] INFO Loading plugin from: /usr/share/java/confluent-rebalancer (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:41,751] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/confluent-rebalancer/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:41,752] INFO Loading plugin from: /usr/share/java/ce-kafka-rest-servlet (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:41,756] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/ce-kafka-rest-servlet/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:41,757] INFO Loading plugin from: /usr/share/java/confluent-control-center (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:45,086] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/confluent-control-center/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:45,087] INFO Loading plugin from: /usr/share/java/maven3-compat-3.6.3.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:45,108] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven3-compat-3.6.3.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:45,109] INFO Loading plugin from: /usr/share/java/ce-kafka-http-server (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:45,775] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/ce-kafka-http-server/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:45,776] INFO Loading plugin from: /usr/share/java/hawtjni-runtime-1.17.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:45,778] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/hawtjni-runtime-1.17.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:45,779] INFO Loading plugin from: /usr/share/java/guice-4.2.1.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:45,817] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/guice-4.2.1.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:45,818] INFO Loading plugin from: /usr/share/java/maven-builder-support-3.x.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:45,820] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven-builder-support-3.x.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:45,821] INFO Loading plugin from: /usr/share/java/maven3-settings-builder-3.6.3.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:45,825] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven3-settings-builder-3.6.3.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:45,826] INFO Loading plugin from: /usr/share/java/java_uno.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:45,828] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/java_uno.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:45,828] INFO Loading plugin from: /usr/share/java/jurt-6.4.7.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:45,837] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/jurt-6.4.7.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:45,837] INFO Loading plugin from: /usr/share/java/jurt.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:45,845] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/jurt.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:45,846] INFO Loading plugin from: /usr/share/java/plexus-utils2.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:45,859] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/plexus-utils2.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:45,859] INFO Loading plugin from: /usr/share/java/slf4j-migrator-1.7.25.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:45,872] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/slf4j-migrator-1.7.25.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:45,872] INFO Loading plugin from: /usr/share/java/maven-resolver-transport-wagon-1.4.1.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:45,885] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/maven-resolver-transport-wagon-1.4.1.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:45,886] INFO Loading plugin from: /usr/share/java/commons-io.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:45,900] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/commons-io.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:45,901] INFO Loading plugin from: /usr/share/java/guice-jmx-4.2.1.jar (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:275)
[2024-02-05 13:43:45,904] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/share/java/guice-jmx-4.2.1.jar} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:56,881] INFO Registered loader: jdk.internal.loader.ClassLoaders$AppClassLoader@75b84c92 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:297)
[2024-02-05 13:43:56,883] INFO Added aliases 'ReplicatorSourceConnector' and 'ReplicatorSource' to plugin 'io.confluent.connect.replicator.ReplicatorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2024-02-05 13:43:56,883] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2024-02-05 13:43:56,883] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2024-02-05 13:43:56,883] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2024-02-05 13:43:56,883] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2024-02-05 13:43:56,883] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2024-02-05 13:43:56,883] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2024-02-05 13:43:56,883] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2024-02-05 13:43:56,883] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2024-02-05 13:43:56,883] INFO Added aliases 'AvroConverter' and 'Avro' to plugin 'io.confluent.connect.avro.AvroConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2024-02-05 13:43:56,884] INFO Added aliases 'JsonSchemaConverter' and 'JsonSchema' to plugin 'io.confluent.connect.json.JsonSchemaConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2024-02-05 13:43:56,884] INFO Added aliases 'ProtobufConverter' and 'Protobuf' to plugin 'io.confluent.connect.protobuf.ProtobufConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2024-02-05 13:43:56,884] INFO Added aliases 'ProtobufNoSRConverter' and 'ProtobufNoSR' to plugin 'io.confluent.ksql.serde.protobuf.ProtobufNoSRConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2024-02-05 13:43:56,884] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2024-02-05 13:43:56,884] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2024-02-05 13:43:56,884] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2024-02-05 13:43:56,884] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2024-02-05 13:43:56,884] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2024-02-05 13:43:56,884] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2024-02-05 13:43:56,885] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2024-02-05 13:43:56,885] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2024-02-05 13:43:56,885] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2024-02-05 13:43:56,885] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2024-02-05 13:43:56,885] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2024-02-05 13:43:56,885] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2024-02-05 13:43:56,885] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2024-02-05 13:43:56,885] INFO Added aliases 'SimpleHeaderConverter' and 'Simple' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2024-02-05 13:43:56,885] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2024-02-05 13:43:56,885] INFO Added alias 'PreviewRecordTransformer' to plugin 'io.confluent.connect.rest.datapreview.extension.util.PreviewRecordTransformer' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:505)
[2024-02-05 13:43:56,885] INFO Added alias 'DropHeaders' to plugin 'org.apache.kafka.connect.transforms.DropHeaders' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:505)
[2024-02-05 13:43:56,886] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:505)
[2024-02-05 13:43:56,886] INFO Added alias 'InsertHeader' to plugin 'org.apache.kafka.connect.transforms.InsertHeader' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:505)
[2024-02-05 13:43:56,886] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:505)
[2024-02-05 13:43:56,886] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:505)
[2024-02-05 13:43:56,886] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:505)
[2024-02-05 13:43:56,886] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:505)
[2024-02-05 13:43:56,886] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:505)
[2024-02-05 13:43:56,886] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:505)
[2024-02-05 13:43:56,886] INFO Added alias 'ConnectorDataPreviewRestExtension' to plugin 'io.confluent.connect.rest.datapreview.extension.ConnectorDataPreviewRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:505)
[2024-02-05 13:43:56,886] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:505)
[2024-02-05 13:43:56,886] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2024-02-05 13:43:56,887] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2024-02-05 13:43:56,887] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:508)
[2024-02-05 13:43:56,989] INFO DistributedConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	auto.include.jmx.reporter = true
	bootstrap.servers = [pkc-4r087.us-west2.gcp.confluent.cloud:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	config.providers = []
	config.storage.replication.factor = 3
	config.storage.topic = connect-configs
	confluent.connector.task.status.metrics = false
	confluent.license = [hidden]
	confluent.license.inject.into.connectors = true
	confluent.topic = _confluent-command
	confluent.topic.auto.include.jmx.reporter = true
	confluent.topic.bootstrap.servers = []
	confluent.topic.client.dns.lookup = use_all_dns_ips
	confluent.topic.client.id = 
	confluent.topic.confluent.lkc.id = null
	confluent.topic.confluent.proxy.protocol.client.address = null
	confluent.topic.confluent.proxy.protocol.client.mode = PROXY
	confluent.topic.confluent.proxy.protocol.client.port = null
	confluent.topic.confluent.proxy.protocol.client.version = NONE
	confluent.topic.connections.max.idle.ms = 540000
	confluent.topic.consumer.allow.auto.create.topics = true
	confluent.topic.consumer.auto.commit.interval.ms = 5000
	confluent.topic.consumer.auto.include.jmx.reporter = true
	confluent.topic.consumer.auto.offset.reset = latest
	confluent.topic.consumer.check.crcs = true
	confluent.topic.consumer.client.dns.lookup = use_all_dns_ips
	confluent.topic.consumer.client.id = 
	confluent.topic.consumer.client.rack = 
	confluent.topic.consumer.confluent.lkc.id = null
	confluent.topic.consumer.confluent.proxy.protocol.client.address = null
	confluent.topic.consumer.confluent.proxy.protocol.client.mode = PROXY
	confluent.topic.consumer.confluent.proxy.protocol.client.port = null
	confluent.topic.consumer.confluent.proxy.protocol.client.version = NONE
	confluent.topic.consumer.connections.max.idle.ms = 540000
	confluent.topic.consumer.default.api.timeout.ms = 60000
	confluent.topic.consumer.enable.auto.commit = true
	confluent.topic.consumer.exclude.internal.topics = true
	confluent.topic.consumer.fetch.max.bytes = 52428800
	confluent.topic.consumer.fetch.max.wait.ms = 500
	confluent.topic.consumer.fetch.min.bytes = 1
	confluent.topic.consumer.group.id = null
	confluent.topic.consumer.group.instance.id = null
	confluent.topic.consumer.heartbeat.interval.ms = 3000
	confluent.topic.consumer.interceptor.classes = []
	confluent.topic.consumer.internal.leave.group.on.close = true
	confluent.topic.consumer.internal.throw.on.fetch.stable.offset.unsupported = false
	confluent.topic.consumer.isolation.level = read_uncommitted
	confluent.topic.consumer.max.partition.fetch.bytes = 1048576
	confluent.topic.consumer.max.poll.interval.ms = 300000
	confluent.topic.consumer.max.poll.records = 500
	confluent.topic.consumer.metadata.max.age.ms = 300000
	confluent.topic.consumer.metric.reporters = []
	confluent.topic.consumer.metrics.num.samples = 2
	confluent.topic.consumer.metrics.recording.level = INFO
	confluent.topic.consumer.metrics.sample.window.ms = 30000
	confluent.topic.consumer.partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	confluent.topic.consumer.receive.buffer.bytes = 65536
	confluent.topic.consumer.reconnect.backoff.max.ms = 1000
	confluent.topic.consumer.reconnect.backoff.ms = 50
	confluent.topic.consumer.request.timeout.ms = 30000
	confluent.topic.consumer.retry.backoff.ms = 100
	confluent.topic.consumer.sasl.client.callback.handler.class = null
	confluent.topic.consumer.sasl.jaas.config = null
	confluent.topic.consumer.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	confluent.topic.consumer.sasl.kerberos.min.time.before.relogin = 60000
	confluent.topic.consumer.sasl.kerberos.service.name = null
	confluent.topic.consumer.sasl.kerberos.ticket.renew.jitter = 0.05
	confluent.topic.consumer.sasl.kerberos.ticket.renew.window.factor = 0.8
	confluent.topic.consumer.sasl.login.callback.handler.class = null
	confluent.topic.consumer.sasl.login.class = null
	confluent.topic.consumer.sasl.login.connect.timeout.ms = null
	confluent.topic.consumer.sasl.login.read.timeout.ms = null
	confluent.topic.consumer.sasl.login.refresh.buffer.seconds = 300
	confluent.topic.consumer.sasl.login.refresh.min.period.seconds = 60
	confluent.topic.consumer.sasl.login.refresh.window.factor = 0.8
	confluent.topic.consumer.sasl.login.refresh.window.jitter = 0.05
	confluent.topic.consumer.sasl.login.retry.backoff.max.ms = 10000
	confluent.topic.consumer.sasl.login.retry.backoff.ms = 100
	confluent.topic.consumer.sasl.mechanism = GSSAPI
	confluent.topic.consumer.sasl.oauthbearer.clock.skew.seconds = 30
	confluent.topic.consumer.sasl.oauthbearer.expected.audience = null
	confluent.topic.consumer.sasl.oauthbearer.expected.issuer = null
	confluent.topic.consumer.sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	confluent.topic.consumer.sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	confluent.topic.consumer.sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	confluent.topic.consumer.sasl.oauthbearer.jwks.endpoint.url = null
	confluent.topic.consumer.sasl.oauthbearer.scope.claim.name = scope
	confluent.topic.consumer.sasl.oauthbearer.sub.claim.name = sub
	confluent.topic.consumer.sasl.oauthbearer.token.endpoint.url = null
	confluent.topic.consumer.security.protocol = PLAINTEXT
	confluent.topic.consumer.security.providers = null
	confluent.topic.consumer.send.buffer.bytes = 131072
	confluent.topic.consumer.session.timeout.ms = 45000
	confluent.topic.consumer.socket.connection.setup.timeout.max.ms = 30000
	confluent.topic.consumer.socket.connection.setup.timeout.ms = 10000
	confluent.topic.consumer.ssl.cipher.suites = null
	confluent.topic.consumer.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	confluent.topic.consumer.ssl.endpoint.identification.algorithm = https
	confluent.topic.consumer.ssl.engine.factory.class = null
	confluent.topic.consumer.ssl.key.password = null
	confluent.topic.consumer.ssl.keymanager.algorithm = SunX509
	confluent.topic.consumer.ssl.keystore.certificate.chain = null
	confluent.topic.consumer.ssl.keystore.key = null
	confluent.topic.consumer.ssl.keystore.location = null
	confluent.topic.consumer.ssl.keystore.password = null
	confluent.topic.consumer.ssl.keystore.type = JKS
	confluent.topic.consumer.ssl.protocol = TLSv1.3
	confluent.topic.consumer.ssl.provider = null
	confluent.topic.consumer.ssl.secure.random.implementation = null
	confluent.topic.consumer.ssl.trustmanager.algorithm = PKIX
	confluent.topic.consumer.ssl.truststore.certificates = null
	confluent.topic.consumer.ssl.truststore.location = null
	confluent.topic.consumer.ssl.truststore.password = null
	confluent.topic.consumer.ssl.truststore.type = JKS
	confluent.topic.interceptor.classes = []
	confluent.topic.metadata.max.age.ms = 300000
	confluent.topic.metric.reporters = []
	confluent.topic.metrics.num.samples = 2
	confluent.topic.metrics.recording.level = INFO
	confluent.topic.metrics.sample.window.ms = 30000
	confluent.topic.producer.acks = all
	confluent.topic.producer.auto.include.jmx.reporter = true
	confluent.topic.producer.batch.size = 16384
	confluent.topic.producer.buffer.memory = 33554432
	confluent.topic.producer.client.dns.lookup = use_all_dns_ips
	confluent.topic.producer.client.id = 
	confluent.topic.producer.compression.type = none
	confluent.topic.producer.confluent.lkc.id = null
	confluent.topic.producer.confluent.proxy.protocol.client.address = null
	confluent.topic.producer.confluent.proxy.protocol.client.mode = PROXY
	confluent.topic.producer.confluent.proxy.protocol.client.port = null
	confluent.topic.producer.confluent.proxy.protocol.client.version = NONE
	confluent.topic.producer.connections.max.idle.ms = 540000
	confluent.topic.producer.delivery.timeout.ms = 120000
	confluent.topic.producer.enable.idempotence = true
	confluent.topic.producer.interceptor.classes = []
	confluent.topic.producer.linger.ms = 0
	confluent.topic.producer.max.block.ms = 60000
	confluent.topic.producer.max.in.flight.requests.per.connection = 5
	confluent.topic.producer.max.request.size = 1048576
	confluent.topic.producer.metadata.max.age.ms = 300000
	confluent.topic.producer.metadata.max.idle.ms = 300000
	confluent.topic.producer.metric.reporters = []
	confluent.topic.producer.metrics.num.samples = 2
	confluent.topic.producer.metrics.recording.level = INFO
	confluent.topic.producer.metrics.sample.window.ms = 30000
	confluent.topic.producer.partitioner.adaptive.partitioning.enable = true
	confluent.topic.producer.partitioner.availability.timeout.ms = 0
	confluent.topic.producer.partitioner.class = null
	confluent.topic.producer.partitioner.ignore.keys = false
	confluent.topic.producer.receive.buffer.bytes = 32768
	confluent.topic.producer.reconnect.backoff.max.ms = 1000
	confluent.topic.producer.reconnect.backoff.ms = 50
	confluent.topic.producer.request.timeout.ms = 30000
	confluent.topic.producer.retry.backoff.ms = 100
	confluent.topic.producer.sasl.client.callback.handler.class = null
	confluent.topic.producer.sasl.jaas.config = null
	confluent.topic.producer.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	confluent.topic.producer.sasl.kerberos.min.time.before.relogin = 60000
	confluent.topic.producer.sasl.kerberos.service.name = null
	confluent.topic.producer.sasl.kerberos.ticket.renew.jitter = 0.05
	confluent.topic.producer.sasl.kerberos.ticket.renew.window.factor = 0.8
	confluent.topic.producer.sasl.login.callback.handler.class = null
	confluent.topic.producer.sasl.login.class = null
	confluent.topic.producer.sasl.login.connect.timeout.ms = null
	confluent.topic.producer.sasl.login.read.timeout.ms = null
	confluent.topic.producer.sasl.login.refresh.buffer.seconds = 300
	confluent.topic.producer.sasl.login.refresh.min.period.seconds = 60
	confluent.topic.producer.sasl.login.refresh.window.factor = 0.8
	confluent.topic.producer.sasl.login.refresh.window.jitter = 0.05
	confluent.topic.producer.sasl.login.retry.backoff.max.ms = 10000
	confluent.topic.producer.sasl.login.retry.backoff.ms = 100
	confluent.topic.producer.sasl.mechanism = GSSAPI
	confluent.topic.producer.sasl.oauthbearer.clock.skew.seconds = 30
	confluent.topic.producer.sasl.oauthbearer.expected.audience = null
	confluent.topic.producer.sasl.oauthbearer.expected.issuer = null
	confluent.topic.producer.sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	confluent.topic.producer.sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	confluent.topic.producer.sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	confluent.topic.producer.sasl.oauthbearer.jwks.endpoint.url = null
	confluent.topic.producer.sasl.oauthbearer.scope.claim.name = scope
	confluent.topic.producer.sasl.oauthbearer.sub.claim.name = sub
	confluent.topic.producer.sasl.oauthbearer.token.endpoint.url = null
	confluent.topic.producer.security.protocol = PLAINTEXT
	confluent.topic.producer.security.providers = null
	confluent.topic.producer.send.buffer.bytes = 131072
	confluent.topic.producer.socket.connection.setup.timeout.max.ms = 30000
	confluent.topic.producer.socket.connection.setup.timeout.ms = 10000
	confluent.topic.producer.ssl.cipher.suites = null
	confluent.topic.producer.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	confluent.topic.producer.ssl.endpoint.identification.algorithm = https
	confluent.topic.producer.ssl.engine.factory.class = null
	confluent.topic.producer.ssl.key.password = null
	confluent.topic.producer.ssl.keymanager.algorithm = SunX509
	confluent.topic.producer.ssl.keystore.certificate.chain = null
	confluent.topic.producer.ssl.keystore.key = null
	confluent.topic.producer.ssl.keystore.location = null
	confluent.topic.producer.ssl.keystore.password = null
	confluent.topic.producer.ssl.keystore.type = JKS
	confluent.topic.producer.ssl.protocol = TLSv1.3
	confluent.topic.producer.ssl.provider = null
	confluent.topic.producer.ssl.secure.random.implementation = null
	confluent.topic.producer.ssl.trustmanager.algorithm = PKIX
	confluent.topic.producer.ssl.truststore.certificates = null
	confluent.topic.producer.ssl.truststore.location = null
	confluent.topic.producer.ssl.truststore.password = null
	confluent.topic.producer.ssl.truststore.type = JKS
	confluent.topic.producer.transaction.timeout.ms = 60000
	confluent.topic.producer.transactional.id = null
	confluent.topic.receive.buffer.bytes = 32768
	confluent.topic.reconnect.backoff.max.ms = 1000
	confluent.topic.reconnect.backoff.ms = 50
	confluent.topic.replication.factor = 3
	confluent.topic.request.timeout.ms = 30000
	confluent.topic.retry.backoff.ms = 100
	confluent.topic.sasl.client.callback.handler.class = null
	confluent.topic.sasl.jaas.config = null
	confluent.topic.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	confluent.topic.sasl.kerberos.min.time.before.relogin = 60000
	confluent.topic.sasl.kerberos.service.name = null
	confluent.topic.sasl.kerberos.ticket.renew.jitter = 0.05
	confluent.topic.sasl.kerberos.ticket.renew.window.factor = 0.8
	confluent.topic.sasl.login.callback.handler.class = null
	confluent.topic.sasl.login.class = null
	confluent.topic.sasl.login.connect.timeout.ms = null
	confluent.topic.sasl.login.read.timeout.ms = null
	confluent.topic.sasl.login.refresh.buffer.seconds = 300
	confluent.topic.sasl.login.refresh.min.period.seconds = 60
	confluent.topic.sasl.login.refresh.window.factor = 0.8
	confluent.topic.sasl.login.refresh.window.jitter = 0.05
	confluent.topic.sasl.login.retry.backoff.max.ms = 10000
	confluent.topic.sasl.login.retry.backoff.ms = 100
	confluent.topic.sasl.mechanism = GSSAPI
	confluent.topic.sasl.oauthbearer.clock.skew.seconds = 30
	confluent.topic.sasl.oauthbearer.expected.audience = null
	confluent.topic.sasl.oauthbearer.expected.issuer = null
	confluent.topic.sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	confluent.topic.sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	confluent.topic.sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	confluent.topic.sasl.oauthbearer.jwks.endpoint.url = null
	confluent.topic.sasl.oauthbearer.scope.claim.name = scope
	confluent.topic.sasl.oauthbearer.sub.claim.name = sub
	confluent.topic.sasl.oauthbearer.token.endpoint.url = null
	confluent.topic.security.protocol = PLAINTEXT
	confluent.topic.security.providers = null
	confluent.topic.send.buffer.bytes = 131072
	confluent.topic.socket.connection.setup.timeout.max.ms = 30000
	confluent.topic.socket.connection.setup.timeout.ms = 10000
	confluent.topic.ssl.cipher.suites = null
	confluent.topic.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	confluent.topic.ssl.endpoint.identification.algorithm = https
	confluent.topic.ssl.engine.factory.class = null
	confluent.topic.ssl.key.password = null
	confluent.topic.ssl.keymanager.algorithm = SunX509
	confluent.topic.ssl.keystore.certificate.chain = null
	confluent.topic.ssl.keystore.key = null
	confluent.topic.ssl.keystore.location = null
	confluent.topic.ssl.keystore.password = null
	confluent.topic.ssl.keystore.type = JKS
	confluent.topic.ssl.protocol = TLSv1.3
	confluent.topic.ssl.provider = null
	confluent.topic.ssl.secure.random.implementation = null
	confluent.topic.ssl.trustmanager.algorithm = PKIX
	confluent.topic.ssl.truststore.certificates = null
	confluent.topic.ssl.truststore.location = null
	confluent.topic.ssl.truststore.password = null
	confluent.topic.ssl.truststore.type = JKS
	connect.cluster.mothership.context = false
	connect.protocol = sessioned
	connections.max.idle.ms = 540000
	connector.client.config.override.policy = All
	enable.fips = false
	exactly.once.source.support = disabled
	group.id = connect-cluster
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	heartbeat.interval.ms = 3000
	inter.worker.key.generation.algorithm = HmacSHA256
	inter.worker.key.size = null
	inter.worker.key.ttl.ms = 3600000
	inter.worker.signature.algorithm = HmacSHA256
	inter.worker.verification.algorithms = [HmacSHA256]
	key.converter = class io.confluent.connect.avro.AvroConverter
	listeners = [http://:8083]
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 10000
	offset.flush.timeout.ms = 5000
	offset.storage.partitions = 25
	offset.storage.replication.factor = 3
	offset.storage.topic = connect-offsets
	plugin.path = [/usr/share/java]
	rebalance.timeout.ms = 60000
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.servlet.initializor.classes = []
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	scheduled.rebalance.max.delay.ms = 300000
	security.protocol = SASL_SSL
	security.providers = 
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	status.storage.partitions = 5
	status.storage.replication.factor = 3
	status.storage.topic = connect-statuses
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class io.confluent.connect.avro.AvroConverter
	worker.sync.timeout.ms = 3000
	worker.unsync.backoff.ms = 300000
 (org.apache.kafka.connect.runtime.distributed.DistributedConfig:370)
[2024-02-05 13:43:56,994] INFO Creating Kafka admin client (org.apache.kafka.connect.runtime.WorkerConfig:299)
[2024-02-05 13:43:56,998] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [pkc-4r087.us-west2.gcp.confluent.cloud:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	confluent.lkc.id = null
	confluent.metrics.reporter.bootstrap.servers = kafka-0:9071
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	confluent.use.controller.listener = false
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	host.resolver.class = class org.apache.kafka.clients.DefaultHostResolver
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retries = 2147483647
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:370)
[2024-02-05 13:43:57,163] INFO Successfully logged in. (org.apache.kafka.common.security.authenticator.AbstractLogin:61)
[2024-02-05 13:43:57,282] INFO These configurations '[producer.sasl.jaas.config, producer.request.timeout.ms, producer.bootstrap.servers, group.id, plugin.path, producer.retry.backoff.ms, value.converter.schema.enable, offset.storage.topic, value.converter, key.converter, expose.internal.connect.endpoints, producer.security.protocol, config.storage.topic, status.storage.topic, producer.sasl.mechanism, offset.flush.interval.ms, key.converter.schemas.enable, producer.ssl.endpoint.identification.algorithm]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:379)
[2024-02-05 13:43:57,283] INFO Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:43:57,283] INFO Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:43:57,283] INFO Kafka startTimeMs: 1707120837282 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:44:13,031] INFO Kafka cluster ID: lkc-qpjpkm (org.apache.kafka.connect.runtime.WorkerConfig:316)
[2024-02-05 13:44:13,035] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:44:13,068] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:44:13,069] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:44:13,069] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:44:13,069] INFO FIPS mode enabled in connect: ${config.fipsEnabled} (org.apache.kafka.connect.cli.AbstractConnectCli:148)
[2024-02-05 13:44:13,229] INFO PublicConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	listeners = [http://:8083]
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.servlet.initializor.classes = []
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
 (org.apache.kafka.connect.runtime.rest.RestServerConfig$PublicConfig:370)
[2024-02-05 13:44:13,237] INFO Logging initialized @73440ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2024-02-05 13:44:13,280] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:121)
[2024-02-05 13:44:13,281] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:192)
[2024-02-05 13:44:13,306] INFO jetty-9.4.53.v20231009; built: 2023-10-09T12:29:09.265Z; git: 27bde00a0b95a1d5bbee0eae7984f891d2d0f8c9; jvm 11.0.21+9-post-Ubuntu-0ubuntu120.04 (org.eclipse.jetty.server.Server:375)
[2024-02-05 13:44:13,340] INFO Started http_8083@4de5ceac{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:333)
[2024-02-05 13:44:13,340] INFO Started @73543ms (org.eclipse.jetty.server.Server:415)
[2024-02-05 13:44:13,371] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:415)
[2024-02-05 13:44:13,371] INFO REST server listening at http://127.0.1.1:8083/, advertising URL http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:212)
[2024-02-05 13:44:13,371] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:415)
[2024-02-05 13:44:13,371] INFO REST admin endpoints at http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:215)
[2024-02-05 13:44:13,372] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:415)
[2024-02-05 13:44:13,372] INFO Setting up All Policy for ConnectorClientConfigOverride. This will allow all client configurations to be overridden (org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy:44)
[2024-02-05 13:44:13,392] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:370)
[2024-02-05 13:44:13,414] INFO Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:44:13,414] INFO Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:44:13,414] INFO Kafka startTimeMs: 1707120853414 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:44:13,425] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:370)
[2024-02-05 13:44:13,425] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	replace.null.with.default = true
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:370)
[2024-02-05 13:44:13,454] INFO Advertised URI: http://127.0.1.1:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:415)
[2024-02-05 13:44:13,465] INFO Successfully logged in. (org.apache.kafka.common.security.authenticator.AbstractLogin:61)
[2024-02-05 13:44:13,498] INFO Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:44:13,498] INFO Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:44:13,498] INFO Kafka startTimeMs: 1707120853498 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:44:13,502] INFO Kafka Connect worker initialization took 72696ms (org.apache.kafka.connect.cli.AbstractConnectCli:166)
[2024-02-05 13:44:13,502] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2024-02-05 13:44:13,505] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2024-02-05 13:44:13,505] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder starting (org.apache.kafka.connect.runtime.distributed.DistributedHerder:360)
[2024-02-05 13:44:13,505] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:264)
[2024-02-05 13:44:13,505] INFO Starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:266)
[2024-02-05 13:44:13,506] INFO Starting KafkaBasedLog with topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:280)
[2024-02-05 13:44:13,507] INFO AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [pkc-4r087.us-west2.gcp.confluent.cloud:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster--shared-admin
	confluent.lkc.id = null
	confluent.metrics.reporter.bootstrap.servers = kafka-0:9071
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	confluent.use.controller.listener = false
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	host.resolver.class = class org.apache.kafka.clients.DefaultHostResolver
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retries = 2147483647
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:370)
[2024-02-05 13:44:13,515] INFO These configurations '[producer.sasl.jaas.config, producer.request.timeout.ms, producer.bootstrap.servers, group.id, plugin.path, producer.retry.backoff.ms, metrics.context.connect.kafka.cluster.id, value.converter.schema.enable, offset.storage.topic, value.converter, key.converter, expose.internal.connect.endpoints, producer.security.protocol, config.storage.topic, metrics.context.connect.group.id, status.storage.topic, producer.sasl.mechanism, offset.flush.interval.ms, key.converter.schemas.enable, producer.ssl.endpoint.identification.algorithm]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:379)
[2024-02-05 13:44:13,515] INFO Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:44:13,516] INFO Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:44:13,516] INFO Kafka startTimeMs: 1707120853515 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:44:13,574] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:237)
[2024-02-05 13:44:13,673] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2024-02-05 13:44:13,673] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2024-02-05 13:44:13,674] INFO node0 Scavenging every 600000ms (org.eclipse.jetty.server.session:132)
[2024-02-05 13:44:14,302] INFO HV000001: Hibernate Validator 6.1.7.Final (org.hibernate.validator.internal.util.Version:21)
[2024-02-05 13:44:14,565] INFO Started o.e.j.s.ServletContextHandler@24d607b1{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:921)
[2024-02-05 13:44:14,565] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:323)
[2024-02-05 13:44:14,565] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2024-02-05 13:44:22,320] INFO 127.0.0.1 - - [05/Feb/2024:08:14:22 +0000] "GET /connectors HTTP/1.1" 200 2 "-" "curl/7.68.0" 130 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-02-05 13:44:31,454] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [pkc-4r087.us-west2.gcp.confluent.cloud:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster--offsets
	compression.type = none
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retries = 2147483647
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:370)
[2024-02-05 13:44:31,512] INFO These configurations '[producer.sasl.jaas.config, producer.request.timeout.ms, metrics.context.resource.version, producer.bootstrap.servers, group.id, metrics.context.resource.type, metrics.context.resource.commit.id, plugin.path, producer.retry.backoff.ms, metrics.context.connect.kafka.cluster.id, value.converter.schema.enable, offset.storage.topic, value.converter, key.converter, expose.internal.connect.endpoints, producer.security.protocol, config.storage.topic, metrics.context.connect.group.id, status.storage.topic, producer.sasl.mechanism, offset.flush.interval.ms, key.converter.schemas.enable, producer.ssl.endpoint.identification.algorithm]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:379)
[2024-02-05 13:44:31,513] INFO Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:44:31,514] INFO Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:44:31,514] INFO Kafka startTimeMs: 1707120871513 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:44:31,520] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [pkc-4r087.us-west2.gcp.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster--offsets
	client.rack = 
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:370)
[2024-02-05 13:44:31,561] INFO These configurations '[producer.sasl.jaas.config, producer.request.timeout.ms, producer.bootstrap.servers, plugin.path, producer.retry.backoff.ms, metrics.context.connect.kafka.cluster.id, value.converter.schema.enable, offset.storage.topic, value.converter, key.converter, expose.internal.connect.endpoints, producer.security.protocol, config.storage.topic, metrics.context.connect.group.id, status.storage.topic, producer.sasl.mechanism, offset.flush.interval.ms, key.converter.schemas.enable, producer.ssl.endpoint.identification.algorithm]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:379)
[2024-02-05 13:44:31,561] INFO Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:44:31,562] INFO Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:44:31,562] INFO Kafka startTimeMs: 1707120871561 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:44:38,790] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Cluster ID: lkc-qpjpkm (org.apache.kafka.clients.Metadata:287)
[2024-02-05 13:44:38,790] INFO [Producer clientId=connect-cluster--offsets] Cluster ID: lkc-qpjpkm (org.apache.kafka.clients.Metadata:287)
[2024-02-05 13:44:38,799] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Assigned to partition(s): connect-offsets-0, connect-offsets-5, connect-offsets-10, connect-offsets-20, connect-offsets-15, connect-offsets-9, connect-offsets-11, connect-offsets-16, connect-offsets-4, connect-offsets-17, connect-offsets-3, connect-offsets-24, connect-offsets-23, connect-offsets-13, connect-offsets-18, connect-offsets-22, connect-offsets-8, connect-offsets-2, connect-offsets-12, connect-offsets-19, connect-offsets-14, connect-offsets-1, connect-offsets-6, connect-offsets-7, connect-offsets-21 (org.apache.kafka.clients.consumer.KafkaConsumer:1135)
[2024-02-05 13:44:38,806] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:44:38,806] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-5 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:44:38,806] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-10 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:44:38,806] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-20 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:44:38,806] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-15 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:44:38,807] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-9 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:44:38,807] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-11 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:44:38,807] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-16 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:44:38,807] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:44:38,807] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-17 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:44:38,807] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:44:38,807] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-24 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:44:38,807] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-23 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:44:38,807] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-13 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:44:38,807] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-18 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:44:38,807] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-22 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:44:38,807] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-8 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:44:38,807] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:44:38,807] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-12 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:44:38,807] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-19 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:44:38,807] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-14 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:44:38,808] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:44:38,808] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-6 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:44:38,808] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-7 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:44:38,808] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Seeking to earliest offset of partition connect-offsets-21 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:44:49,907] INFO Finished reading KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:337)
[2024-02-05 13:44:49,908] INFO Started KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:339)
[2024-02-05 13:44:49,908] INFO Finished reading offsets topic and starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:283)
[2024-02-05 13:44:49,937] INFO LogEventsConfig values: 
	confluent.event.logger.cloudevent.codec = binary
	confluent.event.logger.deduplicate.errors = false
	confluent.event.logger.deduplicate.errors.reset.time.ms = 43200000
	confluent.event.logger.enable = false
	confluent.event.logger.exporter.class = class io.confluent.telemetry.events.exporter.kafka.EventKafkaExporter
	confluent.event.logger.exporter.kafka.producer.bootstrap.servers = 
	confluent.event.logger.exporter.kafka.producer.client.id = confluent-connect-log-events-emitter-connect-cluster
	confluent.event.logger.exporter.kafka.topic.create = true
	confluent.event.logger.exporter.kafka.topic.name = confluent-connect-log-events
	confluent.event.logger.exporter.kafka.type = kafka
 (io.confluent.logevents.connect.LogEventsConfig:370)
[2024-02-05 13:44:49,937] INFO Connect Log Events aren't enabled. (io.confluent.logevents.connect.LogEventsKafkaEmitter:65)
[2024-02-05 13:44:49,937] INFO Worker started (org.apache.kafka.connect.runtime.Worker:282)
[2024-02-05 13:44:49,938] INFO Starting KafkaBasedLog with topic connect-statuses (org.apache.kafka.connect.util.KafkaBasedLog:280)
[2024-02-05 13:44:51,145] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [pkc-4r087.us-west2.gcp.confluent.cloud:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster--statuses
	compression.type = none
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retries = 0
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:370)
[2024-02-05 13:44:51,164] INFO These configurations '[producer.sasl.jaas.config, producer.request.timeout.ms, metrics.context.resource.version, producer.bootstrap.servers, group.id, metrics.context.resource.type, metrics.context.resource.commit.id, plugin.path, producer.retry.backoff.ms, metrics.context.connect.kafka.cluster.id, value.converter.schema.enable, offset.storage.topic, value.converter, key.converter, expose.internal.connect.endpoints, producer.security.protocol, config.storage.topic, metrics.context.connect.group.id, status.storage.topic, producer.sasl.mechanism, offset.flush.interval.ms, key.converter.schemas.enable, producer.ssl.endpoint.identification.algorithm]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:379)
[2024-02-05 13:44:51,165] INFO Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:44:51,166] INFO Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:44:51,166] INFO Kafka startTimeMs: 1707120891165 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:44:51,169] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [pkc-4r087.us-west2.gcp.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster--statuses
	client.rack = 
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:370)
[2024-02-05 13:44:51,204] INFO These configurations '[producer.sasl.jaas.config, producer.request.timeout.ms, metrics.context.resource.version, producer.bootstrap.servers, metrics.context.resource.type, metrics.context.resource.commit.id, plugin.path, producer.retry.backoff.ms, metrics.context.connect.kafka.cluster.id, value.converter.schema.enable, offset.storage.topic, value.converter, key.converter, expose.internal.connect.endpoints, producer.security.protocol, config.storage.topic, metrics.context.connect.group.id, status.storage.topic, producer.sasl.mechanism, offset.flush.interval.ms, key.converter.schemas.enable, producer.ssl.endpoint.identification.algorithm]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:379)
[2024-02-05 13:44:51,205] INFO Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:44:51,205] INFO Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:44:51,205] INFO Kafka startTimeMs: 1707120891205 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:44:55,887] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Cluster ID: lkc-qpjpkm (org.apache.kafka.clients.Metadata:287)
[2024-02-05 13:44:55,888] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Assigned to partition(s): connect-statuses-0, connect-statuses-4, connect-statuses-1, connect-statuses-2, connect-statuses-3 (org.apache.kafka.clients.consumer.KafkaConsumer:1135)
[2024-02-05 13:44:55,889] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-statuses-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:44:55,889] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-statuses-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:44:55,889] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-statuses-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:44:55,889] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-statuses-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:44:55,889] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Seeking to earliest offset of partition connect-statuses-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:44:55,887] INFO [Producer clientId=connect-cluster--statuses] Cluster ID: lkc-qpjpkm (org.apache.kafka.clients.Metadata:287)
[2024-02-05 13:45:03,827] INFO Finished reading KafkaBasedLog for topic connect-statuses (org.apache.kafka.connect.util.KafkaBasedLog:337)
[2024-02-05 13:45:03,827] INFO Started KafkaBasedLog for topic connect-statuses (org.apache.kafka.connect.util.KafkaBasedLog:339)
[2024-02-05 13:45:03,837] INFO Starting KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:370)
[2024-02-05 13:45:03,847] INFO Starting KafkaBasedLog with topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:280)
[2024-02-05 13:45:04,501] INFO ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [pkc-4r087.us-west2.gcp.confluent.cloud:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster--configs
	compression.type = none
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retries = 2147483647
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:370)
[2024-02-05 13:45:04,564] INFO These configurations '[producer.sasl.jaas.config, producer.request.timeout.ms, metrics.context.resource.version, producer.bootstrap.servers, group.id, metrics.context.resource.type, metrics.context.resource.commit.id, plugin.path, producer.retry.backoff.ms, metrics.context.connect.kafka.cluster.id, value.converter.schema.enable, offset.storage.topic, value.converter, key.converter, expose.internal.connect.endpoints, producer.security.protocol, config.storage.topic, metrics.context.connect.group.id, status.storage.topic, producer.sasl.mechanism, offset.flush.interval.ms, key.converter.schemas.enable, producer.ssl.endpoint.identification.algorithm]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:379)
[2024-02-05 13:45:04,564] INFO Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:45:04,564] INFO Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:45:04,565] INFO Kafka startTimeMs: 1707120904564 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:45:04,566] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [pkc-4r087.us-west2.gcp.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connect-cluster--configs
	client.rack = 
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:370)
[2024-02-05 13:45:04,582] INFO These configurations '[producer.sasl.jaas.config, producer.request.timeout.ms, metrics.context.resource.version, producer.bootstrap.servers, metrics.context.resource.type, metrics.context.resource.commit.id, plugin.path, producer.retry.backoff.ms, metrics.context.connect.kafka.cluster.id, value.converter.schema.enable, offset.storage.topic, value.converter, key.converter, expose.internal.connect.endpoints, producer.security.protocol, config.storage.topic, metrics.context.connect.group.id, status.storage.topic, producer.sasl.mechanism, offset.flush.interval.ms, key.converter.schemas.enable, producer.ssl.endpoint.identification.algorithm]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:379)
[2024-02-05 13:45:04,583] INFO Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:45:04,583] INFO Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:45:04,583] INFO Kafka startTimeMs: 1707120904583 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:45:08,361] INFO [Producer clientId=connect-cluster--configs] Cluster ID: lkc-qpjpkm (org.apache.kafka.clients.Metadata:287)
[2024-02-05 13:45:08,364] INFO [Consumer clientId=connect-cluster--configs, groupId=connect-cluster] Cluster ID: lkc-qpjpkm (org.apache.kafka.clients.Metadata:287)
[2024-02-05 13:45:08,369] INFO [Consumer clientId=connect-cluster--configs, groupId=connect-cluster] Assigned to partition(s): connect-configs-0 (org.apache.kafka.clients.consumer.KafkaConsumer:1135)
[2024-02-05 13:45:08,370] INFO [Consumer clientId=connect-cluster--configs, groupId=connect-cluster] Seeking to earliest offset of partition connect-configs-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:45:21,524] INFO Finished reading KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:337)
[2024-02-05 13:45:21,524] INFO Started KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:339)
[2024-02-05 13:45:21,524] INFO Started KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:394)
[2024-02-05 13:45:21,525] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder started (org.apache.kafka.connect.runtime.distributed.DistributedHerder:365)
[2024-02-05 13:45:29,177] INFO [Worker clientId=connect-1, groupId=connect-cluster] Cluster ID: lkc-qpjpkm (org.apache.kafka.clients.Metadata:287)
[2024-02-05 13:45:29,181] INFO [Worker clientId=connect-1, groupId=connect-cluster] Discovered group coordinator b6-pkc-4r087.us-west2.gcp.confluent.cloud:9092 (id: 2147483641 rack: null) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:906)
[2024-02-05 13:45:29,222] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:231)
[2024-02-05 13:45:29,223] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:576)
[2024-02-05 13:45:33,526] INFO [Worker clientId=connect-1, groupId=connect-cluster] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException) (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1072)
[2024-02-05 13:45:33,528] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:576)
[2024-02-05 13:45:35,120] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=5, memberId='connect-1-5626c631-09b4-4bc6-b13c-f89c6adf07d0', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:637)
[2024-02-05 13:45:35,429] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=5, memberId='connect-1-5626c631-09b4-4bc6-b13c-f89c6adf07d0', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:812)
[2024-02-05 13:45:35,431] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 5 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-5626c631-09b4-4bc6-b13c-f89c6adf07d0', leaderUrl='http://127.0.1.1:8083/', offset=2, connectorIds=[], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2416)
[2024-02-05 13:45:35,433] WARN [Worker clientId=connect-1, groupId=connect-cluster] Catching up to assignment's config offset. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1625)
[2024-02-05 13:45:35,433] INFO [Worker clientId=connect-1, groupId=connect-cluster] Current config state offset -1 is behind group assignment 2, reading to end of config log (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1690)
[2024-02-05 13:45:36,472] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished reading to end of log and updated config snapshot, new config log offset: 2 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1717)
[2024-02-05 13:45:36,473] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 2 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1776)
[2024-02-05 13:45:36,473] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1804)
[2024-02-05 13:45:36,519] INFO Injecting Confluent license properties into connector 'replicator-cloud' (org.apache.kafka.connect.runtime.WorkerConfigDecorator:412)
[2024-02-05 13:45:36,537] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:370)
[2024-02-05 13:45:46,914] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector replicator-cloud config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2226)
[2024-02-05 13:45:48,183] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:231)
[2024-02-05 13:45:48,186] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:576)
[2024-02-05 13:45:48,265] INFO 127.0.0.1 - - [05/Feb/2024:08:14:24 +0000] "POST /connectors HTTP/1.1" 201 957 "-" "curl/7.68.0" 83603 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-02-05 13:45:49,008] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=6, memberId='connect-1-5626c631-09b4-4bc6-b13c-f89c6adf07d0', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:637)
[2024-02-05 13:45:50,355] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=6, memberId='connect-1-5626c631-09b4-4bc6-b13c-f89c6adf07d0', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:812)
[2024-02-05 13:45:50,357] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 6 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-5626c631-09b4-4bc6-b13c-f89c6adf07d0', leaderUrl='http://127.0.1.1:8083/', offset=3, connectorIds=[replicator-cloud], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2416)
[2024-02-05 13:45:50,358] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 3 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1776)
[2024-02-05 13:45:50,362] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connector replicator-cloud (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1893)
[2024-02-05 13:45:50,376] INFO [replicator-cloud|worker] Creating connector replicator-cloud of type io.confluent.connect.replicator.ReplicatorSourceConnector (org.apache.kafka.connect.runtime.Worker:370)
[2024-02-05 13:45:50,378] INFO [replicator-cloud|worker] Injecting Confluent license properties into connector 'replicator-cloud' (org.apache.kafka.connect.runtime.WorkerConfigDecorator:412)
[2024-02-05 13:45:50,382] INFO [replicator-cloud|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.replicator.ReplicatorSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	name = replicator-cloud
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:370)
[2024-02-05 13:45:50,386] INFO [replicator-cloud|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.replicator.ReplicatorSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	name = replicator-cloud
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:370)
[2024-02-05 13:45:50,415] INFO [replicator-cloud|worker] Instantiated connector replicator-cloud with version 7.5.2 of type class io.confluent.connect.replicator.ReplicatorSourceConnector (org.apache.kafka.connect.runtime.Worker:403)
[2024-02-05 13:45:50,418] INFO [replicator-cloud|worker] Finished creating connector replicator-cloud (org.apache.kafka.connect.runtime.Worker:424)
[2024-02-05 13:45:50,421] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1804)
[2024-02-05 13:45:50,426] INFO [replicator-cloud|worker] ReplicatorSourceConnectorConfig values: 
	confluent.license = [hidden]
	confluent.topic = _confluent-command
	consumer.poll.timeout.interval.ms = 5000
	dest.kafka.bootstrap.servers = [pkc-4r087.us-west2.gcp.confluent.cloud:9092]
	dest.kafka.client.id = 
	dest.kafka.connections.max.idle.ms = 540000
	dest.kafka.metric.reporters = []
	dest.kafka.metrics.num.samples = 2
	dest.kafka.metrics.sample.window.ms = 30000
	dest.kafka.receive.buffer.bytes = 65536
	dest.kafka.reconnect.backoff.ms = 50
	dest.kafka.request.timeout.ms = 20000
	dest.kafka.retry.backoff.ms = 500
	dest.kafka.sasl.client.callback.handler.class = null
	dest.kafka.sasl.jaas.config = [hidden]
	dest.kafka.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	dest.kafka.sasl.kerberos.min.time.before.relogin = 60000
	dest.kafka.sasl.kerberos.service.name = null
	dest.kafka.sasl.kerberos.ticket.renew.jitter = 0.05
	dest.kafka.sasl.kerberos.ticket.renew.window.factor = 0.8
	dest.kafka.sasl.login.callback.handler.class = null
	dest.kafka.sasl.login.class = null
	dest.kafka.sasl.login.connect.timeout.ms = null
	dest.kafka.sasl.login.read.timeout.ms = null
	dest.kafka.sasl.login.refresh.buffer.seconds = 300
	dest.kafka.sasl.login.refresh.min.period.seconds = 60
	dest.kafka.sasl.login.refresh.window.factor = 0.8
	dest.kafka.sasl.login.refresh.window.jitter = 0.05
	dest.kafka.sasl.login.retry.backoff.max.ms = 10000
	dest.kafka.sasl.login.retry.backoff.ms = 100
	dest.kafka.sasl.mechanism = PLAIN
	dest.kafka.sasl.oauthbearer.clock.skew.seconds = 30
	dest.kafka.sasl.oauthbearer.expected.audience = null
	dest.kafka.sasl.oauthbearer.expected.issuer = null
	dest.kafka.sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	dest.kafka.sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	dest.kafka.sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	dest.kafka.sasl.oauthbearer.jwks.endpoint.url = null
	dest.kafka.sasl.oauthbearer.scope.claim.name = scope
	dest.kafka.sasl.oauthbearer.sub.claim.name = sub
	dest.kafka.sasl.oauthbearer.token.endpoint.url = null
	dest.kafka.security.protocol = SASL_SSL
	dest.kafka.send.buffer.bytes = 131072
	dest.kafka.ssl.cipher.suites = null
	dest.kafka.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	dest.kafka.ssl.endpoint.identification.algorithm = https
	dest.kafka.ssl.engine.factory.class = null
	dest.kafka.ssl.key.password = null
	dest.kafka.ssl.keymanager.algorithm = SunX509
	dest.kafka.ssl.keystore.certificate.chain = null
	dest.kafka.ssl.keystore.key = null
	dest.kafka.ssl.keystore.location = null
	dest.kafka.ssl.keystore.password = null
	dest.kafka.ssl.keystore.type = JKS
	dest.kafka.ssl.protocol = TLSv1.3
	dest.kafka.ssl.provider = null
	dest.kafka.ssl.secure.random.implementation = null
	dest.kafka.ssl.trustmanager.algorithm = PKIX
	dest.kafka.ssl.truststore.certificates = null
	dest.kafka.ssl.truststore.location = null
	dest.kafka.ssl.truststore.password = null
	dest.kafka.ssl.truststore.type = JKS
	dest.topic.replication.factor = 3
	header.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	key.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	offset.start = connect
	offset.timestamps.commit = true
	offset.topic.commit = true
	offset.topic.commit.batch.period.ms = 60000
	offset.translator.batch.period.ms = 60000
	offset.translator.batch.size = 2147483647
	offset.translator.tasks.max = -1
	offset.translator.tasks.separate = false
	provenance.header.enable = false
	provenance.header.filter.overrides = 
	schema.registry.client.basic.auth.credentials.source = URL
	schema.registry.client.basic.auth.user.info = [hidden]
	schema.registry.max.schemas.per.subject = 1000
	schema.registry.topic = null
	schema.registry.url = null
	schema.subject.translator.class = null
	src.consumer.check.crcs = true
	src.consumer.fetch.max.bytes = 52428800
	src.consumer.fetch.max.wait.ms = 500
	src.consumer.fetch.min.bytes = 1
	src.consumer.interceptor.classes = []
	src.consumer.max.partition.fetch.bytes = 1048576
	src.consumer.max.poll.interval.ms = 300000
	src.consumer.max.poll.records = 500
	src.header.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	src.kafka.bootstrap.servers = [localhost:9092]
	src.kafka.client.id = 
	src.kafka.connections.max.idle.ms = 540000
	src.kafka.metric.reporters = []
	src.kafka.metrics.num.samples = 2
	src.kafka.metrics.sample.window.ms = 30000
	src.kafka.receive.buffer.bytes = 65536
	src.kafka.reconnect.backoff.ms = 50
	src.kafka.request.timeout.ms = 20000
	src.kafka.retry.backoff.ms = 100
	src.kafka.sasl.client.callback.handler.class = null
	src.kafka.sasl.jaas.config = null
	src.kafka.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	src.kafka.sasl.kerberos.min.time.before.relogin = 60000
	src.kafka.sasl.kerberos.service.name = null
	src.kafka.sasl.kerberos.ticket.renew.jitter = 0.05
	src.kafka.sasl.kerberos.ticket.renew.window.factor = 0.8
	src.kafka.sasl.login.callback.handler.class = null
	src.kafka.sasl.login.class = null
	src.kafka.sasl.login.connect.timeout.ms = null
	src.kafka.sasl.login.read.timeout.ms = null
	src.kafka.sasl.login.refresh.buffer.seconds = 300
	src.kafka.sasl.login.refresh.min.period.seconds = 60
	src.kafka.sasl.login.refresh.window.factor = 0.8
	src.kafka.sasl.login.refresh.window.jitter = 0.05
	src.kafka.sasl.login.retry.backoff.max.ms = 10000
	src.kafka.sasl.login.retry.backoff.ms = 100
	src.kafka.sasl.mechanism = GSSAPI
	src.kafka.sasl.oauthbearer.clock.skew.seconds = 30
	src.kafka.sasl.oauthbearer.expected.audience = null
	src.kafka.sasl.oauthbearer.expected.issuer = null
	src.kafka.sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	src.kafka.sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	src.kafka.sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	src.kafka.sasl.oauthbearer.jwks.endpoint.url = null
	src.kafka.sasl.oauthbearer.scope.claim.name = scope
	src.kafka.sasl.oauthbearer.sub.claim.name = sub
	src.kafka.sasl.oauthbearer.token.endpoint.url = null
	src.kafka.security.protocol = PLAINTEXT
	src.kafka.send.buffer.bytes = 131072
	src.kafka.ssl.cipher.suites = null
	src.kafka.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	src.kafka.ssl.endpoint.identification.algorithm = https
	src.kafka.ssl.engine.factory.class = null
	src.kafka.ssl.key.password = null
	src.kafka.ssl.keymanager.algorithm = SunX509
	src.kafka.ssl.keystore.certificate.chain = null
	src.kafka.ssl.keystore.key = null
	src.kafka.ssl.keystore.location = null
	src.kafka.ssl.keystore.password = null
	src.kafka.ssl.keystore.type = JKS
	src.kafka.ssl.protocol = TLSv1.3
	src.kafka.ssl.provider = null
	src.kafka.ssl.secure.random.implementation = null
	src.kafka.ssl.trustmanager.algorithm = PKIX
	src.kafka.ssl.truststore.certificates = null
	src.kafka.ssl.truststore.location = null
	src.kafka.ssl.truststore.password = null
	src.kafka.ssl.truststore.type = JKS
	src.key.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	src.value.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	topic.auto.create = true
	topic.blacklist = []
	topic.config.sync = true
	topic.config.sync.interval.ms = 120000
	topic.create.backoff.ms = 120000
	topic.poll.interval.ms = 120000
	topic.preserve.partitions = true
	topic.regex = .*
	topic.rename.format = ${topic}
	topic.timestamp.type = CreateTime
	topic.whitelist = []
	value.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
 (io.confluent.connect.replicator.ReplicatorSourceConnectorConfig:370)
[2024-02-05 13:45:50,428] INFO [replicator-cloud|worker] Starting replicator connector replicator-cloud (io.confluent.connect.replicator.ReplicatorSourceConnector:87)
[2024-02-05 13:45:50,464] INFO [replicator-cloud|worker] AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [pkc-4r087.us-west2.gcp.confluent.cloud:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	confluent.lkc.id = null
	confluent.metrics.reporter.bootstrap.servers = kafka-0:9071
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	confluent.use.controller.listener = false
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	host.resolver.class = class org.apache.kafka.clients.DefaultHostResolver
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retries = 2147483647
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:370)
[2024-02-05 13:45:50,500] INFO [replicator-cloud|worker] These configurations '[replication.factor, enable.idempotence, group.id, producer.enable.idempotence]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:379)
[2024-02-05 13:45:50,500] INFO [replicator-cloud|worker] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:45:50,500] INFO [replicator-cloud|worker] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:45:50,500] INFO [replicator-cloud|worker] Kafka startTimeMs: 1707120950500 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:45:57,911] INFO [replicator-cloud|worker] App info kafka.admin.client for adminclient-2 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:45:57,913] INFO [replicator-cloud|worker] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:45:57,913] INFO [replicator-cloud|worker] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:45:57,913] INFO [replicator-cloud|worker] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:45:57,916] INFO [replicator-cloud|worker] Starting License Store (io.confluent.license.LicenseStore:250)
[2024-02-05 13:45:57,917] INFO [replicator-cloud|worker] Starting KafkaBasedLog with topic _confluent-command (org.apache.kafka.connect.util.KafkaBasedLog:280)
[2024-02-05 13:45:57,917] INFO [replicator-cloud|worker] AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [pkc-4r087.us-west2.gcp.confluent.cloud:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	confluent.lkc.id = null
	confluent.metrics.reporter.bootstrap.servers = kafka-0:9071
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	confluent.use.controller.listener = false
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	host.resolver.class = class org.apache.kafka.clients.DefaultHostResolver
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retries = 2147483647
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:370)
[2024-02-05 13:45:57,920] INFO [replicator-cloud|worker] These configurations '[replication.factor, enable.idempotence, group.id, producer.enable.idempotence]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:379)
[2024-02-05 13:45:57,921] INFO [replicator-cloud|worker] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:45:57,921] INFO [replicator-cloud|worker] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:45:57,921] INFO [replicator-cloud|worker] Kafka startTimeMs: 1707120957921 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:46:04,467] INFO [replicator-cloud|worker] App info kafka.admin.client for adminclient-3 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:46:04,479] INFO [replicator-cloud|worker] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:46:04,484] INFO [replicator-cloud|worker] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:46:04,484] INFO [replicator-cloud|worker] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:46:04,489] INFO [replicator-cloud|worker] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [pkc-4r087.us-west2.gcp.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-null-license-1
	client.rack = 
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = null-license
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class io.confluent.license.LicenseStore$LicenseKeySerde
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.license.LicenseStore$LicenseMessageSerde
 (org.apache.kafka.clients.consumer.ConsumerConfig:370)
[2024-02-05 13:46:04,536] INFO [replicator-cloud|worker] These configurations '[replication.factor, enable.idempotence, producer.enable.idempotence]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:379)
[2024-02-05 13:46:04,536] INFO [replicator-cloud|worker] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:46:04,537] INFO [replicator-cloud|worker] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:46:04,537] INFO [replicator-cloud|worker] Kafka startTimeMs: 1707120964536 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:46:08,777] INFO [replicator-cloud|worker] [Consumer clientId=consumer-null-license-1, groupId=null-license] Cluster ID: lkc-qpjpkm (org.apache.kafka.clients.Metadata:287)
[2024-02-05 13:46:08,782] INFO [replicator-cloud|worker] [Consumer clientId=consumer-null-license-1, groupId=null-license] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1025)
[2024-02-05 13:46:08,782] INFO [replicator-cloud|worker] [Consumer clientId=consumer-null-license-1, groupId=null-license] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1072)
[2024-02-05 13:46:08,785] INFO [replicator-cloud|worker] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:46:08,785] INFO [replicator-cloud|worker] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:46:08,785] INFO [replicator-cloud|worker] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:46:08,796] INFO [replicator-cloud|worker] App info kafka.consumer for consumer-null-license-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:46:08,798] INFO [replicator-cloud|worker] ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [pkc-4r087.us-west2.gcp.confluent.cloud:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class io.confluent.license.LicenseStore$LicenseKeySerde
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retries = 2147483647
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class io.confluent.license.LicenseStore$LicenseMessageSerde
 (org.apache.kafka.clients.producer.ProducerConfig:370)
[2024-02-05 13:46:08,803] INFO [replicator-cloud|worker] These configurations '[replication.factor, group.id, producer.enable.idempotence]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:379)
[2024-02-05 13:46:08,803] INFO [replicator-cloud|worker] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:46:08,803] INFO [replicator-cloud|worker] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:46:08,804] INFO [replicator-cloud|worker] Kafka startTimeMs: 1707120968803 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:46:08,804] INFO [replicator-cloud|worker] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [pkc-4r087.us-west2.gcp.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-null-license-2
	client.rack = 
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = null-license
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class io.confluent.license.LicenseStore$LicenseKeySerde
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.license.LicenseStore$LicenseMessageSerde
 (org.apache.kafka.clients.consumer.ConsumerConfig:370)
[2024-02-05 13:46:08,809] INFO [replicator-cloud|worker] These configurations '[replication.factor, enable.idempotence, producer.enable.idempotence]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:379)
[2024-02-05 13:46:08,809] INFO [replicator-cloud|worker] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:46:08,809] INFO [replicator-cloud|worker] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:46:08,809] INFO [replicator-cloud|worker] Kafka startTimeMs: 1707120968809 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:46:10,645] INFO [replicator-cloud|worker] [Consumer clientId=consumer-null-license-2, groupId=null-license] Cluster ID: lkc-qpjpkm (org.apache.kafka.clients.Metadata:287)
[2024-02-05 13:46:10,646] INFO [replicator-cloud|worker] [Consumer clientId=consumer-null-license-2, groupId=null-license] Assigned to partition(s): _confluent-command-0 (org.apache.kafka.clients.consumer.KafkaConsumer:1135)
[2024-02-05 13:46:10,647] INFO [replicator-cloud|worker] [Consumer clientId=consumer-null-license-2, groupId=null-license] Seeking to earliest offset of partition _confluent-command-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:10,650] INFO [replicator-cloud|worker] [Producer clientId=producer-1] Cluster ID: lkc-qpjpkm (org.apache.kafka.clients.Metadata:287)
[2024-02-05 13:46:15,025] INFO [replicator-cloud|worker] Finished reading KafkaBasedLog for topic _confluent-command (org.apache.kafka.connect.util.KafkaBasedLog:337)
[2024-02-05 13:46:15,026] INFO [replicator-cloud|worker] Started KafkaBasedLog for topic _confluent-command (org.apache.kafka.connect.util.KafkaBasedLog:339)
[2024-02-05 13:46:15,028] INFO [replicator-cloud|worker] Started License Store (io.confluent.license.LicenseStore:252)
[2024-02-05 13:46:15,042] INFO [replicator-cloud|worker] Validating Confluent Replicator License... (io.confluent.connect.replicator.ReplicatorSourceConnector:214)
[2024-02-05 13:46:16,024] INFO [replicator-cloud|worker] AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [pkc-4r087.us-west2.gcp.confluent.cloud:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	confluent.lkc.id = null
	confluent.metrics.reporter.bootstrap.servers = kafka-0:9071
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	confluent.use.controller.listener = false
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	host.resolver.class = class org.apache.kafka.clients.DefaultHostResolver
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retries = 2147483647
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:370)
[2024-02-05 13:46:16,043] INFO [replicator-cloud|worker] These configurations '[replication.factor, enable.idempotence, group.id, producer.enable.idempotence]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:379)
[2024-02-05 13:46:16,043] INFO [replicator-cloud|worker] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:46:16,044] INFO [replicator-cloud|worker] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:46:16,044] INFO [replicator-cloud|worker] Kafka startTimeMs: 1707120976043 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:46:20,860] INFO [replicator-cloud|worker] App info kafka.admin.client for adminclient-4 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:46:20,863] INFO [replicator-cloud|worker] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:46:20,865] INFO [replicator-cloud|worker] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:46:20,866] INFO [replicator-cloud|worker] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:46:23,277] INFO [replicator-cloud|worker] AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [pkc-4r087.us-west2.gcp.confluent.cloud:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	confluent.lkc.id = null
	confluent.metrics.reporter.bootstrap.servers = kafka-0:9071
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	confluent.use.controller.listener = false
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	host.resolver.class = class org.apache.kafka.clients.DefaultHostResolver
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retries = 2147483647
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:370)
[2024-02-05 13:46:23,312] INFO [replicator-cloud|worker] These configurations '[replication.factor, enable.idempotence, group.id, producer.enable.idempotence]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:379)
[2024-02-05 13:46:23,312] INFO [replicator-cloud|worker] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:46:23,313] INFO [replicator-cloud|worker] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:46:23,313] INFO [replicator-cloud|worker] Kafka startTimeMs: 1707120983312 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:46:28,307] INFO [replicator-cloud|worker] App info kafka.admin.client for adminclient-5 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:46:28,314] INFO [replicator-cloud|worker] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:46:28,315] INFO [replicator-cloud|worker] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:46:28,315] INFO [replicator-cloud|worker] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:46:28,316] INFO [replicator-cloud|worker] Trial license for Confluent Enterprise expires in 29 days on 2024-03-06. (io.confluent.license.LicenseManager:559)
[2024-02-05 13:46:28,321] INFO [replicator-cloud|worker] AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	confluent.lkc.id = null
	confluent.metrics.reporter.bootstrap.servers = kafka-0:9071
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	confluent.use.controller.listener = false
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	host.resolver.class = class org.apache.kafka.clients.DefaultHostResolver
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:370)
[2024-02-05 13:46:28,327] INFO [replicator-cloud|worker] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:46:28,327] INFO [replicator-cloud|worker] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:46:28,327] INFO [replicator-cloud|worker] Kafka startTimeMs: 1707120988327 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:46:28,354] INFO [replicator-cloud|worker] Found matching topics: [connect-configs, output_topic, kafka-streams-aggregation-count-store-changelog, input_topic, stream_int-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog, stream_opnew, connect-offsets, stream_new1, postgres-userdata, _dek_registry_keys, _confluent_balancer_api_state, _schema_encoders, connect-status, stream_ip-count-store-changelog, postgres-data, __consumer_timestamps, sgr, postgres-userdata-replica, _schemas, stream_ip, _confluent-command, stream_new, my_topic, stream_opt, stream_ip-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog, stream_op2, stream_op3, _confluent-telemetry-metrics, stream_int, stream_op1] (io.confluent.connect.replicator.NewTopicMonitorThread:330)
[2024-02-05 13:46:28,356] INFO [replicator-cloud|worker] topic.regex is set. Replicator requires a DESCRIBE ACL on topics to match via regex. If this ACL is not present then the topic will not be replicated. (io.confluent.connect.replicator.NewTopicMonitorThread:347)
[2024-02-05 13:46:30,524] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.replicator.ReplicatorSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	name = replicator-cloud
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:370)
[2024-02-05 13:46:30,531] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.replicator.ReplicatorSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	name = replicator-cloud
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:370)
[2024-02-05 13:46:30,550] INFO [replicator-cloud|worker] Gathering task configs... (io.confluent.connect.replicator.ReplicatorSourceConnector:110)
[2024-02-05 13:46:30,551] INFO [replicator-cloud|worker] Assigning topic partitions to 1 tasks... (io.confluent.connect.replicator.NewTopicMonitorThread:150)
[2024-02-05 13:46:30,579] INFO [replicator-cloud|worker] Finished computing task topic partition assignments: {replicator-cloud-0=Assignment(partitions=[__consumer_timestamps-0, __consumer_timestamps-1, __consumer_timestamps-2, __consumer_timestamps-3, __consumer_timestamps-4, __consumer_timestamps-5, __consumer_timestamps-6, __consumer_timestamps-7, __consumer_timestamps-8, __consumer_timestamps-9, __consumer_timestamps-10, __consumer_timestamps-11, __consumer_timestamps-12, __consumer_timestamps-13, __consumer_timestamps-14, __consumer_timestamps-15, __consumer_timestamps-16, __consumer_timestamps-17, __consumer_timestamps-18, __consumer_timestamps-19, __consumer_timestamps-20, __consumer_timestamps-21, __consumer_timestamps-22, __consumer_timestamps-23, __consumer_timestamps-24, __consumer_timestamps-25, __consumer_timestamps-26, __consumer_timestamps-27, __consumer_timestamps-28, __consumer_timestamps-29, __consumer_timestamps-30, __consumer_timestamps-31, __consumer_timestamps-32, __consumer_timestamps-33, __consumer_timestamps-34, __consumer_timestamps-35, __consumer_timestamps-36, __consumer_timestamps-37, __consumer_timestamps-38, __consumer_timestamps-39, __consumer_timestamps-40, __consumer_timestamps-41, __consumer_timestamps-42, __consumer_timestamps-43, __consumer_timestamps-44, __consumer_timestamps-45, __consumer_timestamps-46, __consumer_timestamps-47, __consumer_timestamps-48, __consumer_timestamps-49, _confluent-command-0, _confluent-telemetry-metrics-0, _confluent-telemetry-metrics-1, _confluent-telemetry-metrics-2, _confluent-telemetry-metrics-3, _confluent-telemetry-metrics-4, _confluent-telemetry-metrics-5, _confluent-telemetry-metrics-6, _confluent-telemetry-metrics-7, _confluent-telemetry-metrics-8, _confluent-telemetry-metrics-9, _confluent-telemetry-metrics-10, _confluent-telemetry-metrics-11, _confluent_balancer_api_state-0, _dek_registry_keys-0, _schema_encoders-0, _schemas-0, connect-configs-0, connect-offsets-0, connect-offsets-1, connect-offsets-2, connect-offsets-3, connect-offsets-4, connect-offsets-5, connect-offsets-6, connect-offsets-7, connect-offsets-8, connect-offsets-9, connect-offsets-10, connect-offsets-11, connect-offsets-12, connect-offsets-13, connect-offsets-14, connect-offsets-15, connect-offsets-16, connect-offsets-17, connect-offsets-18, connect-offsets-19, connect-offsets-20, connect-offsets-21, connect-offsets-22, connect-offsets-23, connect-offsets-24, connect-status-0, connect-status-1, connect-status-2, connect-status-3, connect-status-4, input_topic-0, kafka-streams-aggregation-count-store-changelog-0, my_topic-0, output_topic-0, postgres-data-0, postgres-userdata-0, postgres-userdata-replica-0, sgr-0, stream_int-0, stream_int-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog-0, stream_ip-0, stream_ip-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog-0, stream_ip-count-store-changelog-0, stream_new-0, stream_new1-0, stream_op1-0, stream_op2-0, stream_op3-0, stream_opnew-0, stream_opt-0])} (io.confluent.connect.replicator.NewTopicMonitorThread:185)
[2024-02-05 13:46:30,608] INFO [replicator-cloud|worker] ReplicatorSourceTaskConfig values: 
	confluent.license = [hidden]
	confluent.topic = _confluent-command
	consumer.poll.timeout.interval.ms = 5000
	dest.kafka.bootstrap.servers = [pkc-4r087.us-west2.gcp.confluent.cloud:9092]
	dest.kafka.client.id = 
	dest.kafka.connections.max.idle.ms = 540000
	dest.kafka.metric.reporters = []
	dest.kafka.metrics.num.samples = 2
	dest.kafka.metrics.sample.window.ms = 30000
	dest.kafka.receive.buffer.bytes = 65536
	dest.kafka.reconnect.backoff.ms = 50
	dest.kafka.request.timeout.ms = 20000
	dest.kafka.retry.backoff.ms = 500
	dest.kafka.sasl.client.callback.handler.class = null
	dest.kafka.sasl.jaas.config = [hidden]
	dest.kafka.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	dest.kafka.sasl.kerberos.min.time.before.relogin = 60000
	dest.kafka.sasl.kerberos.service.name = null
	dest.kafka.sasl.kerberos.ticket.renew.jitter = 0.05
	dest.kafka.sasl.kerberos.ticket.renew.window.factor = 0.8
	dest.kafka.sasl.login.callback.handler.class = null
	dest.kafka.sasl.login.class = null
	dest.kafka.sasl.login.connect.timeout.ms = null
	dest.kafka.sasl.login.read.timeout.ms = null
	dest.kafka.sasl.login.refresh.buffer.seconds = 300
	dest.kafka.sasl.login.refresh.min.period.seconds = 60
	dest.kafka.sasl.login.refresh.window.factor = 0.8
	dest.kafka.sasl.login.refresh.window.jitter = 0.05
	dest.kafka.sasl.login.retry.backoff.max.ms = 10000
	dest.kafka.sasl.login.retry.backoff.ms = 100
	dest.kafka.sasl.mechanism = PLAIN
	dest.kafka.sasl.oauthbearer.clock.skew.seconds = 30
	dest.kafka.sasl.oauthbearer.expected.audience = null
	dest.kafka.sasl.oauthbearer.expected.issuer = null
	dest.kafka.sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	dest.kafka.sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	dest.kafka.sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	dest.kafka.sasl.oauthbearer.jwks.endpoint.url = null
	dest.kafka.sasl.oauthbearer.scope.claim.name = scope
	dest.kafka.sasl.oauthbearer.sub.claim.name = sub
	dest.kafka.sasl.oauthbearer.token.endpoint.url = null
	dest.kafka.security.protocol = SASL_SSL
	dest.kafka.send.buffer.bytes = 131072
	dest.kafka.ssl.cipher.suites = null
	dest.kafka.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	dest.kafka.ssl.endpoint.identification.algorithm = https
	dest.kafka.ssl.engine.factory.class = null
	dest.kafka.ssl.key.password = null
	dest.kafka.ssl.keymanager.algorithm = SunX509
	dest.kafka.ssl.keystore.certificate.chain = null
	dest.kafka.ssl.keystore.key = null
	dest.kafka.ssl.keystore.location = null
	dest.kafka.ssl.keystore.password = null
	dest.kafka.ssl.keystore.type = JKS
	dest.kafka.ssl.protocol = TLSv1.3
	dest.kafka.ssl.provider = null
	dest.kafka.ssl.secure.random.implementation = null
	dest.kafka.ssl.trustmanager.algorithm = PKIX
	dest.kafka.ssl.truststore.certificates = null
	dest.kafka.ssl.truststore.location = null
	dest.kafka.ssl.truststore.password = null
	dest.kafka.ssl.truststore.type = JKS
	dest.topic.replication.factor = 3
	header.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	key.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	offset.start = connect
	offset.timestamps.commit = true
	offset.topic.commit = true
	offset.topic.commit.batch.period.ms = 60000
	offset.translator.batch.period.ms = 60000
	offset.translator.batch.size = 2147483647
	offset.translator.tasks.max = -1
	offset.translator.tasks.separate = false
	partition.assignment = AAMAAAAeABVfX2NvbnN1bWVyX3RpbWVzdGFtcHMAAAAyAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAFAAAABgAAAAcAAAAIAAAACQAAAAoAAAALAAAADAAAAA0AAAAOAAAADwAAABAAAAARAAAAEgAAABMAAAAUAAAAFQAAABYAAAAXAAAAGAAAABkAAAAaAAAAGwAAABwAAAAdAAAAHgAAAB8AAAAgAAAAIQAAACIAAAAjAAAAJAAAACUAAAAmAAAAJwAAACgAAAApAAAAKgAAACsAAAAsAAAALQAAAC4AAAAvAAAAMAAAADEAEl9jb25mbHVlbnQtY29tbWFuZAAAAAEAAAAAABxfY29uZmx1ZW50LXRlbGVtZXRyeS1tZXRyaWNzAAAADAAAAAAAAAABAAAAAgAAAAMAAAAEAAAABQAAAAYAAAAHAAAACAAAAAkAAAAKAAAACwAdX2NvbmZsdWVudF9iYWxhbmNlcl9hcGlfc3RhdGUAAAABAAAAAAASX2Rla19yZWdpc3RyeV9rZXlzAAAAAQAAAAAAEF9zY2hlbWFfZW5jb2RlcnMAAAABAAAAAAAIX3NjaGVtYXMAAAABAAAAAAAPY29ubmVjdC1jb25maWdzAAAAAQAAAAAAD2Nvbm5lY3Qtb2Zmc2V0cwAAABkAAAAAAAAAAQAAAAIAAAADAAAABAAAAAUAAAAGAAAABwAAAAgAAAAJAAAACgAAAAsAAAAMAAAADQAAAA4AAAAPAAAAEAAAABEAAAASAAAAEwAAABQAAAAVAAAAFgAAABcAAAAYAA5jb25uZWN0LXN0YXR1cwAAAAUAAAAAAAAAAQAAAAIAAAADAAAABAALaW5wdXRfdG9waWMAAAABAAAAAAAva2Fma2Etc3RyZWFtcy1hZ2dyZWdhdGlvbi1jb3VudC1zdG9yZS1jaGFuZ2Vsb2cAAAABAAAAAAAIbXlfdG9waWMAAAABAAAAAAAMb3V0cHV0X3RvcGljAAAAAQAAAAAADXBvc3RncmVzLWRhdGEAAAABAAAAAAARcG9zdGdyZXMtdXNlcmRhdGEAAAABAAAAAAAZcG9zdGdyZXMtdXNlcmRhdGEtcmVwbGljYQAAAAEAAAAAAANzZ3IAAAABAAAAAAAKc3RyZWFtX2ludAAAAAEAAAAAAD1zdHJlYW1faW50LUtTVFJFQU0tQUdHUkVHQVRFLVNUQVRFLVNUT1JFLTAwMDAwMDAwMDEtY2hhbmdlbG9nAAAAAQAAAAAACXN0cmVhbV9pcAAAAAEAAAAAADxzdHJlYW1faXAtS1NUUkVBTS1BR0dSRUdBVEUtU1RBVEUtU1RPUkUtMDAwMDAwMDAwMS1jaGFuZ2Vsb2cAAAABAAAAAAAfc3RyZWFtX2lwLWNvdW50LXN0b3JlLWNoYW5nZWxvZwAAAAEAAAAAAApzdHJlYW1fbmV3AAAAAQAAAAAAC3N0cmVhbV9uZXcxAAAAAQAAAAAACnN0cmVhbV9vcDEAAAABAAAAAAAKc3RyZWFtX29wMgAAAAEAAAAAAApzdHJlYW1fb3AzAAAAAQAAAAAADHN0cmVhbV9vcG5ldwAAAAEAAAAAAApzdHJlYW1fb3B0AAAAAQAAAAD/////
	provenance.header.enable = false
	provenance.header.filter.overrides = 
	schema.registry.client.basic.auth.credentials.source = URL
	schema.registry.client.basic.auth.user.info = [hidden]
	schema.registry.max.schemas.per.subject = 1000
	schema.registry.topic = null
	schema.registry.url = null
	schema.subject.translator.class = null
	src.consumer.check.crcs = true
	src.consumer.fetch.max.bytes = 52428800
	src.consumer.fetch.max.wait.ms = 500
	src.consumer.fetch.min.bytes = 1
	src.consumer.interceptor.classes = []
	src.consumer.max.partition.fetch.bytes = 1048576
	src.consumer.max.poll.interval.ms = 300000
	src.consumer.max.poll.records = 500
	src.header.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	src.kafka.bootstrap.servers = [localhost:9092]
	src.kafka.client.id = 
	src.kafka.connections.max.idle.ms = 540000
	src.kafka.metric.reporters = []
	src.kafka.metrics.num.samples = 2
	src.kafka.metrics.sample.window.ms = 30000
	src.kafka.receive.buffer.bytes = 65536
	src.kafka.reconnect.backoff.ms = 50
	src.kafka.request.timeout.ms = 20000
	src.kafka.retry.backoff.ms = 100
	src.kafka.sasl.client.callback.handler.class = null
	src.kafka.sasl.jaas.config = null
	src.kafka.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	src.kafka.sasl.kerberos.min.time.before.relogin = 60000
	src.kafka.sasl.kerberos.service.name = null
	src.kafka.sasl.kerberos.ticket.renew.jitter = 0.05
	src.kafka.sasl.kerberos.ticket.renew.window.factor = 0.8
	src.kafka.sasl.login.callback.handler.class = null
	src.kafka.sasl.login.class = null
	src.kafka.sasl.login.connect.timeout.ms = null
	src.kafka.sasl.login.read.timeout.ms = null
	src.kafka.sasl.login.refresh.buffer.seconds = 300
	src.kafka.sasl.login.refresh.min.period.seconds = 60
	src.kafka.sasl.login.refresh.window.factor = 0.8
	src.kafka.sasl.login.refresh.window.jitter = 0.05
	src.kafka.sasl.login.retry.backoff.max.ms = 10000
	src.kafka.sasl.login.retry.backoff.ms = 100
	src.kafka.sasl.mechanism = GSSAPI
	src.kafka.sasl.oauthbearer.clock.skew.seconds = 30
	src.kafka.sasl.oauthbearer.expected.audience = null
	src.kafka.sasl.oauthbearer.expected.issuer = null
	src.kafka.sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	src.kafka.sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	src.kafka.sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	src.kafka.sasl.oauthbearer.jwks.endpoint.url = null
	src.kafka.sasl.oauthbearer.scope.claim.name = scope
	src.kafka.sasl.oauthbearer.sub.claim.name = sub
	src.kafka.sasl.oauthbearer.token.endpoint.url = null
	src.kafka.security.protocol = PLAINTEXT
	src.kafka.send.buffer.bytes = 131072
	src.kafka.ssl.cipher.suites = null
	src.kafka.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	src.kafka.ssl.endpoint.identification.algorithm = https
	src.kafka.ssl.engine.factory.class = null
	src.kafka.ssl.key.password = null
	src.kafka.ssl.keymanager.algorithm = SunX509
	src.kafka.ssl.keystore.certificate.chain = null
	src.kafka.ssl.keystore.key = null
	src.kafka.ssl.keystore.location = null
	src.kafka.ssl.keystore.password = null
	src.kafka.ssl.keystore.type = JKS
	src.kafka.ssl.protocol = TLSv1.3
	src.kafka.ssl.provider = null
	src.kafka.ssl.secure.random.implementation = null
	src.kafka.ssl.trustmanager.algorithm = PKIX
	src.kafka.ssl.truststore.certificates = null
	src.kafka.ssl.truststore.location = null
	src.kafka.ssl.truststore.password = null
	src.kafka.ssl.truststore.type = JKS
	src.key.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	src.value.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	task.id = replicator-cloud-0
	topic.auto.create = true
	topic.blacklist = []
	topic.config.sync = true
	topic.config.sync.interval.ms = 120000
	topic.create.backoff.ms = 120000
	topic.poll.interval.ms = 120000
	topic.preserve.partitions = true
	topic.regex = .*
	topic.rename.format = ${topic}
	topic.timestamp.type = CreateTime
	topic.whitelist = []
	value.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
 (io.confluent.connect.replicator.ReplicatorSourceTaskConfig:370)
[2024-02-05 13:46:31,877] INFO [Worker clientId=connect-1, groupId=connect-cluster] Tasks [replicator-cloud-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2241)
[2024-02-05 13:46:32,302] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:231)
[2024-02-05 13:46:32,303] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:576)
[2024-02-05 13:46:32,511] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=7, memberId='connect-1-5626c631-09b4-4bc6-b13c-f89c6adf07d0', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:637)
[2024-02-05 13:46:32,730] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=7, memberId='connect-1-5626c631-09b4-4bc6-b13c-f89c6adf07d0', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:812)
[2024-02-05 13:46:32,731] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 7 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-5626c631-09b4-4bc6-b13c-f89c6adf07d0', leaderUrl='http://127.0.1.1:8083/', offset=5, connectorIds=[replicator-cloud], taskIds=[replicator-cloud-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2416)
[2024-02-05 13:46:32,735] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 5 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1776)
[2024-02-05 13:46:32,736] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting task replicator-cloud-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1818)
[2024-02-05 13:46:32,762] INFO [replicator-cloud|task-0] Creating task replicator-cloud-0 (org.apache.kafka.connect.runtime.Worker:765)
[2024-02-05 13:46:32,766] INFO [replicator-cloud|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.replicator.ReplicatorSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	name = replicator-cloud
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:370)
[2024-02-05 13:46:32,767] INFO [replicator-cloud|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.replicator.ReplicatorSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	name = replicator-cloud
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:370)
[2024-02-05 13:46:32,778] INFO [replicator-cloud|task-0] TaskConfig values: 
	task.class = class io.confluent.connect.replicator.ReplicatorSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:370)
[2024-02-05 13:46:32,797] INFO [replicator-cloud|task-0] Instantiated task replicator-cloud-0 with version 7.5.2 of type io.confluent.connect.replicator.ReplicatorSourceTask (org.apache.kafka.connect.runtime.Worker:779)
[2024-02-05 13:46:32,801] INFO [replicator-cloud|task-0] Set up the key converter class io.confluent.connect.replicator.util.ByteArrayConverter for task replicator-cloud-0 using the connector config (org.apache.kafka.connect.runtime.Worker:797)
[2024-02-05 13:46:32,801] INFO [replicator-cloud|task-0] Set up the value converter class io.confluent.connect.replicator.util.ByteArrayConverter for task replicator-cloud-0 using the connector config (org.apache.kafka.connect.runtime.Worker:803)
[2024-02-05 13:46:32,801] INFO [replicator-cloud|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task replicator-cloud-0 using the worker config (org.apache.kafka.connect.runtime.Worker:809)
[2024-02-05 13:46:32,812] INFO [replicator-cloud|task-0] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.replicator.ReplicatorSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	name = replicator-cloud
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:370)
[2024-02-05 13:46:32,812] INFO [replicator-cloud|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.replicator.ReplicatorSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	name = replicator-cloud
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:370)
[2024-02-05 13:46:32,813] INFO [replicator-cloud|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1758)
[2024-02-05 13:46:32,814] INFO [replicator-cloud|task-0] ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [pkc-4r087.us-west2.gcp.confluent.cloud:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-replicator-cloud-0
	compression.type = none
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retries = 2147483647
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:370)
[2024-02-05 13:46:32,821] INFO [replicator-cloud|task-0] These configurations '[metrics.context.resource.connector, metrics.context.resource.version, metrics.context.connect.group.id, metrics.context.resource.type, metrics.context.resource.commit.id, metrics.context.resource.task, metrics.context.connect.kafka.cluster.id]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:379)
[2024-02-05 13:46:32,821] INFO [replicator-cloud|task-0] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:46:32,821] INFO [replicator-cloud|task-0] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:46:32,821] INFO [replicator-cloud|task-0] Kafka startTimeMs: 1707120992821 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:46:32,824] INFO [replicator-cloud|task-0] AbstractConfig values: 
	trace.records.enable = false
	trace.records.header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	trace.records.key.converter = class org.apache.kafka.connect.json.JsonConverter
	trace.records.predicates = []
	trace.records.topic = connect-traces
	trace.records.topic.partition = 1
	trace.records.topic.replication.factor = 3
	trace.records.transforms = []
	trace.records.value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.common.config.AbstractConfig:370)
[2024-02-05 13:46:32,825] INFO [replicator-cloud|task-0] TracerConfig values: 
	trace.records.enable = false
	trace.records.header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	trace.records.key.converter = class org.apache.kafka.connect.json.JsonConverter
	trace.records.predicates = []
	trace.records.topic = connect-traces
	trace.records.topic.partition = 1
	trace.records.topic.replication.factor = 3
	trace.records.transforms = []
	trace.records.value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.tracing.TracerConfig:370)
[2024-02-05 13:46:32,826] INFO [replicator-cloud|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1790)
[2024-02-05 13:46:32,841] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1804)
[2024-02-05 13:46:32,843] INFO [replicator-cloud|task-0] ReplicatorSourceTaskConfig values: 
	confluent.license = [hidden]
	confluent.topic = _confluent-command
	consumer.poll.timeout.interval.ms = 5000
	dest.kafka.bootstrap.servers = [pkc-4r087.us-west2.gcp.confluent.cloud:9092]
	dest.kafka.client.id = 
	dest.kafka.connections.max.idle.ms = 540000
	dest.kafka.metric.reporters = []
	dest.kafka.metrics.num.samples = 2
	dest.kafka.metrics.sample.window.ms = 30000
	dest.kafka.receive.buffer.bytes = 65536
	dest.kafka.reconnect.backoff.ms = 50
	dest.kafka.request.timeout.ms = 20000
	dest.kafka.retry.backoff.ms = 500
	dest.kafka.sasl.client.callback.handler.class = null
	dest.kafka.sasl.jaas.config = [hidden]
	dest.kafka.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	dest.kafka.sasl.kerberos.min.time.before.relogin = 60000
	dest.kafka.sasl.kerberos.service.name = null
	dest.kafka.sasl.kerberos.ticket.renew.jitter = 0.05
	dest.kafka.sasl.kerberos.ticket.renew.window.factor = 0.8
	dest.kafka.sasl.login.callback.handler.class = null
	dest.kafka.sasl.login.class = null
	dest.kafka.sasl.login.connect.timeout.ms = null
	dest.kafka.sasl.login.read.timeout.ms = null
	dest.kafka.sasl.login.refresh.buffer.seconds = 300
	dest.kafka.sasl.login.refresh.min.period.seconds = 60
	dest.kafka.sasl.login.refresh.window.factor = 0.8
	dest.kafka.sasl.login.refresh.window.jitter = 0.05
	dest.kafka.sasl.login.retry.backoff.max.ms = 10000
	dest.kafka.sasl.login.retry.backoff.ms = 100
	dest.kafka.sasl.mechanism = PLAIN
	dest.kafka.sasl.oauthbearer.clock.skew.seconds = 30
	dest.kafka.sasl.oauthbearer.expected.audience = null
	dest.kafka.sasl.oauthbearer.expected.issuer = null
	dest.kafka.sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	dest.kafka.sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	dest.kafka.sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	dest.kafka.sasl.oauthbearer.jwks.endpoint.url = null
	dest.kafka.sasl.oauthbearer.scope.claim.name = scope
	dest.kafka.sasl.oauthbearer.sub.claim.name = sub
	dest.kafka.sasl.oauthbearer.token.endpoint.url = null
	dest.kafka.security.protocol = SASL_SSL
	dest.kafka.send.buffer.bytes = 131072
	dest.kafka.ssl.cipher.suites = null
	dest.kafka.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	dest.kafka.ssl.endpoint.identification.algorithm = https
	dest.kafka.ssl.engine.factory.class = null
	dest.kafka.ssl.key.password = null
	dest.kafka.ssl.keymanager.algorithm = SunX509
	dest.kafka.ssl.keystore.certificate.chain = null
	dest.kafka.ssl.keystore.key = null
	dest.kafka.ssl.keystore.location = null
	dest.kafka.ssl.keystore.password = null
	dest.kafka.ssl.keystore.type = JKS
	dest.kafka.ssl.protocol = TLSv1.3
	dest.kafka.ssl.provider = null
	dest.kafka.ssl.secure.random.implementation = null
	dest.kafka.ssl.trustmanager.algorithm = PKIX
	dest.kafka.ssl.truststore.certificates = null
	dest.kafka.ssl.truststore.location = null
	dest.kafka.ssl.truststore.password = null
	dest.kafka.ssl.truststore.type = JKS
	dest.topic.replication.factor = 3
	header.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	key.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	offset.start = connect
	offset.timestamps.commit = true
	offset.topic.commit = true
	offset.topic.commit.batch.period.ms = 60000
	offset.translator.batch.period.ms = 60000
	offset.translator.batch.size = 2147483647
	offset.translator.tasks.max = -1
	offset.translator.tasks.separate = false
	partition.assignment = AAMAAAAeABVfX2NvbnN1bWVyX3RpbWVzdGFtcHMAAAAyAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAFAAAABgAAAAcAAAAIAAAACQAAAAoAAAALAAAADAAAAA0AAAAOAAAADwAAABAAAAARAAAAEgAAABMAAAAUAAAAFQAAABYAAAAXAAAAGAAAABkAAAAaAAAAGwAAABwAAAAdAAAAHgAAAB8AAAAgAAAAIQAAACIAAAAjAAAAJAAAACUAAAAmAAAAJwAAACgAAAApAAAAKgAAACsAAAAsAAAALQAAAC4AAAAvAAAAMAAAADEAEl9jb25mbHVlbnQtY29tbWFuZAAAAAEAAAAAABxfY29uZmx1ZW50LXRlbGVtZXRyeS1tZXRyaWNzAAAADAAAAAAAAAABAAAAAgAAAAMAAAAEAAAABQAAAAYAAAAHAAAACAAAAAkAAAAKAAAACwAdX2NvbmZsdWVudF9iYWxhbmNlcl9hcGlfc3RhdGUAAAABAAAAAAASX2Rla19yZWdpc3RyeV9rZXlzAAAAAQAAAAAAEF9zY2hlbWFfZW5jb2RlcnMAAAABAAAAAAAIX3NjaGVtYXMAAAABAAAAAAAPY29ubmVjdC1jb25maWdzAAAAAQAAAAAAD2Nvbm5lY3Qtb2Zmc2V0cwAAABkAAAAAAAAAAQAAAAIAAAADAAAABAAAAAUAAAAGAAAABwAAAAgAAAAJAAAACgAAAAsAAAAMAAAADQAAAA4AAAAPAAAAEAAAABEAAAASAAAAEwAAABQAAAAVAAAAFgAAABcAAAAYAA5jb25uZWN0LXN0YXR1cwAAAAUAAAAAAAAAAQAAAAIAAAADAAAABAALaW5wdXRfdG9waWMAAAABAAAAAAAva2Fma2Etc3RyZWFtcy1hZ2dyZWdhdGlvbi1jb3VudC1zdG9yZS1jaGFuZ2Vsb2cAAAABAAAAAAAIbXlfdG9waWMAAAABAAAAAAAMb3V0cHV0X3RvcGljAAAAAQAAAAAADXBvc3RncmVzLWRhdGEAAAABAAAAAAARcG9zdGdyZXMtdXNlcmRhdGEAAAABAAAAAAAZcG9zdGdyZXMtdXNlcmRhdGEtcmVwbGljYQAAAAEAAAAAAANzZ3IAAAABAAAAAAAKc3RyZWFtX2ludAAAAAEAAAAAAD1zdHJlYW1faW50LUtTVFJFQU0tQUdHUkVHQVRFLVNUQVRFLVNUT1JFLTAwMDAwMDAwMDEtY2hhbmdlbG9nAAAAAQAAAAAACXN0cmVhbV9pcAAAAAEAAAAAADxzdHJlYW1faXAtS1NUUkVBTS1BR0dSRUdBVEUtU1RBVEUtU1RPUkUtMDAwMDAwMDAwMS1jaGFuZ2Vsb2cAAAABAAAAAAAfc3RyZWFtX2lwLWNvdW50LXN0b3JlLWNoYW5nZWxvZwAAAAEAAAAAAApzdHJlYW1fbmV3AAAAAQAAAAAAC3N0cmVhbV9uZXcxAAAAAQAAAAAACnN0cmVhbV9vcDEAAAABAAAAAAAKc3RyZWFtX29wMgAAAAEAAAAAAApzdHJlYW1fb3AzAAAAAQAAAAAADHN0cmVhbV9vcG5ldwAAAAEAAAAAAApzdHJlYW1fb3B0AAAAAQAAAAD/////
	provenance.header.enable = false
	provenance.header.filter.overrides = 
	schema.registry.client.basic.auth.credentials.source = URL
	schema.registry.client.basic.auth.user.info = [hidden]
	schema.registry.max.schemas.per.subject = 1000
	schema.registry.topic = null
	schema.registry.url = null
	schema.subject.translator.class = null
	src.consumer.check.crcs = true
	src.consumer.fetch.max.bytes = 52428800
	src.consumer.fetch.max.wait.ms = 500
	src.consumer.fetch.min.bytes = 1
	src.consumer.interceptor.classes = []
	src.consumer.max.partition.fetch.bytes = 1048576
	src.consumer.max.poll.interval.ms = 300000
	src.consumer.max.poll.records = 500
	src.header.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	src.kafka.bootstrap.servers = [localhost:9092]
	src.kafka.client.id = 
	src.kafka.connections.max.idle.ms = 540000
	src.kafka.metric.reporters = []
	src.kafka.metrics.num.samples = 2
	src.kafka.metrics.sample.window.ms = 30000
	src.kafka.receive.buffer.bytes = 65536
	src.kafka.reconnect.backoff.ms = 50
	src.kafka.request.timeout.ms = 20000
	src.kafka.retry.backoff.ms = 100
	src.kafka.sasl.client.callback.handler.class = null
	src.kafka.sasl.jaas.config = null
	src.kafka.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	src.kafka.sasl.kerberos.min.time.before.relogin = 60000
	src.kafka.sasl.kerberos.service.name = null
	src.kafka.sasl.kerberos.ticket.renew.jitter = 0.05
	src.kafka.sasl.kerberos.ticket.renew.window.factor = 0.8
	src.kafka.sasl.login.callback.handler.class = null
	src.kafka.sasl.login.class = null
	src.kafka.sasl.login.connect.timeout.ms = null
	src.kafka.sasl.login.read.timeout.ms = null
	src.kafka.sasl.login.refresh.buffer.seconds = 300
	src.kafka.sasl.login.refresh.min.period.seconds = 60
	src.kafka.sasl.login.refresh.window.factor = 0.8
	src.kafka.sasl.login.refresh.window.jitter = 0.05
	src.kafka.sasl.login.retry.backoff.max.ms = 10000
	src.kafka.sasl.login.retry.backoff.ms = 100
	src.kafka.sasl.mechanism = GSSAPI
	src.kafka.sasl.oauthbearer.clock.skew.seconds = 30
	src.kafka.sasl.oauthbearer.expected.audience = null
	src.kafka.sasl.oauthbearer.expected.issuer = null
	src.kafka.sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	src.kafka.sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	src.kafka.sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	src.kafka.sasl.oauthbearer.jwks.endpoint.url = null
	src.kafka.sasl.oauthbearer.scope.claim.name = scope
	src.kafka.sasl.oauthbearer.sub.claim.name = sub
	src.kafka.sasl.oauthbearer.token.endpoint.url = null
	src.kafka.security.protocol = PLAINTEXT
	src.kafka.send.buffer.bytes = 131072
	src.kafka.ssl.cipher.suites = null
	src.kafka.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	src.kafka.ssl.endpoint.identification.algorithm = https
	src.kafka.ssl.engine.factory.class = null
	src.kafka.ssl.key.password = null
	src.kafka.ssl.keymanager.algorithm = SunX509
	src.kafka.ssl.keystore.certificate.chain = null
	src.kafka.ssl.keystore.key = null
	src.kafka.ssl.keystore.location = null
	src.kafka.ssl.keystore.password = null
	src.kafka.ssl.keystore.type = JKS
	src.kafka.ssl.protocol = TLSv1.3
	src.kafka.ssl.provider = null
	src.kafka.ssl.secure.random.implementation = null
	src.kafka.ssl.trustmanager.algorithm = PKIX
	src.kafka.ssl.truststore.certificates = null
	src.kafka.ssl.truststore.location = null
	src.kafka.ssl.truststore.password = null
	src.kafka.ssl.truststore.type = JKS
	src.key.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	src.value.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	task.id = replicator-cloud-0
	topic.auto.create = true
	topic.blacklist = []
	topic.config.sync = true
	topic.config.sync.interval.ms = 120000
	topic.create.backoff.ms = 120000
	topic.poll.interval.ms = 120000
	topic.preserve.partitions = true
	topic.regex = .*
	topic.rename.format = ${topic}
	topic.timestamp.type = CreateTime
	topic.whitelist = []
	value.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
 (io.confluent.connect.replicator.ReplicatorSourceTaskConfig:370)
[2024-02-05 13:46:32,843] INFO [replicator-cloud|task-0] Starting Replicator source task replicator-cloud-0 (io.confluent.connect.replicator.ReplicatorSourceTask:314)
[2024-02-05 13:46:32,847] INFO [replicator-cloud|task-0] AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [pkc-4r087.us-west2.gcp.confluent.cloud:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	confluent.lkc.id = null
	confluent.metrics.reporter.bootstrap.servers = kafka-0:9071
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	confluent.use.controller.listener = false
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	host.resolver.class = class org.apache.kafka.clients.DefaultHostResolver
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retries = 2147483647
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:370)
[2024-02-05 13:46:32,851] INFO [replicator-cloud|task-0] Successfully logged in. (org.apache.kafka.common.security.authenticator.AbstractLogin:61)
[2024-02-05 13:46:32,853] INFO [replicator-cloud|task-0] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:46:32,853] INFO [replicator-cloud|task-0] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:46:32,853] INFO [replicator-cloud|task-0] Kafka startTimeMs: 1707120992853 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:46:32,858] INFO [replicator-cloud|task-0] AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	confluent.lkc.id = null
	confluent.metrics.reporter.bootstrap.servers = kafka-0:9071
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	confluent.use.controller.listener = false
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	host.resolver.class = class org.apache.kafka.clients.DefaultHostResolver
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:370)
[2024-02-05 13:46:32,861] INFO [replicator-cloud|task-0] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:46:32,861] INFO [replicator-cloud|task-0] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:46:32,861] INFO [replicator-cloud|task-0] Kafka startTimeMs: 1707120992861 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:46:35,552] INFO [replicator-cloud|task-0] [Producer clientId=connector-producer-replicator-cloud-0] Cluster ID: lkc-qpjpkm (org.apache.kafka.clients.Metadata:287)
[2024-02-05 13:46:38,819] INFO [replicator-cloud|task-0] Source cluster ID: xq-PEpqTSoutAwe9O2TUvQ (io.confluent.connect.replicator.ReplicatorSourceTask:436)
[2024-02-05 13:46:38,820] INFO [replicator-cloud|task-0] Destination cluster ID: lkc-qpjpkm (io.confluent.connect.replicator.ReplicatorSourceTask:437)
[2024-02-05 13:46:38,821] INFO [replicator-cloud|task-0] ConsumerConfig values: 
	allow.auto.create.topics = false
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = replicator-cloud-0
	client.rack = 
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = replicator-cloud
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:370)
[2024-02-05 13:46:38,825] INFO [replicator-cloud|task-0] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:46:38,825] INFO [replicator-cloud|task-0] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:46:38,825] INFO [replicator-cloud|task-0] Kafka startTimeMs: 1707120998825 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:46:38,831] INFO [replicator-cloud|task-0] ConsumerOffsetsTranslatorConfig values: 
	confluent.license = [hidden]
	confluent.topic = _confluent-command
	consumer.poll.timeout.interval.ms = 5000
	dest.kafka.bootstrap.servers = [pkc-4r087.us-west2.gcp.confluent.cloud:9092]
	dest.kafka.client.id = 
	dest.kafka.connections.max.idle.ms = 540000
	dest.kafka.metric.reporters = []
	dest.kafka.metrics.num.samples = 2
	dest.kafka.metrics.sample.window.ms = 30000
	dest.kafka.receive.buffer.bytes = 65536
	dest.kafka.reconnect.backoff.ms = 50
	dest.kafka.request.timeout.ms = 20000
	dest.kafka.retry.backoff.ms = 500
	dest.kafka.sasl.client.callback.handler.class = null
	dest.kafka.sasl.jaas.config = [hidden]
	dest.kafka.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	dest.kafka.sasl.kerberos.min.time.before.relogin = 60000
	dest.kafka.sasl.kerberos.service.name = null
	dest.kafka.sasl.kerberos.ticket.renew.jitter = 0.05
	dest.kafka.sasl.kerberos.ticket.renew.window.factor = 0.8
	dest.kafka.sasl.login.callback.handler.class = null
	dest.kafka.sasl.login.class = null
	dest.kafka.sasl.login.connect.timeout.ms = null
	dest.kafka.sasl.login.read.timeout.ms = null
	dest.kafka.sasl.login.refresh.buffer.seconds = 300
	dest.kafka.sasl.login.refresh.min.period.seconds = 60
	dest.kafka.sasl.login.refresh.window.factor = 0.8
	dest.kafka.sasl.login.refresh.window.jitter = 0.05
	dest.kafka.sasl.login.retry.backoff.max.ms = 10000
	dest.kafka.sasl.login.retry.backoff.ms = 100
	dest.kafka.sasl.mechanism = PLAIN
	dest.kafka.sasl.oauthbearer.clock.skew.seconds = 30
	dest.kafka.sasl.oauthbearer.expected.audience = null
	dest.kafka.sasl.oauthbearer.expected.issuer = null
	dest.kafka.sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	dest.kafka.sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	dest.kafka.sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	dest.kafka.sasl.oauthbearer.jwks.endpoint.url = null
	dest.kafka.sasl.oauthbearer.scope.claim.name = scope
	dest.kafka.sasl.oauthbearer.sub.claim.name = sub
	dest.kafka.sasl.oauthbearer.token.endpoint.url = null
	dest.kafka.security.protocol = SASL_SSL
	dest.kafka.send.buffer.bytes = 131072
	dest.kafka.ssl.cipher.suites = null
	dest.kafka.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	dest.kafka.ssl.endpoint.identification.algorithm = https
	dest.kafka.ssl.engine.factory.class = null
	dest.kafka.ssl.key.password = null
	dest.kafka.ssl.keymanager.algorithm = SunX509
	dest.kafka.ssl.keystore.certificate.chain = null
	dest.kafka.ssl.keystore.key = null
	dest.kafka.ssl.keystore.location = null
	dest.kafka.ssl.keystore.password = null
	dest.kafka.ssl.keystore.type = JKS
	dest.kafka.ssl.protocol = TLSv1.3
	dest.kafka.ssl.provider = null
	dest.kafka.ssl.secure.random.implementation = null
	dest.kafka.ssl.trustmanager.algorithm = PKIX
	dest.kafka.ssl.truststore.certificates = null
	dest.kafka.ssl.truststore.location = null
	dest.kafka.ssl.truststore.password = null
	dest.kafka.ssl.truststore.type = JKS
	dest.topic.replication.factor = 3
	fetch.offset.expiry.ms = 600000
	fetch.offset.retry.backoff.ms = 100
	header.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	key.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	offset.start = connect
	offset.timestamps.commit = true
	offset.topic.commit = true
	offset.topic.commit.batch.period.ms = 60000
	offset.translator.batch.period.ms = 60000
	offset.translator.batch.size = 2147483647
	offset.translator.tasks.max = -1
	offset.translator.tasks.separate = false
	provenance.header.enable = false
	provenance.header.filter.overrides = 
	schema.registry.client.basic.auth.credentials.source = URL
	schema.registry.client.basic.auth.user.info = [hidden]
	schema.registry.max.schemas.per.subject = 1000
	schema.registry.topic = null
	schema.registry.url = null
	schema.subject.translator.class = null
	src.consumer.check.crcs = true
	src.consumer.fetch.max.bytes = 52428800
	src.consumer.fetch.max.wait.ms = 500
	src.consumer.fetch.min.bytes = 1
	src.consumer.interceptor.classes = []
	src.consumer.max.partition.fetch.bytes = 1048576
	src.consumer.max.poll.interval.ms = 300000
	src.consumer.max.poll.records = 500
	src.header.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	src.kafka.bootstrap.servers = [localhost:9092]
	src.kafka.client.id = 
	src.kafka.connections.max.idle.ms = 540000
	src.kafka.metric.reporters = []
	src.kafka.metrics.num.samples = 2
	src.kafka.metrics.sample.window.ms = 30000
	src.kafka.receive.buffer.bytes = 65536
	src.kafka.reconnect.backoff.ms = 50
	src.kafka.request.timeout.ms = 20000
	src.kafka.retry.backoff.ms = 100
	src.kafka.sasl.client.callback.handler.class = null
	src.kafka.sasl.jaas.config = null
	src.kafka.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	src.kafka.sasl.kerberos.min.time.before.relogin = 60000
	src.kafka.sasl.kerberos.service.name = null
	src.kafka.sasl.kerberos.ticket.renew.jitter = 0.05
	src.kafka.sasl.kerberos.ticket.renew.window.factor = 0.8
	src.kafka.sasl.login.callback.handler.class = null
	src.kafka.sasl.login.class = null
	src.kafka.sasl.login.connect.timeout.ms = null
	src.kafka.sasl.login.read.timeout.ms = null
	src.kafka.sasl.login.refresh.buffer.seconds = 300
	src.kafka.sasl.login.refresh.min.period.seconds = 60
	src.kafka.sasl.login.refresh.window.factor = 0.8
	src.kafka.sasl.login.refresh.window.jitter = 0.05
	src.kafka.sasl.login.retry.backoff.max.ms = 10000
	src.kafka.sasl.login.retry.backoff.ms = 100
	src.kafka.sasl.mechanism = GSSAPI
	src.kafka.sasl.oauthbearer.clock.skew.seconds = 30
	src.kafka.sasl.oauthbearer.expected.audience = null
	src.kafka.sasl.oauthbearer.expected.issuer = null
	src.kafka.sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	src.kafka.sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	src.kafka.sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	src.kafka.sasl.oauthbearer.jwks.endpoint.url = null
	src.kafka.sasl.oauthbearer.scope.claim.name = scope
	src.kafka.sasl.oauthbearer.sub.claim.name = sub
	src.kafka.sasl.oauthbearer.token.endpoint.url = null
	src.kafka.security.protocol = PLAINTEXT
	src.kafka.send.buffer.bytes = 131072
	src.kafka.ssl.cipher.suites = null
	src.kafka.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	src.kafka.ssl.endpoint.identification.algorithm = https
	src.kafka.ssl.engine.factory.class = null
	src.kafka.ssl.key.password = null
	src.kafka.ssl.keymanager.algorithm = SunX509
	src.kafka.ssl.keystore.certificate.chain = null
	src.kafka.ssl.keystore.key = null
	src.kafka.ssl.keystore.location = null
	src.kafka.ssl.keystore.password = null
	src.kafka.ssl.keystore.type = JKS
	src.kafka.ssl.protocol = TLSv1.3
	src.kafka.ssl.provider = null
	src.kafka.ssl.secure.random.implementation = null
	src.kafka.ssl.trustmanager.algorithm = PKIX
	src.kafka.ssl.truststore.certificates = null
	src.kafka.ssl.truststore.location = null
	src.kafka.ssl.truststore.password = null
	src.kafka.ssl.truststore.type = JKS
	src.key.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	src.value.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	topic.auto.create = true
	topic.blacklist = []
	topic.config.sync = true
	topic.config.sync.interval.ms = 120000
	topic.create.backoff.ms = 120000
	topic.poll.interval.ms = 120000
	topic.preserve.partitions = true
	topic.regex = .*
	topic.rename.format = ${topic}
	topic.timestamp.type = CreateTime
	topic.whitelist = []
	value.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
 (io.confluent.connect.replicator.offsets.ConsumerOffsetsTranslatorConfig:370)
[2024-02-05 13:46:38,834] INFO [replicator-cloud|task-0] Requesting metadata refresh after 1 new topics were added (io.confluent.connect.replicator.util.ReplicatorAdminClient:254)
[2024-02-05 13:46:38,835] INFO [replicator-cloud|task-0] ConsumerTimestampsWriterConfig values: 
	timestamps.producer.max.per.partition = 2147483647
	timestamps.producer.topic.blacklist = []
	timestamps.producer.topic.regex = null
	timestamps.producer.topic.whitelist = null
	timestamps.topic.num.partitions = 50
	timestamps.topic.replication.factor = 3
 (io.confluent.connect.replicator.offsets.ConsumerTimestampsWriterConfig:370)
[2024-02-05 13:46:38,842] INFO [replicator-cloud|task-0] ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-2
	compression.type = lz4
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class io.confluent.connect.replicator.offsets.GroupTopicPartitionSerializer
	linger.ms = 500
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 10485760
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retries = 2147483647
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class io.confluent.connect.replicator.offsets.TimestampAndDeltaSerializer
 (org.apache.kafka.clients.producer.ProducerConfig:370)
[2024-02-05 13:46:38,864] INFO [replicator-cloud|task-0] [Producer clientId=producer-2] Instantiated an idempotent producer. (org.apache.kafka.clients.producer.KafkaProducer:596)
[2024-02-05 13:46:38,869] INFO [replicator-cloud|task-0] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:46:38,869] INFO [replicator-cloud|task-0] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:46:38,869] INFO [replicator-cloud|task-0] Kafka startTimeMs: 1707120998869 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:46:38,871] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Assigned to partition(s): __consumer_timestamps-0, __consumer_timestamps-1, __consumer_timestamps-2, __consumer_timestamps-3, __consumer_timestamps-4, __consumer_timestamps-5, __consumer_timestamps-6, __consumer_timestamps-7, __consumer_timestamps-8, __consumer_timestamps-9, __consumer_timestamps-10, __consumer_timestamps-11, __consumer_timestamps-12, __consumer_timestamps-13, __consumer_timestamps-14, __consumer_timestamps-15, __consumer_timestamps-16, __consumer_timestamps-17, __consumer_timestamps-18, __consumer_timestamps-19, __consumer_timestamps-20, __consumer_timestamps-21, __consumer_timestamps-22, __consumer_timestamps-23, __consumer_timestamps-24, __consumer_timestamps-25, __consumer_timestamps-26, __consumer_timestamps-27, __consumer_timestamps-28, __consumer_timestamps-29, __consumer_timestamps-30, __consumer_timestamps-31, __consumer_timestamps-32, __consumer_timestamps-33, __consumer_timestamps-34, __consumer_timestamps-35, __consumer_timestamps-36, __consumer_timestamps-37, __consumer_timestamps-38, __consumer_timestamps-39, __consumer_timestamps-40, __consumer_timestamps-41, __consumer_timestamps-42, __consumer_timestamps-43, __consumer_timestamps-44, __consumer_timestamps-45, __consumer_timestamps-46, __consumer_timestamps-47, __consumer_timestamps-48, __consumer_timestamps-49, _confluent-command-0, _confluent-telemetry-metrics-0, _confluent-telemetry-metrics-1, _confluent-telemetry-metrics-2, _confluent-telemetry-metrics-3, _confluent-telemetry-metrics-4, _confluent-telemetry-metrics-5, _confluent-telemetry-metrics-6, _confluent-telemetry-metrics-7, _confluent-telemetry-metrics-8, _confluent-telemetry-metrics-9, _confluent-telemetry-metrics-10, _confluent-telemetry-metrics-11, _confluent_balancer_api_state-0, _dek_registry_keys-0, _schema_encoders-0, _schemas-0, connect-configs-0, connect-offsets-0, connect-offsets-1, connect-offsets-2, connect-offsets-3, connect-offsets-4, connect-offsets-5, connect-offsets-6, connect-offsets-7, connect-offsets-8, connect-offsets-9, connect-offsets-10, connect-offsets-11, connect-offsets-12, connect-offsets-13, connect-offsets-14, connect-offsets-15, connect-offsets-16, connect-offsets-17, connect-offsets-18, connect-offsets-19, connect-offsets-20, connect-offsets-21, connect-offsets-22, connect-offsets-23, connect-offsets-24, connect-status-0, connect-status-1, connect-status-2, connect-status-3, connect-status-4, input_topic-0, kafka-streams-aggregation-count-store-changelog-0, my_topic-0, output_topic-0, postgres-data-0, postgres-userdata-0, postgres-userdata-replica-0, sgr-0, stream_int-0, stream_int-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog-0, stream_ip-0, stream_ip-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog-0, stream_ip-count-store-changelog-0, stream_new-0, stream_new1-0, stream_op1-0, stream_op2-0, stream_op3-0, stream_opnew-0, stream_opt-0 (org.apache.kafka.clients.consumer.KafkaConsumer:1135)
[2024-02-05 13:46:38,893] INFO [replicator-cloud|task-0] Requesting metadata refresh after 29 new topics were added (io.confluent.connect.replicator.util.ReplicatorAdminClient:254)
[2024-02-05 13:46:38,897] INFO [replicator-cloud|task-0] [Producer clientId=producer-2] Cluster ID: xq-PEpqTSoutAwe9O2TUvQ (org.apache.kafka.clients.Metadata:287)
[2024-02-05 13:46:38,898] INFO [replicator-cloud|task-0] [Producer clientId=producer-2] ProducerId set to 9001 with epoch 0 (org.apache.kafka.clients.producer.internals.TransactionManager:441)
[2024-02-05 13:46:39,669] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Cluster ID: xq-PEpqTSoutAwe9O2TUvQ (org.apache.kafka.clients.Metadata:287)
[2024-02-05 13:46:39,670] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Discovered group coordinator sumo-HP-EliteBook-840-G4:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:906)
[2024-02-05 13:46:39,680] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition __consumer_timestamps-15 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,680] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition connect-offsets-12 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,681] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition __consumer_timestamps-40 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,681] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition _confluent-telemetry-metrics-10 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,681] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition input_topic-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,681] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition __consumer_timestamps-23 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,681] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition connect-offsets-4 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,681] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition __consumer_timestamps-48 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,681] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition __consumer_timestamps-31 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,681] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition __consumer_timestamps-39 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,681] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition __consumer_timestamps-6 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,681] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition connect-status-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,682] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition _confluent-telemetry-metrics-1 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,682] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition connect-offsets-20 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,682] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition __consumer_timestamps-47 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,682] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition __consumer_timestamps-14 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,682] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition connect-offsets-13 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,682] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition _confluent-telemetry-metrics-9 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,682] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition stream_ip-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,682] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition __consumer_timestamps-22 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,682] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition connect-offsets-5 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,682] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition __consumer_timestamps-30 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,683] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition stream_ip-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,683] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition __consumer_timestamps-38 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,683] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition __consumer_timestamps-5 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,683] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition stream_op3-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,683] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition stream_op1-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,683] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition _confluent-telemetry-metrics-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,683] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition connect-offsets-21 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,683] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition stream_op2-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,683] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition connect-offsets-14 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,683] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition __consumer_timestamps-42 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,684] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition _confluent-telemetry-metrics-8 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,684] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition kafka-streams-aggregation-count-store-changelog-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,684] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition __consumer_timestamps-9 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,684] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition connect-offsets-6 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,684] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition __consumer_timestamps-17 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,684] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition stream_new1-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,684] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition _dek_registry_keys-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,684] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition postgres-userdata-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,684] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition __consumer_timestamps-25 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,685] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition _schema_encoders-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,685] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition connect-offsets-22 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,685] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition __consumer_timestamps-33 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,685] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition sgr-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,685] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition stream_ip-count-store-changelog-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,685] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition __consumer_timestamps-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,685] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition connect-offsets-7 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,685] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition _confluent-telemetry-metrics-7 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,685] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition postgres-userdata-replica-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,685] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition __consumer_timestamps-41 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,686] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition __consumer_timestamps-8 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,686] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition __consumer_timestamps-49 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,686] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition __consumer_timestamps-16 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,686] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition connect-offsets-23 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,686] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition __consumer_timestamps-24 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,686] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition __consumer_timestamps-7 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,686] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition connect-offsets-15 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,686] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition __consumer_timestamps-32 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,686] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition output_topic-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,686] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition connect-offsets-8 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,686] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition __consumer_timestamps-44 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,687] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition _confluent-telemetry-metrics-6 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,687] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition __consumer_timestamps-11 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,687] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition stream_int-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,687] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition stream_opnew-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,687] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition connect-offsets-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,687] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition __consumer_timestamps-19 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,687] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition connect-offsets-24 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,687] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition __consumer_timestamps-27 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,687] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition _confluent_balancer_api_state-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,687] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition connect-offsets-16 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,687] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition __consumer_timestamps-35 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,687] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition __consumer_timestamps-2 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,688] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition connect-status-4 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,688] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition connect-offsets-9 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,688] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition _schemas-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,688] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition _confluent-telemetry-metrics-5 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,688] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition __consumer_timestamps-43 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,688] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition __consumer_timestamps-10 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,688] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition connect-offsets-1 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,688] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition __consumer_timestamps-18 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,688] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition __consumer_timestamps-26 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,688] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition connect-offsets-17 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,688] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition __consumer_timestamps-34 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,689] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition __consumer_timestamps-1 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,689] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition connect-status-3 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,689] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition stream_int-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,689] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition connect-offsets-10 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,689] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition connect-configs-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,689] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition __consumer_timestamps-46 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,689] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition _confluent-telemetry-metrics-4 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,689] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition __consumer_timestamps-13 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,689] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition connect-offsets-2 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,689] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition __consumer_timestamps-21 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,689] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition __consumer_timestamps-29 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,690] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition connect-offsets-18 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,690] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition postgres-data-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,690] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition connect-status-2 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,690] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition __consumer_timestamps-37 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,690] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition __consumer_timestamps-4 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,690] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition _confluent-telemetry-metrics-3 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,690] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition __consumer_timestamps-45 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,690] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition __consumer_timestamps-12 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,690] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition connect-offsets-11 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,690] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition _confluent-telemetry-metrics-11 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,690] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition _confluent-command-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,691] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition __consumer_timestamps-20 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,691] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition stream_new-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,691] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition connect-offsets-3 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,691] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition __consumer_timestamps-28 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,691] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition connect-status-1 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,691] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition my_topic-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,691] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition __consumer_timestamps-36 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,691] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition stream_opt-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,691] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition __consumer_timestamps-3 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,691] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition _confluent-telemetry-metrics-2 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,691] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Found no committed offset for partition connect-offsets-19 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:46:39,693] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition __consumer_timestamps-15 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,693] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition connect-offsets-12 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,693] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition __consumer_timestamps-40 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,693] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition _confluent-telemetry-metrics-10 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,693] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition input_topic-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,694] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition __consumer_timestamps-23 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,694] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition connect-offsets-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,694] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition __consumer_timestamps-48 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,694] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition __consumer_timestamps-31 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,694] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition __consumer_timestamps-39 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,694] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition __consumer_timestamps-6 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,694] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition connect-status-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,694] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition connect-offsets-20 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,694] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition _confluent-telemetry-metrics-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,694] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition __consumer_timestamps-47 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,694] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition __consumer_timestamps-14 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,694] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition connect-offsets-13 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,695] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition _confluent-telemetry-metrics-9 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,695] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition stream_ip-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,695] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition __consumer_timestamps-22 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,695] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition connect-offsets-5 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,695] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition __consumer_timestamps-30 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,695] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition stream_ip-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,695] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition __consumer_timestamps-38 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,695] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition stream_op3-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,695] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition __consumer_timestamps-5 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,695] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition stream_op1-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,695] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition connect-offsets-21 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,695] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition stream_op2-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,695] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition _confluent-telemetry-metrics-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,695] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition connect-offsets-14 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,696] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition __consumer_timestamps-42 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,696] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition kafka-streams-aggregation-count-store-changelog-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,696] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition _confluent-telemetry-metrics-8 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,696] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition __consumer_timestamps-9 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,696] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition connect-offsets-6 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,696] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition __consumer_timestamps-17 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,696] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition stream_new1-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,696] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition _dek_registry_keys-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,696] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition postgres-userdata-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,696] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition __consumer_timestamps-25 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,696] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition _schema_encoders-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,696] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition connect-offsets-22 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,696] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition stream_ip-count-store-changelog-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,696] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition __consumer_timestamps-33 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,697] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition sgr-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,697] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition __consumer_timestamps-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,697] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition connect-offsets-7 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,697] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition _confluent-telemetry-metrics-7 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,697] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition postgres-userdata-replica-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,697] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition __consumer_timestamps-41 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,697] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition __consumer_timestamps-8 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,697] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition __consumer_timestamps-49 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,697] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition __consumer_timestamps-16 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,697] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition connect-offsets-23 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,697] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition __consumer_timestamps-24 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,697] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition __consumer_timestamps-7 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,697] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition connect-offsets-15 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,697] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition __consumer_timestamps-32 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,698] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition output_topic-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,698] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition connect-offsets-8 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,698] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition _confluent-telemetry-metrics-6 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,698] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition __consumer_timestamps-44 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,698] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition __consumer_timestamps-11 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,698] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition stream_int-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,698] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition stream_opnew-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,698] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition connect-offsets-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,698] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition __consumer_timestamps-19 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,698] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition connect-offsets-24 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,698] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition __consumer_timestamps-27 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,698] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition _confluent_balancer_api_state-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,699] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition connect-offsets-16 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,699] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition __consumer_timestamps-35 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,699] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition __consumer_timestamps-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,699] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition connect-status-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,699] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition connect-offsets-9 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,699] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition _schemas-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,699] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition _confluent-telemetry-metrics-5 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,699] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition __consumer_timestamps-43 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,699] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition __consumer_timestamps-10 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,699] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition connect-offsets-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,699] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition __consumer_timestamps-18 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,699] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition __consumer_timestamps-26 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,699] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition connect-offsets-17 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,699] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition __consumer_timestamps-34 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,700] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition connect-status-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,700] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition __consumer_timestamps-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,700] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition stream_int-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,700] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition connect-configs-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,700] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition connect-offsets-10 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,700] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition __consumer_timestamps-46 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,700] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition _confluent-telemetry-metrics-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,700] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition __consumer_timestamps-13 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,700] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition connect-offsets-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,700] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition __consumer_timestamps-21 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,700] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition __consumer_timestamps-29 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,700] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition postgres-data-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,700] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition connect-offsets-18 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,700] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition connect-status-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,701] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition __consumer_timestamps-37 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,702] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition __consumer_timestamps-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,702] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition _confluent-telemetry-metrics-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,702] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition __consumer_timestamps-45 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,702] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition __consumer_timestamps-12 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,703] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition connect-offsets-11 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,703] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition _confluent-telemetry-metrics-11 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,703] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition _confluent-command-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,703] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition __consumer_timestamps-20 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,703] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition stream_new-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,703] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition connect-offsets-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,703] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition __consumer_timestamps-28 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,703] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition connect-status-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,703] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition my_topic-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,703] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition __consumer_timestamps-36 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,703] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition stream_opt-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,703] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition __consumer_timestamps-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,703] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition connect-offsets-19 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,704] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Seeking to earliest offset of partition _confluent-telemetry-metrics-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:46:39,705] INFO [replicator-cloud|task-0] Started kafka replicator task replicator-cloud-0 replicating topic partitions [__consumer_timestamps-0, __consumer_timestamps-1, __consumer_timestamps-2, __consumer_timestamps-3, __consumer_timestamps-4, __consumer_timestamps-5, __consumer_timestamps-6, __consumer_timestamps-7, __consumer_timestamps-8, __consumer_timestamps-9, __consumer_timestamps-10, __consumer_timestamps-11, __consumer_timestamps-12, __consumer_timestamps-13, __consumer_timestamps-14, __consumer_timestamps-15, __consumer_timestamps-16, __consumer_timestamps-17, __consumer_timestamps-18, __consumer_timestamps-19, __consumer_timestamps-20, __consumer_timestamps-21, __consumer_timestamps-22, __consumer_timestamps-23, __consumer_timestamps-24, __consumer_timestamps-25, __consumer_timestamps-26, __consumer_timestamps-27, __consumer_timestamps-28, __consumer_timestamps-29, __consumer_timestamps-30, __consumer_timestamps-31, __consumer_timestamps-32, __consumer_timestamps-33, __consumer_timestamps-34, __consumer_timestamps-35, __consumer_timestamps-36, __consumer_timestamps-37, __consumer_timestamps-38, __consumer_timestamps-39, __consumer_timestamps-40, __consumer_timestamps-41, __consumer_timestamps-42, __consumer_timestamps-43, __consumer_timestamps-44, __consumer_timestamps-45, __consumer_timestamps-46, __consumer_timestamps-47, __consumer_timestamps-48, __consumer_timestamps-49, _confluent-command-0, _confluent-telemetry-metrics-0, _confluent-telemetry-metrics-1, _confluent-telemetry-metrics-2, _confluent-telemetry-metrics-3, _confluent-telemetry-metrics-4, _confluent-telemetry-metrics-5, _confluent-telemetry-metrics-6, _confluent-telemetry-metrics-7, _confluent-telemetry-metrics-8, _confluent-telemetry-metrics-9, _confluent-telemetry-metrics-10, _confluent-telemetry-metrics-11, _confluent_balancer_api_state-0, _dek_registry_keys-0, _schema_encoders-0, _schemas-0, connect-configs-0, connect-offsets-0, connect-offsets-1, connect-offsets-2, connect-offsets-3, connect-offsets-4, connect-offsets-5, connect-offsets-6, connect-offsets-7, connect-offsets-8, connect-offsets-9, connect-offsets-10, connect-offsets-11, connect-offsets-12, connect-offsets-13, connect-offsets-14, connect-offsets-15, connect-offsets-16, connect-offsets-17, connect-offsets-18, connect-offsets-19, connect-offsets-20, connect-offsets-21, connect-offsets-22, connect-offsets-23, connect-offsets-24, connect-status-0, connect-status-1, connect-status-2, connect-status-3, connect-status-4, input_topic-0, kafka-streams-aggregation-count-store-changelog-0, my_topic-0, output_topic-0, postgres-data-0, postgres-userdata-0, postgres-userdata-replica-0, sgr-0, stream_int-0, stream_int-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog-0, stream_ip-0, stream_ip-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog-0, stream_ip-count-store-changelog-0, stream_new-0, stream_new1-0, stream_op1-0, stream_op2-0, stream_op3-0, stream_opnew-0, stream_opt-0] (io.confluent.connect.replicator.ReplicatorSourceTask:390)
[2024-02-05 13:46:39,706] INFO [replicator-cloud|task-0] Setting up metrics recording for task replicator-cloud-0... (io.confluent.connect.replicator.ReplicatorSourceTask:395)
[2024-02-05 13:46:39,707] INFO [replicator-cloud|task-0] Registering Confluent Replicator metrics with JMX for task 'replicator-cloud-0' (io.confluent.connect.replicator.metrics.ConfluentReplicatorMetrics:60)
[2024-02-05 13:46:39,708] INFO [replicator-cloud|task-0] Successfully registered Confluent Replicator metrics with JMX for task 'replicator-cloud-0' (io.confluent.connect.replicator.metrics.ConfluentReplicatorMetrics:69)
[2024-02-05 13:46:39,762] INFO [replicator-cloud|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = confluent-replicator-end-offsets-consumer-client
	client.rack = 
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = confluent-replicator-end-offsets-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:370)
[2024-02-05 13:46:39,766] INFO [replicator-cloud|task-0] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:46:39,766] INFO [replicator-cloud|task-0] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:46:39,766] INFO [replicator-cloud|task-0] Kafka startTimeMs: 1707120999766 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:46:39,767] INFO [replicator-cloud|task-0] Successfully set up metrics recording for task replicator-cloud-0 (io.confluent.connect.replicator.ReplicatorSourceTask:402)
[2024-02-05 13:46:39,767] INFO [replicator-cloud|task-0] Successfully started up Replicator source task replicator-cloud-0 (io.confluent.connect.replicator.ReplicatorSourceTask:403)
[2024-02-05 13:46:39,768] INFO [replicator-cloud|task-0] WorkerSourceTask{id=replicator-cloud-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.AbstractWorkerSourceTask:284)
[2024-02-05 13:46:39,770] INFO [replicator-cloud|task-0] Fetching destination topic metadata for destination topic output_topic (io.confluent.connect.replicator.ReplicatorSourceTask:1128)
[2024-02-05 13:46:39,770] INFO [replicator-cloud|task-0] Fetching source topic configs for source topic output_topic (io.confluent.connect.replicator.ReplicatorSourceTask:1135)
[2024-02-05 13:46:39,774] INFO [replicator-cloud|task-0] Using user-specified replication factor of 3 for creating destination topic output_topic (io.confluent.connect.replicator.ReplicatorSourceTask:1151)
[2024-02-05 13:46:39,775] INFO [replicator-cloud|task-0] [Consumer clientId=confluent-replicator-end-offsets-consumer-client, groupId=confluent-replicator-end-offsets-consumer-group] Cluster ID: xq-PEpqTSoutAwe9O2TUvQ (org.apache.kafka.clients.Metadata:287)
[2024-02-05 13:46:39,990] INFO [replicator-cloud|task-0] Creating topic output_topic in destination cluster with 1 partitions and replication factor 3 (io.confluent.connect.replicator.ReplicatorSourceTask:1186)
[2024-02-05 13:46:39,991] INFO [replicator-cloud|task-0] Creating topic output_topic with Optional[1] partitions, replication factor Optional[3], and config {message.timestamp.type=CreateTime} (io.confluent.connect.replicator.util.ReplicatorAdminClient:340)
[2024-02-05 13:46:41,360] INFO 127.0.0.1 - - [05/Feb/2024:08:16:41 +0000] "GET /connectors HTTP/1.1" 200 20 "-" "curl/7.68.0" 5 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-02-05 13:46:41,963] INFO [replicator-cloud|task-0] Fetching destination topic metadata for destination topic kafka-streams-aggregation-count-store-changelog (io.confluent.connect.replicator.ReplicatorSourceTask:1128)
[2024-02-05 13:46:42,180] INFO [replicator-cloud|task-0] Fetching source topic configs for source topic kafka-streams-aggregation-count-store-changelog (io.confluent.connect.replicator.ReplicatorSourceTask:1135)
[2024-02-05 13:46:42,187] INFO [replicator-cloud|task-0] Using user-specified replication factor of 3 for creating destination topic kafka-streams-aggregation-count-store-changelog (io.confluent.connect.replicator.ReplicatorSourceTask:1151)
[2024-02-05 13:46:42,188] INFO [replicator-cloud|task-0] Creating topic kafka-streams-aggregation-count-store-changelog in destination cluster with 1 partitions and replication factor 3 (io.confluent.connect.replicator.ReplicatorSourceTask:1186)
[2024-02-05 13:46:42,188] INFO [replicator-cloud|task-0] Creating topic kafka-streams-aggregation-count-store-changelog with Optional[1] partitions, replication factor Optional[3], and config {cleanup.policy=compact,delete, message.timestamp.type=CreateTime, retention.ms=172800000} (io.confluent.connect.replicator.util.ReplicatorAdminClient:340)
[2024-02-05 13:46:42,770] INFO [replicator-cloud|task-0] Fetching destination topic metadata for destination topic input_topic (io.confluent.connect.replicator.ReplicatorSourceTask:1128)
[2024-02-05 13:46:42,987] INFO [replicator-cloud|task-0] Fetching source topic configs for source topic input_topic (io.confluent.connect.replicator.ReplicatorSourceTask:1135)
[2024-02-05 13:46:42,990] INFO [replicator-cloud|task-0] Using user-specified replication factor of 3 for creating destination topic input_topic (io.confluent.connect.replicator.ReplicatorSourceTask:1151)
[2024-02-05 13:46:42,990] INFO [replicator-cloud|task-0] Creating topic input_topic in destination cluster with 1 partitions and replication factor 3 (io.confluent.connect.replicator.ReplicatorSourceTask:1186)
[2024-02-05 13:46:42,991] INFO [replicator-cloud|task-0] Creating topic input_topic with Optional[1] partitions, replication factor Optional[3], and config {message.timestamp.type=CreateTime} (io.confluent.connect.replicator.util.ReplicatorAdminClient:340)
[2024-02-05 13:46:43,664] INFO [replicator-cloud|task-0] Fetching destination topic metadata for destination topic stream_int-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog (io.confluent.connect.replicator.ReplicatorSourceTask:1128)
[2024-02-05 13:46:44,226] INFO [replicator-cloud|task-0] Fetching source topic configs for source topic stream_int-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog (io.confluent.connect.replicator.ReplicatorSourceTask:1135)
[2024-02-05 13:46:44,233] INFO [replicator-cloud|task-0] Using user-specified replication factor of 3 for creating destination topic stream_int-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog (io.confluent.connect.replicator.ReplicatorSourceTask:1151)
[2024-02-05 13:46:44,234] INFO [replicator-cloud|task-0] Creating topic stream_int-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog in destination cluster with 1 partitions and replication factor 3 (io.confluent.connect.replicator.ReplicatorSourceTask:1186)
[2024-02-05 13:46:44,234] INFO [replicator-cloud|task-0] Creating topic stream_int-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog with Optional[1] partitions, replication factor Optional[3], and config {cleanup.policy=compact, message.timestamp.type=CreateTime} (io.confluent.connect.replicator.util.ReplicatorAdminClient:340)
[2024-02-05 13:46:44,784] INFO [replicator-cloud|task-0] Fetching destination topic metadata for destination topic stream_opnew (io.confluent.connect.replicator.ReplicatorSourceTask:1128)
[2024-02-05 13:46:45,248] INFO [replicator-cloud|task-0] Fetching source topic configs for source topic stream_opnew (io.confluent.connect.replicator.ReplicatorSourceTask:1135)
[2024-02-05 13:46:45,259] INFO [replicator-cloud|task-0] Using user-specified replication factor of 3 for creating destination topic stream_opnew (io.confluent.connect.replicator.ReplicatorSourceTask:1151)
[2024-02-05 13:46:45,260] INFO [replicator-cloud|task-0] Creating topic stream_opnew in destination cluster with 1 partitions and replication factor 3 (io.confluent.connect.replicator.ReplicatorSourceTask:1186)
[2024-02-05 13:46:45,268] INFO [replicator-cloud|task-0] Creating topic stream_opnew with Optional[1] partitions, replication factor Optional[3], and config {message.timestamp.type=CreateTime} (io.confluent.connect.replicator.util.ReplicatorAdminClient:340)
[2024-02-05 13:46:46,608] INFO [replicator-cloud|task-0] Fetching destination topic metadata for destination topic stream_new1 (io.confluent.connect.replicator.ReplicatorSourceTask:1128)
[2024-02-05 13:46:47,411] INFO [replicator-cloud|task-0] Fetching source topic configs for source topic stream_new1 (io.confluent.connect.replicator.ReplicatorSourceTask:1135)
[2024-02-05 13:46:47,419] INFO [replicator-cloud|task-0] Using user-specified replication factor of 3 for creating destination topic stream_new1 (io.confluent.connect.replicator.ReplicatorSourceTask:1151)
[2024-02-05 13:46:47,421] INFO [replicator-cloud|task-0] Creating topic stream_new1 in destination cluster with 1 partitions and replication factor 3 (io.confluent.connect.replicator.ReplicatorSourceTask:1186)
[2024-02-05 13:46:47,421] INFO [replicator-cloud|task-0] Creating topic stream_new1 with Optional[1] partitions, replication factor Optional[3], and config {message.timestamp.type=CreateTime} (io.confluent.connect.replicator.util.ReplicatorAdminClient:340)
[2024-02-05 13:46:48,139] INFO 127.0.0.1 - - [05/Feb/2024:08:16:48 +0000] "GET /connectors/replicator-cloud HTTP/1.1" 200 998 "-" "curl/7.68.0" 16 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-02-05 13:46:48,691] INFO [replicator-cloud|task-0] Fetching destination topic metadata for destination topic _dek_registry_keys (io.confluent.connect.replicator.ReplicatorSourceTask:1128)
[2024-02-05 13:46:49,557] INFO [replicator-cloud|task-0] Fetching source topic configs for source topic _dek_registry_keys (io.confluent.connect.replicator.ReplicatorSourceTask:1135)
[2024-02-05 13:46:49,559] INFO [replicator-cloud|task-0] Using user-specified replication factor of 3 for creating destination topic _dek_registry_keys (io.confluent.connect.replicator.ReplicatorSourceTask:1151)
[2024-02-05 13:46:49,560] INFO [replicator-cloud|task-0] Creating topic _dek_registry_keys in destination cluster with 1 partitions and replication factor 3 (io.confluent.connect.replicator.ReplicatorSourceTask:1186)
[2024-02-05 13:46:49,560] INFO [replicator-cloud|task-0] Creating topic _dek_registry_keys with Optional[1] partitions, replication factor Optional[3], and config {cleanup.policy=compact, message.timestamp.type=CreateTime} (io.confluent.connect.replicator.util.ReplicatorAdminClient:340)
[2024-02-05 13:46:50,465] INFO [replicator-cloud|task-0] Fetching destination topic metadata for destination topic _confluent_balancer_api_state (io.confluent.connect.replicator.ReplicatorSourceTask:1128)
[2024-02-05 13:46:50,728] INFO [replicator-cloud|task-0] Fetching source topic configs for source topic _confluent_balancer_api_state (io.confluent.connect.replicator.ReplicatorSourceTask:1135)
[2024-02-05 13:46:50,730] INFO [replicator-cloud|task-0] Using user-specified replication factor of 3 for creating destination topic _confluent_balancer_api_state (io.confluent.connect.replicator.ReplicatorSourceTask:1151)
[2024-02-05 13:46:50,730] INFO [replicator-cloud|task-0] Creating topic _confluent_balancer_api_state in destination cluster with 1 partitions and replication factor 3 (io.confluent.connect.replicator.ReplicatorSourceTask:1186)
[2024-02-05 13:46:50,730] INFO [replicator-cloud|task-0] Creating topic _confluent_balancer_api_state with Optional[1] partitions, replication factor Optional[3], and config {cleanup.policy=compact, message.timestamp.type=CreateTime, retention.ms=-1} (io.confluent.connect.replicator.util.ReplicatorAdminClient:340)
[2024-02-05 13:46:52,178] INFO 127.0.0.1 - - [05/Feb/2024:08:16:52 +0000] "GET /connectors/replicator-cloud/status HTTP/1.1" 200 170 "-" "curl/7.68.0" 21 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-02-05 13:46:52,862] INFO [replicator-cloud|task-0] Fetching destination topic metadata for destination topic _schema_encoders (io.confluent.connect.replicator.ReplicatorSourceTask:1128)
[2024-02-05 13:46:53,087] INFO [replicator-cloud|task-0] Fetching source topic configs for source topic _schema_encoders (io.confluent.connect.replicator.ReplicatorSourceTask:1135)
[2024-02-05 13:46:53,089] INFO [replicator-cloud|task-0] Using user-specified replication factor of 3 for creating destination topic _schema_encoders (io.confluent.connect.replicator.ReplicatorSourceTask:1151)
[2024-02-05 13:46:53,090] INFO [replicator-cloud|task-0] Creating topic _schema_encoders in destination cluster with 1 partitions and replication factor 3 (io.confluent.connect.replicator.ReplicatorSourceTask:1186)
[2024-02-05 13:46:53,090] INFO [replicator-cloud|task-0] Creating topic _schema_encoders with Optional[1] partitions, replication factor Optional[3], and config {cleanup.policy=compact, message.timestamp.type=CreateTime} (io.confluent.connect.replicator.util.ReplicatorAdminClient:340)
[2024-02-05 13:46:53,665] INFO [replicator-cloud|task-0] Fetching destination topic metadata for destination topic connect-status (io.confluent.connect.replicator.ReplicatorSourceTask:1128)
[2024-02-05 13:46:53,880] INFO [replicator-cloud|task-0] Fetching source topic configs for source topic connect-status (io.confluent.connect.replicator.ReplicatorSourceTask:1135)
[2024-02-05 13:46:53,888] INFO [replicator-cloud|task-0] Using user-specified replication factor of 3 for creating destination topic connect-status (io.confluent.connect.replicator.ReplicatorSourceTask:1151)
[2024-02-05 13:46:53,889] INFO [replicator-cloud|task-0] Creating topic connect-status in destination cluster with 5 partitions and replication factor 3 (io.confluent.connect.replicator.ReplicatorSourceTask:1186)
[2024-02-05 13:46:53,890] INFO [replicator-cloud|task-0] Creating topic connect-status with Optional[5] partitions, replication factor Optional[3], and config {cleanup.policy=compact, message.timestamp.type=CreateTime} (io.confluent.connect.replicator.util.ReplicatorAdminClient:340)
[2024-02-05 13:46:55,127] INFO [replicator-cloud|task-0] Fetching destination topic metadata for destination topic postgres-data (io.confluent.connect.replicator.ReplicatorSourceTask:1128)
[2024-02-05 13:46:55,634] INFO [replicator-cloud|task-0] Fetching source topic configs for source topic postgres-data (io.confluent.connect.replicator.ReplicatorSourceTask:1135)
[2024-02-05 13:46:55,640] INFO [replicator-cloud|task-0] Using user-specified replication factor of 3 for creating destination topic postgres-data (io.confluent.connect.replicator.ReplicatorSourceTask:1151)
[2024-02-05 13:46:55,641] INFO [replicator-cloud|task-0] Creating topic postgres-data in destination cluster with 1 partitions and replication factor 3 (io.confluent.connect.replicator.ReplicatorSourceTask:1186)
[2024-02-05 13:46:55,641] INFO [replicator-cloud|task-0] Creating topic postgres-data with Optional[1] partitions, replication factor Optional[3], and config {message.timestamp.type=CreateTime} (io.confluent.connect.replicator.util.ReplicatorAdminClient:340)
[2024-02-05 13:46:56,594] INFO [replicator-cloud|task-0] Fetching destination topic metadata for destination topic stream_ip-count-store-changelog (io.confluent.connect.replicator.ReplicatorSourceTask:1128)
[2024-02-05 13:46:56,816] INFO [replicator-cloud|task-0] Fetching source topic configs for source topic stream_ip-count-store-changelog (io.confluent.connect.replicator.ReplicatorSourceTask:1135)
[2024-02-05 13:46:56,823] INFO [replicator-cloud|task-0] Using user-specified replication factor of 3 for creating destination topic stream_ip-count-store-changelog (io.confluent.connect.replicator.ReplicatorSourceTask:1151)
[2024-02-05 13:46:56,823] INFO [replicator-cloud|task-0] Creating topic stream_ip-count-store-changelog in destination cluster with 1 partitions and replication factor 3 (io.confluent.connect.replicator.ReplicatorSourceTask:1186)
[2024-02-05 13:46:56,824] INFO [replicator-cloud|task-0] Creating topic stream_ip-count-store-changelog with Optional[1] partitions, replication factor Optional[3], and config {cleanup.policy=compact,delete, message.timestamp.type=CreateTime, retention.ms=172800000} (io.confluent.connect.replicator.util.ReplicatorAdminClient:340)
[2024-02-05 13:46:57,414] INFO [replicator-cloud|task-0] Fetching destination topic metadata for destination topic sgr (io.confluent.connect.replicator.ReplicatorSourceTask:1128)
[2024-02-05 13:46:57,418] WARN [replicator-cloud|task-0] Failed to refresh topic metadata. Will try again in 30000ms. (io.confluent.connect.replicator.util.ReplicatorAdminClient:443)
java.lang.InterruptedException
	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:385)
	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:2005)
	at org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165)
	at io.confluent.connect.replicator.util.NewReplicatorAdminClient$TopicMetadataTask.refreshTopicMetadata(NewReplicatorAdminClient.java:455)
	at io.confluent.connect.replicator.util.NewReplicatorAdminClient$TopicMetadataTask.run(NewReplicatorAdminClient.java:439)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-02-05 13:46:57,649] INFO [replicator-cloud|task-0] Fetching source topic configs for source topic sgr (io.confluent.connect.replicator.ReplicatorSourceTask:1135)
[2024-02-05 13:46:57,661] INFO [replicator-cloud|task-0] Using user-specified replication factor of 3 for creating destination topic sgr (io.confluent.connect.replicator.ReplicatorSourceTask:1151)
[2024-02-05 13:46:57,662] INFO [replicator-cloud|task-0] Creating topic sgr in destination cluster with 1 partitions and replication factor 3 (io.confluent.connect.replicator.ReplicatorSourceTask:1186)
[2024-02-05 13:46:57,662] INFO [replicator-cloud|task-0] Creating topic sgr with Optional[1] partitions, replication factor Optional[3], and config {message.timestamp.type=CreateTime} (io.confluent.connect.replicator.util.ReplicatorAdminClient:340)
[2024-02-05 13:46:58,358] INFO [replicator-cloud|task-0] Fetching destination topic metadata for destination topic postgres-userdata-replica (io.confluent.connect.replicator.ReplicatorSourceTask:1128)
[2024-02-05 13:46:58,578] INFO [replicator-cloud|task-0] Fetching source topic configs for source topic postgres-userdata-replica (io.confluent.connect.replicator.ReplicatorSourceTask:1135)
[2024-02-05 13:46:58,583] INFO [replicator-cloud|task-0] Using user-specified replication factor of 3 for creating destination topic postgres-userdata-replica (io.confluent.connect.replicator.ReplicatorSourceTask:1151)
[2024-02-05 13:46:58,583] INFO [replicator-cloud|task-0] Creating topic postgres-userdata-replica in destination cluster with 1 partitions and replication factor 3 (io.confluent.connect.replicator.ReplicatorSourceTask:1186)
[2024-02-05 13:46:58,583] INFO [replicator-cloud|task-0] Creating topic postgres-userdata-replica with Optional[1] partitions, replication factor Optional[3], and config {message.timestamp.type=CreateTime} (io.confluent.connect.replicator.util.ReplicatorAdminClient:340)
[2024-02-05 13:46:59,529] INFO [replicator-cloud|task-0] Fetching destination topic metadata for destination topic _schemas (io.confluent.connect.replicator.ReplicatorSourceTask:1128)
[2024-02-05 13:47:00,273] INFO [replicator-cloud|task-0] Fetching source topic configs for source topic _schemas (io.confluent.connect.replicator.ReplicatorSourceTask:1135)
[2024-02-05 13:47:00,277] INFO [replicator-cloud|task-0] Using user-specified replication factor of 3 for creating destination topic _schemas (io.confluent.connect.replicator.ReplicatorSourceTask:1151)
[2024-02-05 13:47:00,277] INFO [replicator-cloud|task-0] Creating topic _schemas in destination cluster with 1 partitions and replication factor 3 (io.confluent.connect.replicator.ReplicatorSourceTask:1186)
[2024-02-05 13:47:00,277] INFO [replicator-cloud|task-0] Creating topic _schemas with Optional[1] partitions, replication factor Optional[3], and config {cleanup.policy=compact, message.timestamp.type=CreateTime} (io.confluent.connect.replicator.util.ReplicatorAdminClient:340)
[2024-02-05 13:47:01,297] INFO [replicator-cloud|task-0] Fetching destination topic metadata for destination topic stream_ip (io.confluent.connect.replicator.ReplicatorSourceTask:1128)
[2024-02-05 13:47:01,511] INFO [replicator-cloud|task-0] Fetching source topic configs for source topic stream_ip (io.confluent.connect.replicator.ReplicatorSourceTask:1135)
[2024-02-05 13:47:01,513] INFO [replicator-cloud|task-0] Using user-specified replication factor of 3 for creating destination topic stream_ip (io.confluent.connect.replicator.ReplicatorSourceTask:1151)
[2024-02-05 13:47:01,513] INFO [replicator-cloud|task-0] Creating topic stream_ip in destination cluster with 1 partitions and replication factor 3 (io.confluent.connect.replicator.ReplicatorSourceTask:1186)
[2024-02-05 13:47:01,513] INFO [replicator-cloud|task-0] Creating topic stream_ip with Optional[1] partitions, replication factor Optional[3], and config {message.timestamp.type=CreateTime} (io.confluent.connect.replicator.util.ReplicatorAdminClient:340)
[2024-02-05 13:47:02,479] INFO [replicator-cloud|task-0] Fetching destination topic metadata for destination topic stream_new (io.confluent.connect.replicator.ReplicatorSourceTask:1128)
[2024-02-05 13:47:02,750] INFO [replicator-cloud|task-0] Fetching source topic configs for source topic stream_new (io.confluent.connect.replicator.ReplicatorSourceTask:1135)
[2024-02-05 13:47:02,757] INFO [replicator-cloud|task-0] Using user-specified replication factor of 3 for creating destination topic stream_new (io.confluent.connect.replicator.ReplicatorSourceTask:1151)
[2024-02-05 13:47:02,758] INFO [replicator-cloud|task-0] Creating topic stream_new in destination cluster with 1 partitions and replication factor 3 (io.confluent.connect.replicator.ReplicatorSourceTask:1186)
[2024-02-05 13:47:02,758] INFO [replicator-cloud|task-0] Creating topic stream_new with Optional[1] partitions, replication factor Optional[3], and config {message.timestamp.type=CreateTime} (io.confluent.connect.replicator.util.ReplicatorAdminClient:340)
[2024-02-05 13:47:04,065] INFO [replicator-cloud|task-0] Fetching destination topic metadata for destination topic my_topic (io.confluent.connect.replicator.ReplicatorSourceTask:1128)
[2024-02-05 13:47:04,282] INFO [replicator-cloud|task-0] Fetching source topic configs for source topic my_topic (io.confluent.connect.replicator.ReplicatorSourceTask:1135)
[2024-02-05 13:47:04,290] INFO [replicator-cloud|task-0] Using user-specified replication factor of 3 for creating destination topic my_topic (io.confluent.connect.replicator.ReplicatorSourceTask:1151)
[2024-02-05 13:47:04,291] INFO [replicator-cloud|task-0] Creating topic my_topic in destination cluster with 1 partitions and replication factor 3 (io.confluent.connect.replicator.ReplicatorSourceTask:1186)
[2024-02-05 13:47:04,291] INFO [replicator-cloud|task-0] Creating topic my_topic with Optional[1] partitions, replication factor Optional[3], and config {message.timestamp.type=CreateTime} (io.confluent.connect.replicator.util.ReplicatorAdminClient:340)
[2024-02-05 13:47:05,490] INFO [replicator-cloud|task-0] Fetching destination topic metadata for destination topic stream_opt (io.confluent.connect.replicator.ReplicatorSourceTask:1128)
[2024-02-05 13:47:06,331] INFO [replicator-cloud|task-0] Fetching source topic configs for source topic stream_opt (io.confluent.connect.replicator.ReplicatorSourceTask:1135)
[2024-02-05 13:47:06,337] INFO [replicator-cloud|task-0] Using user-specified replication factor of 3 for creating destination topic stream_opt (io.confluent.connect.replicator.ReplicatorSourceTask:1151)
[2024-02-05 13:47:06,338] INFO [replicator-cloud|task-0] Creating topic stream_opt in destination cluster with 1 partitions and replication factor 3 (io.confluent.connect.replicator.ReplicatorSourceTask:1186)
[2024-02-05 13:47:06,339] INFO [replicator-cloud|task-0] Creating topic stream_opt with Optional[1] partitions, replication factor Optional[3], and config {message.timestamp.type=CreateTime} (io.confluent.connect.replicator.util.ReplicatorAdminClient:340)
[2024-02-05 13:47:07,607] INFO [replicator-cloud|task-0] Fetching destination topic metadata for destination topic stream_ip-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog (io.confluent.connect.replicator.ReplicatorSourceTask:1128)
[2024-02-05 13:47:07,922] INFO [replicator-cloud|task-0] Fetching source topic configs for source topic stream_ip-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog (io.confluent.connect.replicator.ReplicatorSourceTask:1135)
[2024-02-05 13:47:07,927] INFO [replicator-cloud|task-0] Using user-specified replication factor of 3 for creating destination topic stream_ip-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog (io.confluent.connect.replicator.ReplicatorSourceTask:1151)
[2024-02-05 13:47:07,927] INFO [replicator-cloud|task-0] Creating topic stream_ip-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog in destination cluster with 1 partitions and replication factor 3 (io.confluent.connect.replicator.ReplicatorSourceTask:1186)
[2024-02-05 13:47:07,928] INFO [replicator-cloud|task-0] Creating topic stream_ip-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog with Optional[1] partitions, replication factor Optional[3], and config {cleanup.policy=compact, message.timestamp.type=CreateTime} (io.confluent.connect.replicator.util.ReplicatorAdminClient:340)
[2024-02-05 13:47:08,568] INFO [replicator-cloud|task-0] Fetching destination topic metadata for destination topic stream_op2 (io.confluent.connect.replicator.ReplicatorSourceTask:1128)
[2024-02-05 13:47:08,790] INFO [replicator-cloud|task-0] Fetching source topic configs for source topic stream_op2 (io.confluent.connect.replicator.ReplicatorSourceTask:1135)
[2024-02-05 13:47:08,796] INFO [replicator-cloud|task-0] Using user-specified replication factor of 3 for creating destination topic stream_op2 (io.confluent.connect.replicator.ReplicatorSourceTask:1151)
[2024-02-05 13:47:08,797] INFO [replicator-cloud|task-0] Creating topic stream_op2 in destination cluster with 1 partitions and replication factor 3 (io.confluent.connect.replicator.ReplicatorSourceTask:1186)
[2024-02-05 13:47:08,797] INFO [replicator-cloud|task-0] Creating topic stream_op2 with Optional[1] partitions, replication factor Optional[3], and config {message.timestamp.type=CreateTime} (io.confluent.connect.replicator.util.ReplicatorAdminClient:340)
[2024-02-05 13:47:09,356] INFO [replicator-cloud|task-0] Fetching destination topic metadata for destination topic stream_op3 (io.confluent.connect.replicator.ReplicatorSourceTask:1128)
[2024-02-05 13:47:09,571] INFO [replicator-cloud|task-0] Fetching source topic configs for source topic stream_op3 (io.confluent.connect.replicator.ReplicatorSourceTask:1135)
[2024-02-05 13:47:09,572] INFO [replicator-cloud|task-0] Using user-specified replication factor of 3 for creating destination topic stream_op3 (io.confluent.connect.replicator.ReplicatorSourceTask:1151)
[2024-02-05 13:47:09,572] INFO [replicator-cloud|task-0] Creating topic stream_op3 in destination cluster with 1 partitions and replication factor 3 (io.confluent.connect.replicator.ReplicatorSourceTask:1186)
[2024-02-05 13:47:09,573] INFO [replicator-cloud|task-0] Creating topic stream_op3 with Optional[1] partitions, replication factor Optional[3], and config {message.timestamp.type=CreateTime} (io.confluent.connect.replicator.util.ReplicatorAdminClient:340)
[2024-02-05 13:47:09,917] INFO [replicator-cloud|task-0] Fetching destination topic metadata for destination topic _confluent-telemetry-metrics (io.confluent.connect.replicator.ReplicatorSourceTask:1128)
[2024-02-05 13:47:10,134] INFO [replicator-cloud|task-0] Fetching source topic configs for source topic _confluent-telemetry-metrics (io.confluent.connect.replicator.ReplicatorSourceTask:1135)
[2024-02-05 13:47:10,139] INFO [replicator-cloud|task-0] Using user-specified replication factor of 3 for creating destination topic _confluent-telemetry-metrics (io.confluent.connect.replicator.ReplicatorSourceTask:1151)
[2024-02-05 13:47:10,355] INFO [replicator-cloud|task-0] Creating topic _confluent-telemetry-metrics in destination cluster with 12 partitions and replication factor 3 (io.confluent.connect.replicator.ReplicatorSourceTask:1186)
[2024-02-05 13:47:10,355] INFO [replicator-cloud|task-0] Creating topic _confluent-telemetry-metrics with Optional[12] partitions, replication factor Optional[3], and config {max.message.bytes=10485760, message.timestamp.type=CreateTime, min.insync.replicas=1, retention.ms=259200000, segment.ms=14400000, retention.bytes=-1} (io.confluent.connect.replicator.util.ReplicatorAdminClient:340)
[2024-02-05 13:47:10,647] WARN [replicator-cloud|task-0] Encountered exception when trying to create destination topic _confluent-telemetry-metrics:  (io.confluent.connect.replicator.ReplicatorSourceTask:1195)
java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.PolicyViolationException: Config property 'max.message.bytes' with value '10485760' is larger than the maximum allowed value of of 8388608.
	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:2005)
	at org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165)
	at io.confluent.connect.replicator.util.NewReplicatorAdminClient.createTopic(NewReplicatorAdminClient.java:357)
	at io.confluent.connect.replicator.util.NewReplicatorAdminClient.createTopic(NewReplicatorAdminClient.java:330)
	at io.confluent.connect.replicator.util.NewReplicatorAdminClient.createTopic(NewReplicatorAdminClient.java:319)
	at io.confluent.connect.replicator.ReplicatorSourceTask.maybeCreateOrExpandDestTopic(ReplicatorSourceTask.java:1192)
	at io.confluent.connect.replicator.ReplicatorSourceTask.retryTopicExpansionIfNeeded(ReplicatorSourceTask.java:1009)
	at io.confluent.connect.replicator.ReplicatorSourceTask.poll(ReplicatorSourceTask.java:476)
	at org.apache.kafka.connect.runtime.AbstractWorkerSourceTask.poll(AbstractWorkerSourceTask.java:488)
	at org.apache.kafka.connect.runtime.AbstractWorkerSourceTask.execute(AbstractWorkerSourceTask.java:360)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:229)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:284)
	at org.apache.kafka.connect.runtime.AbstractWorkerSourceTask.run(AbstractWorkerSourceTask.java:80)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:181)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.apache.kafka.common.errors.PolicyViolationException: Config property 'max.message.bytes' with value '10485760' is larger than the maximum allowed value of of 8388608.
[2024-02-05 13:47:10,648] INFO [replicator-cloud|task-0] Fetching destination topic metadata for destination topic stream_int (io.confluent.connect.replicator.ReplicatorSourceTask:1128)
[2024-02-05 13:47:10,648] INFO [replicator-cloud|task-0] Fetching source topic configs for source topic stream_int (io.confluent.connect.replicator.ReplicatorSourceTask:1135)
[2024-02-05 13:47:10,649] INFO [replicator-cloud|task-0] Using user-specified replication factor of 3 for creating destination topic stream_int (io.confluent.connect.replicator.ReplicatorSourceTask:1151)
[2024-02-05 13:47:10,650] INFO [replicator-cloud|task-0] Creating topic stream_int in destination cluster with 1 partitions and replication factor 3 (io.confluent.connect.replicator.ReplicatorSourceTask:1186)
[2024-02-05 13:47:10,650] INFO [replicator-cloud|task-0] Creating topic stream_int with Optional[1] partitions, replication factor Optional[3], and config {message.timestamp.type=CreateTime} (io.confluent.connect.replicator.util.ReplicatorAdminClient:340)
[2024-02-05 13:47:11,058] INFO [replicator-cloud|task-0] Fetching destination topic metadata for destination topic stream_op1 (io.confluent.connect.replicator.ReplicatorSourceTask:1128)
[2024-02-05 13:47:11,270] INFO [replicator-cloud|task-0] Fetching source topic configs for source topic stream_op1 (io.confluent.connect.replicator.ReplicatorSourceTask:1135)
[2024-02-05 13:47:11,272] INFO [replicator-cloud|task-0] Using user-specified replication factor of 3 for creating destination topic stream_op1 (io.confluent.connect.replicator.ReplicatorSourceTask:1151)
[2024-02-05 13:47:11,272] INFO [replicator-cloud|task-0] Creating topic stream_op1 in destination cluster with 1 partitions and replication factor 3 (io.confluent.connect.replicator.ReplicatorSourceTask:1186)
[2024-02-05 13:47:11,272] INFO [replicator-cloud|task-0] Creating topic stream_op1 with Optional[1] partitions, replication factor Optional[3], and config {message.timestamp.type=CreateTime} (io.confluent.connect.replicator.util.ReplicatorAdminClient:340)
[2024-02-05 13:47:12,284] INFO [replicator-cloud|task-0] Updating configuration of destination topic connect-configs with properties {cleanup.policy=compact, message.timestamp.type=CreateTime} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:47:13,361] INFO [replicator-cloud|task-0] Updating configuration of destination topic output_topic with properties {message.timestamp.type=CreateTime} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:47:14,084] INFO [replicator-cloud|task-0] Updating configuration of destination topic kafka-streams-aggregation-count-store-changelog with properties {cleanup.policy=compact,delete, message.timestamp.type=CreateTime, retention.ms=172800000} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:47:14,763] INFO [replicator-cloud|task-0] Updating configuration of destination topic input_topic with properties {message.timestamp.type=CreateTime} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:47:15,537] INFO [replicator-cloud|task-0] Updating configuration of destination topic stream_int-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog with properties {cleanup.policy=compact, message.timestamp.type=CreateTime} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:47:16,214] INFO [replicator-cloud|task-0] Updating configuration of destination topic stream_opnew with properties {message.timestamp.type=CreateTime} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:47:16,951] INFO [replicator-cloud|task-0] Updating configuration of destination topic connect-offsets with properties {cleanup.policy=compact, message.timestamp.type=CreateTime} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:47:17,632] INFO [replicator-cloud|task-0] Updating configuration of destination topic stream_new1 with properties {message.timestamp.type=CreateTime} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:47:18,320] INFO [replicator-cloud|task-0] Updating configuration of destination topic _dek_registry_keys with properties {cleanup.policy=compact, message.timestamp.type=CreateTime} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:47:19,006] INFO [replicator-cloud|task-0] Updating configuration of destination topic postgres-userdata with properties {message.timestamp.type=CreateTime} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:47:19,675] INFO [replicator-cloud|task-0] Updating configuration of destination topic _confluent_balancer_api_state with properties {cleanup.policy=compact, message.timestamp.type=CreateTime, retention.ms=-1} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:47:20,339] INFO [replicator-cloud|task-0] Updating configuration of destination topic _schema_encoders with properties {cleanup.policy=compact, message.timestamp.type=CreateTime} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:47:21,028] INFO [replicator-cloud|task-0] Updating configuration of destination topic connect-status with properties {cleanup.policy=compact, message.timestamp.type=CreateTime} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:47:22,283] INFO [replicator-cloud|task-0] Updating configuration of destination topic postgres-data with properties {message.timestamp.type=CreateTime} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:47:23,636] INFO [replicator-cloud|task-0] Updating configuration of destination topic stream_ip-count-store-changelog with properties {cleanup.policy=compact,delete, message.timestamp.type=CreateTime, retention.ms=172800000} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:47:24,296] INFO [replicator-cloud|task-0] Updating configuration of destination topic sgr with properties {message.timestamp.type=CreateTime} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:47:24,956] INFO [replicator-cloud|task-0] Updating configuration of destination topic postgres-userdata-replica with properties {message.timestamp.type=CreateTime} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:47:25,615] INFO [replicator-cloud|task-0] Updating configuration of destination topic _schemas with properties {cleanup.policy=compact, message.timestamp.type=CreateTime} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:47:26,293] INFO [replicator-cloud|task-0] Updating configuration of destination topic stream_ip with properties {message.timestamp.type=CreateTime} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:47:26,951] INFO [replicator-cloud|task-0] Updating configuration of destination topic _confluent-command with properties {cleanup.policy=compact, message.timestamp.type=CreateTime, min.insync.replicas=1} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:47:27,679] INFO [replicator-cloud|task-0] Updating configuration of destination topic stream_new with properties {message.timestamp.type=CreateTime} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:47:29,309] INFO [replicator-cloud|task-0] Updating configuration of destination topic my_topic with properties {message.timestamp.type=CreateTime} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:47:29,971] INFO [replicator-cloud|task-0] Updating configuration of destination topic stream_opt with properties {message.timestamp.type=CreateTime} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:47:31,268] INFO [replicator-cloud|task-0] Updating configuration of destination topic stream_ip-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog with properties {cleanup.policy=compact, message.timestamp.type=CreateTime} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:47:32,748] INFO [replicator-cloud|task-0] Updating configuration of destination topic stream_op2 with properties {message.timestamp.type=CreateTime} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:47:33,885] INFO [replicator-cloud|task-0] Updating configuration of destination topic stream_op3 with properties {message.timestamp.type=CreateTime} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:47:34,550] INFO [replicator-cloud|task-0] Updating configuration of destination topic stream_int with properties {message.timestamp.type=CreateTime} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:47:35,759] INFO [replicator-cloud|task-0] Updating configuration of destination topic stream_op1 with properties {message.timestamp.type=CreateTime} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:47:36,575] INFO [replicator-cloud|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = none
	bootstrap.servers = [pkc-4r087.us-west2.gcp.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = replicator-cloud-0
	client.rack = 
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = replicator-localhost
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:370)
[2024-02-05 13:47:36,617] INFO [replicator-cloud|task-0] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:47:36,618] INFO [replicator-cloud|task-0] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:47:36,618] INFO [replicator-cloud|task-0] Kafka startTimeMs: 1707121056617 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:47:36,618] WARN [replicator-cloud|task-0] Error registering AppInfo mbean (org.apache.kafka.common.utils.AppInfoParser:68)
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=replicator-cloud-0
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:828)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:671)
	at io.confluent.connect.replicator.offsets.ConsumerOffsetsTranslator.buildDestConsumer(ConsumerOffsetsTranslator.java:322)
	at io.confluent.connect.replicator.offsets.ConsumerOffsetsTranslator.commitOffsets(ConsumerOffsetsTranslator.java:264)
	at io.confluent.connect.replicator.offsets.ConsumerOffsetsTranslator.translateOffsets(ConsumerOffsetsTranslator.java:232)
	at io.confluent.connect.replicator.offsets.ConsumerOffsetsTranslator.translateCollectedRecords(ConsumerOffsetsTranslator.java:186)
	at io.confluent.connect.replicator.ReplicatorSourceTask.translateCollectedRecords(ReplicatorSourceTask.java:652)
	at io.confluent.connect.replicator.ReplicatorSourceTask.poll(ReplicatorSourceTask.java:604)
	at org.apache.kafka.connect.runtime.AbstractWorkerSourceTask.poll(AbstractWorkerSourceTask.java:488)
	at org.apache.kafka.connect.runtime.AbstractWorkerSourceTask.execute(AbstractWorkerSourceTask.java:360)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:229)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:284)
	at org.apache.kafka.connect.runtime.AbstractWorkerSourceTask.run(AbstractWorkerSourceTask.java:80)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:181)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-02-05 13:47:39,054] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-localhost] Cluster ID: lkc-qpjpkm (org.apache.kafka.clients.Metadata:287)
[2024-02-05 13:47:45,521] WARN [replicator-cloud|task-0] Could not find offset for group replicator-localhost, topic postgres-userdata, partition 0, timestamp 1707116386589, waiting for replication to catch up.  Please check replication lag. (io.confluent.connect.replicator.offsets.ConsumerOffsetsTranslator:426)
[2024-02-05 13:47:45,539] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-localhost] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1025)
[2024-02-05 13:47:45,541] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-localhost] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1072)
[2024-02-05 13:47:45,542] INFO [replicator-cloud|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:47:45,542] INFO [replicator-cloud|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:47:45,542] INFO [replicator-cloud|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:47:45,546] INFO [replicator-cloud|task-0] App info kafka.consumer for replicator-cloud-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:47:45,548] INFO [replicator-cloud|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = none
	bootstrap.servers = [pkc-4r087.us-west2.gcp.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = replicator-cloud-0
	client.rack = 
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ConsumerGroup1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:370)
[2024-02-05 13:47:45,560] INFO [replicator-cloud|task-0] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:47:45,561] INFO [replicator-cloud|task-0] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:47:45,561] INFO [replicator-cloud|task-0] Kafka startTimeMs: 1707121065560 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:47:48,945] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=ConsumerGroup1] Cluster ID: lkc-qpjpkm (org.apache.kafka.clients.Metadata:287)
[2024-02-05 13:47:54,848] WARN [replicator-cloud|task-0] Could not find offset for group ConsumerGroup1, topic stream_ip, partition 0, timestamp 1704871412056:7, waiting for replication to catch up.  Please check replication lag. (io.confluent.connect.replicator.offsets.ConsumerOffsetsTranslator:426)
[2024-02-05 13:47:54,849] WARN [replicator-cloud|task-0] Could not find offset for group ConsumerGroup1, topic stream_op3, partition 0, timestamp 1704867999328, waiting for replication to catch up.  Please check replication lag. (io.confluent.connect.replicator.offsets.ConsumerOffsetsTranslator:426)
[2024-02-05 13:47:54,850] WARN [replicator-cloud|task-0] Could not find offset for group ConsumerGroup1, topic stream_op1, partition 0, timestamp 1704866647275:5, waiting for replication to catch up.  Please check replication lag. (io.confluent.connect.replicator.offsets.ConsumerOffsetsTranslator:426)
[2024-02-05 13:47:54,850] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=ConsumerGroup1] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1025)
[2024-02-05 13:47:54,851] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=ConsumerGroup1] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1072)
[2024-02-05 13:47:54,852] INFO [replicator-cloud|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:47:54,852] INFO [replicator-cloud|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:47:54,853] INFO [replicator-cloud|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:47:54,861] INFO [replicator-cloud|task-0] App info kafka.consumer for replicator-cloud-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:47:54,866] INFO [replicator-cloud|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = none
	bootstrap.servers = [pkc-4r087.us-west2.gcp.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = replicator-cloud-0
	client.rack = 
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ConsumerGroup2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:370)
[2024-02-05 13:47:54,878] INFO [replicator-cloud|task-0] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:47:54,878] INFO [replicator-cloud|task-0] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:47:54,879] INFO [replicator-cloud|task-0] Kafka startTimeMs: 1707121074878 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:47:57,202] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=ConsumerGroup2] Cluster ID: lkc-qpjpkm (org.apache.kafka.clients.Metadata:287)
[2024-02-05 13:48:02,592] WARN [replicator-cloud|task-0] Could not find offset for group ConsumerGroup2, topic stream_op3, partition 0, timestamp 1705037816254:8, waiting for replication to catch up.  Please check replication lag. (io.confluent.connect.replicator.offsets.ConsumerOffsetsTranslator:426)
[2024-02-05 13:48:02,593] WARN [replicator-cloud|task-0] Could not find offset for group ConsumerGroup2, topic stream_op1, partition 0, timestamp 1704875562566:2, waiting for replication to catch up.  Please check replication lag. (io.confluent.connect.replicator.offsets.ConsumerOffsetsTranslator:426)
[2024-02-05 13:48:02,593] WARN [replicator-cloud|task-0] Could not find offset for group ConsumerGroup2, topic stream_op2, partition 0, timestamp 1705037455440:7, waiting for replication to catch up.  Please check replication lag. (io.confluent.connect.replicator.offsets.ConsumerOffsetsTranslator:426)
[2024-02-05 13:48:02,594] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=ConsumerGroup2] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1025)
[2024-02-05 13:48:02,594] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=ConsumerGroup2] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1072)
[2024-02-05 13:48:02,595] INFO [replicator-cloud|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:48:02,595] INFO [replicator-cloud|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:48:02,596] INFO [replicator-cloud|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:48:02,602] INFO [replicator-cloud|task-0] App info kafka.consumer for replicator-cloud-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:48:02,603] INFO [replicator-cloud|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = none
	bootstrap.servers = [pkc-4r087.us-west2.gcp.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = replicator-cloud-0
	client.rack = 
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = replicator
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:370)
[2024-02-05 13:48:02,615] INFO [replicator-cloud|task-0] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:48:02,615] INFO [replicator-cloud|task-0] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:48:02,616] INFO [replicator-cloud|task-0] Kafka startTimeMs: 1707121082615 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:48:06,129] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator] Cluster ID: lkc-qpjpkm (org.apache.kafka.clients.Metadata:287)
[2024-02-05 13:48:13,619] WARN [replicator-cloud|task-0] Could not find offset for group replicator, topic postgres-userdata, partition 0, timestamp 1706859036568, waiting for replication to catch up.  Please check replication lag. (io.confluent.connect.replicator.offsets.ConsumerOffsetsTranslator:426)
[2024-02-05 13:48:13,622] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1025)
[2024-02-05 13:48:13,625] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1072)
[2024-02-05 13:48:13,627] INFO [replicator-cloud|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:48:13,627] INFO [replicator-cloud|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:48:13,628] INFO [replicator-cloud|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:48:13,634] INFO [replicator-cloud|task-0] App info kafka.consumer for replicator-cloud-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:48:13,636] INFO [replicator-cloud|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = none
	bootstrap.servers = [pkc-4r087.us-west2.gcp.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = replicator-cloud-0
	client.rack = 
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ConsumerGroup3
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:370)
[2024-02-05 13:48:13,676] INFO [replicator-cloud|task-0] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:48:13,676] INFO [replicator-cloud|task-0] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:48:13,676] INFO [replicator-cloud|task-0] Kafka startTimeMs: 1707121093676 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:48:16,494] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=ConsumerGroup3] Cluster ID: lkc-qpjpkm (org.apache.kafka.clients.Metadata:287)
[2024-02-05 13:48:22,927] WARN [replicator-cloud|task-0] Could not find offset for group ConsumerGroup3, topic output_topic, partition 0, timestamp 1705055731393:4, waiting for replication to catch up.  Please check replication lag. (io.confluent.connect.replicator.offsets.ConsumerOffsetsTranslator:426)
[2024-02-05 13:48:22,928] WARN [replicator-cloud|task-0] Could not find offset for group ConsumerGroup3, topic stream_ip, partition 0, timestamp 1705037816254:8, waiting for replication to catch up.  Please check replication lag. (io.confluent.connect.replicator.offsets.ConsumerOffsetsTranslator:426)
[2024-02-05 13:48:22,929] WARN [replicator-cloud|task-0] Could not find offset for group ConsumerGroup3, topic stream_opnew, partition 0, timestamp 1705052302916:1, waiting for replication to catch up.  Please check replication lag. (io.confluent.connect.replicator.offsets.ConsumerOffsetsTranslator:426)
[2024-02-05 13:48:22,932] WARN [replicator-cloud|task-0] Could not find offset for group ConsumerGroup3, topic stream_opt, partition 0, timestamp 1705043913303:3, waiting for replication to catch up.  Please check replication lag. (io.confluent.connect.replicator.offsets.ConsumerOffsetsTranslator:426)
[2024-02-05 13:48:22,932] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=ConsumerGroup3] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1025)
[2024-02-05 13:48:22,933] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=ConsumerGroup3] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1072)
[2024-02-05 13:48:22,934] INFO [replicator-cloud|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:48:22,934] INFO [replicator-cloud|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:48:22,935] INFO [replicator-cloud|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:48:22,944] INFO [replicator-cloud|task-0] App info kafka.consumer for replicator-cloud-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:48:22,947] INFO [replicator-cloud|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = none
	bootstrap.servers = [pkc-4r087.us-west2.gcp.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = replicator-cloud-0
	client.rack = 
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = replicator-config
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:370)
[2024-02-05 13:48:22,961] INFO [replicator-cloud|task-0] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:48:22,961] INFO [replicator-cloud|task-0] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:48:22,961] INFO [replicator-cloud|task-0] Kafka startTimeMs: 1707121102961 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:48:25,850] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-config] Cluster ID: lkc-qpjpkm (org.apache.kafka.clients.Metadata:287)
[2024-02-05 13:48:28,369] INFO [replicator-cloud|worker] Found matching topics: [connect-configs, output_topic, kafka-streams-aggregation-count-store-changelog, input_topic, stream_int-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog, stream_opnew, connect-offsets, stream_new1, postgres-userdata, _dek_registry_keys, _confluent_balancer_api_state, _schema_encoders, connect-status, stream_ip-count-store-changelog, postgres-data, __consumer_timestamps, sgr, postgres-userdata-replica, _schemas, stream_ip, _confluent-command, stream_new, my_topic, stream_opt, stream_ip-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog, stream_op2, stream_op3, _confluent-telemetry-metrics, stream_int, stream_op1] (io.confluent.connect.replicator.NewTopicMonitorThread:330)
[2024-02-05 13:48:28,370] INFO [replicator-cloud|worker] topic.regex is set. Replicator requires a DESCRIBE ACL on topics to match via regex. If this ACL is not present then the topic will not be replicated. (io.confluent.connect.replicator.NewTopicMonitorThread:347)
[2024-02-05 13:48:32,672] WARN [replicator-cloud|task-0] Could not find offset for group replicator-config, topic postgres-userdata, partition 0, timestamp 1706860176945, waiting for replication to catch up.  Please check replication lag. (io.confluent.connect.replicator.offsets.ConsumerOffsetsTranslator:426)
[2024-02-05 13:48:32,680] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-config] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1025)
[2024-02-05 13:48:32,682] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-config] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1072)
[2024-02-05 13:48:32,683] INFO [replicator-cloud|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:48:32,688] INFO [replicator-cloud|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:48:32,688] INFO [replicator-cloud|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:48:32,691] INFO [replicator-cloud|task-0] App info kafka.consumer for replicator-cloud-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:48:32,692] INFO [replicator-cloud|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = none
	bootstrap.servers = [pkc-4r087.us-west2.gcp.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = replicator-cloud-0
	client.rack = 
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ConsumerGroup11
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:370)
[2024-02-05 13:48:32,710] INFO [replicator-cloud|task-0] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:48:32,710] INFO [replicator-cloud|task-0] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:48:32,710] INFO [replicator-cloud|task-0] Kafka startTimeMs: 1707121112709 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:48:34,725] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=ConsumerGroup11] Cluster ID: lkc-qpjpkm (org.apache.kafka.clients.Metadata:287)
[2024-02-05 13:48:42,861] WARN [replicator-cloud|task-0] Could not find offset for group ConsumerGroup11, topic kafka-streams-aggregation-count-store-changelog, partition 0, timestamp 1704800086245, waiting for replication to catch up.  Please check replication lag. (io.confluent.connect.replicator.offsets.ConsumerOffsetsTranslator:426)
[2024-02-05 13:48:42,863] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=ConsumerGroup11] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1025)
[2024-02-05 13:48:42,863] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=ConsumerGroup11] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1072)
[2024-02-05 13:48:42,864] INFO [replicator-cloud|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:48:42,864] INFO [replicator-cloud|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:48:42,864] INFO [replicator-cloud|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:48:42,868] INFO [replicator-cloud|task-0] App info kafka.consumer for replicator-cloud-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:48:42,868] INFO [replicator-cloud|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = none
	bootstrap.servers = [pkc-4r087.us-west2.gcp.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = replicator-cloud-0
	client.rack = 
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ConsumerGroup10
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:370)
[2024-02-05 13:48:42,875] INFO [replicator-cloud|task-0] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:48:42,876] INFO [replicator-cloud|task-0] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:48:42,876] INFO [replicator-cloud|task-0] Kafka startTimeMs: 1707121122875 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:48:45,846] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=ConsumerGroup10] Cluster ID: lkc-qpjpkm (org.apache.kafka.clients.Metadata:287)
[2024-02-05 13:48:52,112] WARN [replicator-cloud|task-0] Could not find offset for group ConsumerGroup10, topic kafka-streams-aggregation-count-store-changelog, partition 0, timestamp 1704800086245, waiting for replication to catch up.  Please check replication lag. (io.confluent.connect.replicator.offsets.ConsumerOffsetsTranslator:426)
[2024-02-05 13:48:52,115] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=ConsumerGroup10] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1025)
[2024-02-05 13:48:52,117] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=ConsumerGroup10] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1072)
[2024-02-05 13:48:52,118] INFO [replicator-cloud|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:48:52,119] INFO [replicator-cloud|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:48:52,119] INFO [replicator-cloud|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:48:52,128] INFO [replicator-cloud|task-0] App info kafka.consumer for replicator-cloud-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:48:57,861] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector jdbc_source_postgres config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2226)
[2024-02-05 13:48:57,862] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:231)
[2024-02-05 13:48:57,862] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:576)
[2024-02-05 13:48:57,862] INFO [Worker clientId=connect-1, groupId=connect-cluster] Tasks [jdbc_source_postgres-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2241)
[2024-02-05 13:48:57,863] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector jdbc_sink_connector config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2226)
[2024-02-05 13:48:57,863] INFO [Worker clientId=connect-1, groupId=connect-cluster] Tasks [jdbc_sink_connector-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2241)
[2024-02-05 13:48:57,864] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector s3-sink config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2226)
[2024-02-05 13:48:57,865] INFO [Worker clientId=connect-1, groupId=connect-cluster] Tasks [s3-sink-0, s3-sink-1, s3-sink-2] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2241)
[2024-02-05 13:48:57,865] INFO [Worker clientId=connect-1, groupId=connect-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2284)
[2024-02-05 13:48:58,160] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=8, memberId='connect-1-5626c631-09b4-4bc6-b13c-f89c6adf07d0', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:637)
[2024-02-05 13:48:58,388] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=8, memberId='connect-1-5626c631-09b4-4bc6-b13c-f89c6adf07d0', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:812)
[2024-02-05 13:48:58,389] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 8 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-5626c631-09b4-4bc6-b13c-f89c6adf07d0', leaderUrl='http://127.0.1.1:8083/', offset=9, connectorIds=[jdbc_source_postgres, replicator-cloud], taskIds=[jdbc_source_postgres-0, replicator-cloud-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2416)
[2024-02-05 13:48:58,390] WARN [Worker clientId=connect-1, groupId=connect-cluster] Catching up to assignment's config offset. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1625)
[2024-02-05 13:48:58,390] INFO [Worker clientId=connect-1, groupId=connect-cluster] Current config state offset 7 is behind group assignment 9, reading to end of config log (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1690)
[2024-02-05 13:48:58,533] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Disconnecting from node 0 due to request timeout. (org.apache.kafka.clients.NetworkClient:933)
[2024-02-05 13:48:58,541] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Cancelled in-flight FETCH request with correlation id 8 due to node 0 being disconnected (elapsed time since creation: 81987ms, elapsed time since send: 81987ms, request timeout: 20000ms) (org.apache.kafka.clients.NetworkClient:406)
[2024-02-05 13:48:58,544] WARN [replicator-cloud|task-0] Commit of offsets threw an unexpected exception: {connect-configs-0=OffsetAndMetadata{offset=152, leaderEpoch=null, metadata=''}, __consumer_timestamps-13=OffsetAndMetadata{offset=1, leaderEpoch=null, metadata=''}, __consumer_timestamps-44=OffsetAndMetadata{offset=1, leaderEpoch=null, metadata=''}, __consumer_timestamps-11=OffsetAndMetadata{offset=1, leaderEpoch=null, metadata=''}, __consumer_timestamps-43=OffsetAndMetadata{offset=2, leaderEpoch=null, metadata=''}, __consumer_timestamps-10=OffsetAndMetadata{offset=5, leaderEpoch=null, metadata=''}, stream_int-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog-0=OffsetAndMetadata{offset=25, leaderEpoch=null, metadata=''}, __consumer_timestamps-8=OffsetAndMetadata{offset=10, leaderEpoch=null, metadata=''}, __consumer_timestamps-22=OffsetAndMetadata{offset=5, leaderEpoch=null, metadata=''}, __consumer_timestamps-21=OffsetAndMetadata{offset=1, leaderEpoch=null, metadata=''}, connect-offsets-0=OffsetAndMetadata{offset=3, leaderEpoch=null, metadata=''}, __consumer_timestamps-19=OffsetAndMetadata{offset=1, leaderEpoch=null, metadata=''}, __consumer_timestamps-17=OffsetAndMetadata{offset=3, leaderEpoch=null, metadata=''}, __consumer_timestamps-49=OffsetAndMetadata{offset=3, leaderEpoch=null, metadata=''}, connect-offsets-24=OffsetAndMetadata{offset=9, leaderEpoch=null, metadata=''}, postgres-userdata-0=OffsetAndMetadata{offset=24, leaderEpoch=null, metadata=''}, __consumer_timestamps-39=OffsetAndMetadata{offset=1, leaderEpoch=null, metadata=''}, __consumer_timestamps-5=OffsetAndMetadata{offset=1, leaderEpoch=null, metadata=''}, __consumer_timestamps-36=OffsetAndMetadata{offset=1, leaderEpoch=null, metadata=''}, connect-status-0=OffsetAndMetadata{offset=97, leaderEpoch=null, metadata=''}, __consumer_timestamps-0=OffsetAndMetadata{offset=9, leaderEpoch=null, metadata=''}} (io.confluent.connect.replicator.offsets.ConsumerOffsetsTopicCommitter:271)
org.apache.kafka.common.errors.WakeupException
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.maybeTriggerWakeup(ConsumerNetworkClient.java:529)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:293)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:230)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.commitOffsetsSync(ConsumerCoordinator.java:1176)
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1518)
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1465)
	at io.confluent.connect.replicator.offsets.ConsumerOffsetsTopicCommitter.commitConsumerOffset(ConsumerOffsetsTopicCommitter.java:268)
	at io.confluent.connect.replicator.offsets.ConsumerOffsetsTopicCommitter.checkCommit(ConsumerOffsetsTopicCommitter.java:253)
	at io.confluent.connect.replicator.ReplicatorSourceTask.poll(ReplicatorSourceTask.java:471)
	at org.apache.kafka.connect.runtime.AbstractWorkerSourceTask.poll(AbstractWorkerSourceTask.java:488)
	at org.apache.kafka.connect.runtime.AbstractWorkerSourceTask.execute(AbstractWorkerSourceTask.java:360)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:229)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:284)
	at org.apache.kafka.connect.runtime.AbstractWorkerSourceTask.run(AbstractWorkerSourceTask.java:80)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:181)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-02-05 13:48:58,546] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Error sending fetch request (sessionId=1118953867, epoch=1) to node 0: (org.apache.kafka.clients.FetchSessionHandler:615)
org.apache.kafka.common.errors.DisconnectException
[2024-02-05 13:48:58,552] INFO [replicator-cloud|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = none
	bootstrap.servers = [pkc-4r087.us-west2.gcp.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = replicator-cloud-0
	client.rack = 
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = replicator-localhost
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:370)
[2024-02-05 13:48:58,598] INFO [replicator-cloud|task-0] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:48:58,598] INFO [replicator-cloud|task-0] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:48:58,598] INFO [replicator-cloud|task-0] Kafka startTimeMs: 1707121138598 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:48:58,826] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished reading to end of log and updated config snapshot, new config log offset: 20 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1717)
[2024-02-05 13:48:58,826] INFO [Worker clientId=connect-1, groupId=connect-cluster] Current config state offset 20 does not match group assignment 9. Forcing rebalance. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1660)
[2024-02-05 13:48:58,827] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:231)
[2024-02-05 13:48:58,827] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:576)
[2024-02-05 13:48:59,055] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=9, memberId='connect-1-5626c631-09b4-4bc6-b13c-f89c6adf07d0', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:637)
[2024-02-05 13:48:59,292] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=9, memberId='connect-1-5626c631-09b4-4bc6-b13c-f89c6adf07d0', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:812)
[2024-02-05 13:48:59,292] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 9 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-5626c631-09b4-4bc6-b13c-f89c6adf07d0', leaderUrl='http://127.0.1.1:8083/', offset=20, connectorIds=[s3-sink, jdbc_sink_connector, jdbc_source_postgres, replicator-cloud], taskIds=[s3-sink-0, jdbc_sink_connector-0, jdbc_source_postgres-0, replicator-cloud-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2416)
[2024-02-05 13:48:59,292] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 20 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1776)
[2024-02-05 13:48:59,292] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connector s3-sink (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1893)
[2024-02-05 13:48:59,293] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connector jdbc_source_postgres (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1893)
[2024-02-05 13:48:59,294] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting task s3-sink-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1818)
[2024-02-05 13:48:59,294] INFO [jdbc_source_postgres|worker] Creating connector jdbc_source_postgres of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:370)
[2024-02-05 13:48:59,294] INFO [s3-sink|worker] Creating connector s3-sink of type io.confluent.connect.s3.S3SinkConnector (org.apache.kafka.connect.runtime.Worker:370)
[2024-02-05 13:48:59,295] ERROR [s3-sink|worker] Failed to start connector s3-sink (org.apache.kafka.connect.runtime.Worker:406)
org.apache.kafka.connect.errors.ConnectException: Failed to find any class that implements Connector and which name matches io.confluent.connect.s3.S3SinkConnector, available connectors are: PluginDesc{klass=class io.confluent.connect.replicator.ReplicatorSourceConnector, name='io.confluent.connect.replicator.ReplicatorSourceConnector', version='7.5.2', encodedVersion=7.5.2, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSinkConnector, name='org.apache.kafka.connect.tools.MockSinkConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=sink, typeName='sink', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSourceConnector, name='org.apache.kafka.connect.tools.MockSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.SchemaSourceConnector, name='org.apache.kafka.connect.tools.SchemaSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSinkConnector, name='org.apache.kafka.connect.tools.VerifiableSinkConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=sink, typeName='sink', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSourceConnector, name='org.apache.kafka.connect.tools.VerifiableSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}
	at org.apache.kafka.connect.runtime.isolation.Plugins.connectorClass(Plugins.java:253)
	at org.apache.kafka.connect.runtime.isolation.Plugins.newConnector(Plugins.java:224)
	at org.apache.kafka.connect.runtime.Worker.startConnector(Worker.java:371)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startConnector(DistributedHerder.java:1920)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getConnectorStartingCallable$38(DistributedHerder.java:1926)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-02-05 13:48:59,295] WARN Unable to retrieve connector type (org.apache.kafka.connect.runtime.AbstractHerder:821)
org.apache.kafka.connect.errors.ConnectException: Failed to find any class that implements Connector and which name matches io.confluent.connect.s3.S3SinkConnector, available connectors are: PluginDesc{klass=class io.confluent.connect.replicator.ReplicatorSourceConnector, name='io.confluent.connect.replicator.ReplicatorSourceConnector', version='7.5.2', encodedVersion=7.5.2, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSinkConnector, name='org.apache.kafka.connect.tools.MockSinkConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=sink, typeName='sink', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSourceConnector, name='org.apache.kafka.connect.tools.MockSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.SchemaSourceConnector, name='org.apache.kafka.connect.tools.SchemaSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSinkConnector, name='org.apache.kafka.connect.tools.VerifiableSinkConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=sink, typeName='sink', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSourceConnector, name='org.apache.kafka.connect.tools.VerifiableSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}
	at org.apache.kafka.connect.runtime.isolation.Plugins.connectorClass(Plugins.java:253)
	at org.apache.kafka.connect.runtime.isolation.Plugins.newConnector(Plugins.java:224)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$getConnector$10(AbstractHerder.java:801)
	at java.base/java.util.concurrent.ConcurrentHashMap.computeIfAbsent(ConcurrentHashMap.java:1705)
	at org.apache.kafka.connect.runtime.AbstractHerder.getConnector(AbstractHerder.java:801)
	at org.apache.kafka.connect.runtime.AbstractHerder.connectorType(AbstractHerder.java:819)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startTask(DistributedHerder.java:1820)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getTaskStartingCallable$33(DistributedHerder.java:1872)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-02-05 13:48:59,296] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting task jdbc_sink_connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1818)
[2024-02-05 13:48:59,295] ERROR [jdbc_source_postgres|worker] Failed to start connector jdbc_source_postgres (org.apache.kafka.connect.runtime.Worker:406)
org.apache.kafka.connect.errors.ConnectException: Failed to find any class that implements Connector and which name matches io.confluent.connect.jdbc.JdbcSourceConnector, available connectors are: PluginDesc{klass=class io.confluent.connect.replicator.ReplicatorSourceConnector, name='io.confluent.connect.replicator.ReplicatorSourceConnector', version='7.5.2', encodedVersion=7.5.2, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSinkConnector, name='org.apache.kafka.connect.tools.MockSinkConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=sink, typeName='sink', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSourceConnector, name='org.apache.kafka.connect.tools.MockSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.SchemaSourceConnector, name='org.apache.kafka.connect.tools.SchemaSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSinkConnector, name='org.apache.kafka.connect.tools.VerifiableSinkConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=sink, typeName='sink', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSourceConnector, name='org.apache.kafka.connect.tools.VerifiableSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}
	at org.apache.kafka.connect.runtime.isolation.Plugins.connectorClass(Plugins.java:253)
	at org.apache.kafka.connect.runtime.isolation.Plugins.newConnector(Plugins.java:224)
	at org.apache.kafka.connect.runtime.Worker.startConnector(Worker.java:371)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startConnector(DistributedHerder.java:1920)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getConnectorStartingCallable$38(DistributedHerder.java:1926)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-02-05 13:48:59,296] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting task jdbc_source_postgres-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1818)
[2024-02-05 13:48:59,297] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connector jdbc_sink_connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1893)
[2024-02-05 13:48:59,297] INFO [jdbc_sink_connector|worker] Creating connector jdbc_sink_connector of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:370)
[2024-02-05 13:48:59,296] ERROR [Worker clientId=connect-1, groupId=connect-cluster] Couldn't instantiate task s3-sink-0 because it has an invalid task configuration. This task will not execute until reconfigured. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1874)
org.apache.kafka.connect.errors.ConnectException: Failed to start task s3-sink-0 since it is not a recognizable type (source or sink)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startTask(DistributedHerder.java:1865)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getTaskStartingCallable$33(DistributedHerder.java:1872)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-02-05 13:48:59,300] WARN Unable to retrieve connector type (org.apache.kafka.connect.runtime.AbstractHerder:821)
org.apache.kafka.connect.errors.ConnectException: Failed to find any class that implements Connector and which name matches io.confluent.connect.jdbc.JdbcSourceConnector, available connectors are: PluginDesc{klass=class io.confluent.connect.replicator.ReplicatorSourceConnector, name='io.confluent.connect.replicator.ReplicatorSourceConnector', version='7.5.2', encodedVersion=7.5.2, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSinkConnector, name='org.apache.kafka.connect.tools.MockSinkConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=sink, typeName='sink', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSourceConnector, name='org.apache.kafka.connect.tools.MockSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.SchemaSourceConnector, name='org.apache.kafka.connect.tools.SchemaSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSinkConnector, name='org.apache.kafka.connect.tools.VerifiableSinkConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=sink, typeName='sink', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSourceConnector, name='org.apache.kafka.connect.tools.VerifiableSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}
	at org.apache.kafka.connect.runtime.isolation.Plugins.connectorClass(Plugins.java:253)
	at org.apache.kafka.connect.runtime.isolation.Plugins.newConnector(Plugins.java:224)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$getConnector$10(AbstractHerder.java:801)
	at java.base/java.util.concurrent.ConcurrentHashMap.computeIfAbsent(ConcurrentHashMap.java:1705)
	at org.apache.kafka.connect.runtime.AbstractHerder.getConnector(AbstractHerder.java:801)
	at org.apache.kafka.connect.runtime.AbstractHerder.connectorType(AbstractHerder.java:819)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startTask(DistributedHerder.java:1820)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getTaskStartingCallable$33(DistributedHerder.java:1872)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-02-05 13:48:59,310] ERROR [Worker clientId=connect-1, groupId=connect-cluster] Couldn't instantiate task jdbc_source_postgres-0 because it has an invalid task configuration. This task will not execute until reconfigured. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1874)
org.apache.kafka.connect.errors.ConnectException: Failed to start task jdbc_source_postgres-0 since it is not a recognizable type (source or sink)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startTask(DistributedHerder.java:1865)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getTaskStartingCallable$33(DistributedHerder.java:1872)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-02-05 13:48:59,297] WARN Unable to retrieve connector type (org.apache.kafka.connect.runtime.AbstractHerder:821)
org.apache.kafka.connect.errors.ConnectException: Failed to find any class that implements Connector and which name matches io.confluent.connect.jdbc.JdbcSinkConnector, available connectors are: PluginDesc{klass=class io.confluent.connect.replicator.ReplicatorSourceConnector, name='io.confluent.connect.replicator.ReplicatorSourceConnector', version='7.5.2', encodedVersion=7.5.2, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSinkConnector, name='org.apache.kafka.connect.tools.MockSinkConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=sink, typeName='sink', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSourceConnector, name='org.apache.kafka.connect.tools.MockSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.SchemaSourceConnector, name='org.apache.kafka.connect.tools.SchemaSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSinkConnector, name='org.apache.kafka.connect.tools.VerifiableSinkConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=sink, typeName='sink', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSourceConnector, name='org.apache.kafka.connect.tools.VerifiableSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}
	at org.apache.kafka.connect.runtime.isolation.Plugins.connectorClass(Plugins.java:253)
	at org.apache.kafka.connect.runtime.isolation.Plugins.newConnector(Plugins.java:224)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$getConnector$10(AbstractHerder.java:801)
	at java.base/java.util.concurrent.ConcurrentHashMap.computeIfAbsent(ConcurrentHashMap.java:1705)
	at org.apache.kafka.connect.runtime.AbstractHerder.getConnector(AbstractHerder.java:801)
	at org.apache.kafka.connect.runtime.AbstractHerder.connectorType(AbstractHerder.java:819)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startTask(DistributedHerder.java:1820)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getTaskStartingCallable$33(DistributedHerder.java:1872)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-02-05 13:48:59,310] ERROR [Worker clientId=connect-1, groupId=connect-cluster] Couldn't instantiate task jdbc_sink_connector-0 because it has an invalid task configuration. This task will not execute until reconfigured. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1874)
org.apache.kafka.connect.errors.ConnectException: Failed to start task jdbc_sink_connector-0 since it is not a recognizable type (source or sink)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startTask(DistributedHerder.java:1865)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getTaskStartingCallable$33(DistributedHerder.java:1872)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-02-05 13:48:59,312] ERROR [jdbc_sink_connector|worker] Failed to start connector jdbc_sink_connector (org.apache.kafka.connect.runtime.Worker:406)
org.apache.kafka.connect.errors.ConnectException: Failed to find any class that implements Connector and which name matches io.confluent.connect.jdbc.JdbcSinkConnector, available connectors are: PluginDesc{klass=class io.confluent.connect.replicator.ReplicatorSourceConnector, name='io.confluent.connect.replicator.ReplicatorSourceConnector', version='7.5.2', encodedVersion=7.5.2, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSinkConnector, name='org.apache.kafka.connect.tools.MockSinkConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=sink, typeName='sink', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSourceConnector, name='org.apache.kafka.connect.tools.MockSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.SchemaSourceConnector, name='org.apache.kafka.connect.tools.SchemaSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSinkConnector, name='org.apache.kafka.connect.tools.VerifiableSinkConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=sink, typeName='sink', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSourceConnector, name='org.apache.kafka.connect.tools.VerifiableSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}
	at org.apache.kafka.connect.runtime.isolation.Plugins.connectorClass(Plugins.java:253)
	at org.apache.kafka.connect.runtime.isolation.Plugins.newConnector(Plugins.java:224)
	at org.apache.kafka.connect.runtime.Worker.startConnector(Worker.java:371)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startConnector(DistributedHerder.java:1920)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getConnectorStartingCallable$38(DistributedHerder.java:1926)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-02-05 13:48:59,356] ERROR [jdbc_source_postgres|worker] [Worker clientId=connect-1, groupId=connect-cluster] Failed to start connector 'jdbc_source_postgres' (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1928)
org.apache.kafka.connect.errors.ConnectException: Failed to start connector: jdbc_source_postgres
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$startConnector$36(DistributedHerder.java:1899)
	at org.apache.kafka.connect.runtime.Worker.startConnector(Worker.java:408)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startConnector(DistributedHerder.java:1920)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getConnectorStartingCallable$38(DistributedHerder.java:1926)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.apache.kafka.connect.errors.ConnectException: Failed to find any class that implements Connector and which name matches io.confluent.connect.jdbc.JdbcSourceConnector, available connectors are: PluginDesc{klass=class io.confluent.connect.replicator.ReplicatorSourceConnector, name='io.confluent.connect.replicator.ReplicatorSourceConnector', version='7.5.2', encodedVersion=7.5.2, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSinkConnector, name='org.apache.kafka.connect.tools.MockSinkConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=sink, typeName='sink', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSourceConnector, name='org.apache.kafka.connect.tools.MockSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.SchemaSourceConnector, name='org.apache.kafka.connect.tools.SchemaSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSinkConnector, name='org.apache.kafka.connect.tools.VerifiableSinkConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=sink, typeName='sink', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSourceConnector, name='org.apache.kafka.connect.tools.VerifiableSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}
	at org.apache.kafka.connect.runtime.isolation.Plugins.connectorClass(Plugins.java:253)
	at org.apache.kafka.connect.runtime.isolation.Plugins.newConnector(Plugins.java:224)
	at org.apache.kafka.connect.runtime.Worker.startConnector(Worker.java:371)
	... 6 more
[2024-02-05 13:48:59,357] ERROR [jdbc_sink_connector|worker] [Worker clientId=connect-1, groupId=connect-cluster] Failed to start connector 'jdbc_sink_connector' (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1928)
org.apache.kafka.connect.errors.ConnectException: Failed to start connector: jdbc_sink_connector
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$startConnector$36(DistributedHerder.java:1899)
	at org.apache.kafka.connect.runtime.Worker.startConnector(Worker.java:408)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startConnector(DistributedHerder.java:1920)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getConnectorStartingCallable$38(DistributedHerder.java:1926)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.apache.kafka.connect.errors.ConnectException: Failed to find any class that implements Connector and which name matches io.confluent.connect.jdbc.JdbcSinkConnector, available connectors are: PluginDesc{klass=class io.confluent.connect.replicator.ReplicatorSourceConnector, name='io.confluent.connect.replicator.ReplicatorSourceConnector', version='7.5.2', encodedVersion=7.5.2, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSinkConnector, name='org.apache.kafka.connect.tools.MockSinkConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=sink, typeName='sink', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSourceConnector, name='org.apache.kafka.connect.tools.MockSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.SchemaSourceConnector, name='org.apache.kafka.connect.tools.SchemaSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSinkConnector, name='org.apache.kafka.connect.tools.VerifiableSinkConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=sink, typeName='sink', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSourceConnector, name='org.apache.kafka.connect.tools.VerifiableSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}
	at org.apache.kafka.connect.runtime.isolation.Plugins.connectorClass(Plugins.java:253)
	at org.apache.kafka.connect.runtime.isolation.Plugins.newConnector(Plugins.java:224)
	at org.apache.kafka.connect.runtime.Worker.startConnector(Worker.java:371)
	... 6 more
[2024-02-05 13:48:59,357] ERROR [s3-sink|worker] [Worker clientId=connect-1, groupId=connect-cluster] Failed to start connector 's3-sink' (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1928)
org.apache.kafka.connect.errors.ConnectException: Failed to start connector: s3-sink
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$startConnector$36(DistributedHerder.java:1899)
	at org.apache.kafka.connect.runtime.Worker.startConnector(Worker.java:408)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startConnector(DistributedHerder.java:1920)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getConnectorStartingCallable$38(DistributedHerder.java:1926)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.apache.kafka.connect.errors.ConnectException: Failed to find any class that implements Connector and which name matches io.confluent.connect.s3.S3SinkConnector, available connectors are: PluginDesc{klass=class io.confluent.connect.replicator.ReplicatorSourceConnector, name='io.confluent.connect.replicator.ReplicatorSourceConnector', version='7.5.2', encodedVersion=7.5.2, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSinkConnector, name='org.apache.kafka.connect.tools.MockSinkConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=sink, typeName='sink', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSourceConnector, name='org.apache.kafka.connect.tools.MockSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.SchemaSourceConnector, name='org.apache.kafka.connect.tools.SchemaSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSinkConnector, name='org.apache.kafka.connect.tools.VerifiableSinkConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=sink, typeName='sink', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSourceConnector, name='org.apache.kafka.connect.tools.VerifiableSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}
	at org.apache.kafka.connect.runtime.isolation.Plugins.connectorClass(Plugins.java:253)
	at org.apache.kafka.connect.runtime.isolation.Plugins.newConnector(Plugins.java:224)
	at org.apache.kafka.connect.runtime.Worker.startConnector(Worker.java:371)
	... 6 more
[2024-02-05 13:48:59,360] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1804)
[2024-02-05 13:49:00,016] INFO [Worker clientId=connect-1, groupId=connect-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2284)
[2024-02-05 13:49:00,016] INFO [Worker clientId=connect-1, groupId=connect-cluster] Handling connector-only config update by restarting connector s3-sink (org.apache.kafka.connect.runtime.distributed.DistributedHerder:693)
[2024-02-05 13:49:00,017] INFO [s3-sink|worker] Stopping connector s3-sink (org.apache.kafka.connect.runtime.Worker:492)
[2024-02-05 13:49:00,017] WARN [s3-sink|worker] Ignoring stop request for unowned connector s3-sink (org.apache.kafka.connect.runtime.Worker:495)
[2024-02-05 13:49:00,017] WARN [s3-sink|worker] Ignoring await stop request for non-present connector s3-sink (org.apache.kafka.connect.runtime.Worker:516)
[2024-02-05 13:49:00,017] INFO [Worker clientId=connect-1, groupId=connect-cluster] Handling connector-only config update by restarting connector jdbc_sink_connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:693)
[2024-02-05 13:49:00,017] INFO [jdbc_sink_connector|worker] Stopping connector jdbc_sink_connector (org.apache.kafka.connect.runtime.Worker:492)
[2024-02-05 13:49:00,017] WARN [jdbc_sink_connector|worker] Ignoring stop request for unowned connector jdbc_sink_connector (org.apache.kafka.connect.runtime.Worker:495)
[2024-02-05 13:49:00,017] WARN [jdbc_sink_connector|worker] Ignoring await stop request for non-present connector jdbc_sink_connector (org.apache.kafka.connect.runtime.Worker:516)
[2024-02-05 13:49:00,017] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connector s3-sink (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1893)
[2024-02-05 13:49:00,017] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connector jdbc_sink_connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1893)
[2024-02-05 13:49:00,018] INFO [s3-sink|worker] Creating connector s3-sink of type io.confluent.connect.s3.S3SinkConnector (org.apache.kafka.connect.runtime.Worker:370)
[2024-02-05 13:49:00,018] INFO [jdbc_sink_connector|worker] Creating connector jdbc_sink_connector of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:370)
[2024-02-05 13:49:00,018] ERROR [jdbc_sink_connector|worker] Failed to start connector jdbc_sink_connector (org.apache.kafka.connect.runtime.Worker:406)
org.apache.kafka.connect.errors.ConnectException: Failed to find any class that implements Connector and which name matches io.confluent.connect.jdbc.JdbcSinkConnector, available connectors are: PluginDesc{klass=class io.confluent.connect.replicator.ReplicatorSourceConnector, name='io.confluent.connect.replicator.ReplicatorSourceConnector', version='7.5.2', encodedVersion=7.5.2, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSinkConnector, name='org.apache.kafka.connect.tools.MockSinkConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=sink, typeName='sink', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSourceConnector, name='org.apache.kafka.connect.tools.MockSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.SchemaSourceConnector, name='org.apache.kafka.connect.tools.SchemaSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSinkConnector, name='org.apache.kafka.connect.tools.VerifiableSinkConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=sink, typeName='sink', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSourceConnector, name='org.apache.kafka.connect.tools.VerifiableSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}
	at org.apache.kafka.connect.runtime.isolation.Plugins.connectorClass(Plugins.java:253)
	at org.apache.kafka.connect.runtime.isolation.Plugins.newConnector(Plugins.java:224)
	at org.apache.kafka.connect.runtime.Worker.startConnector(Worker.java:371)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startConnector(DistributedHerder.java:1920)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getConnectorStartingCallable$38(DistributedHerder.java:1926)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-02-05 13:49:00,018] ERROR [s3-sink|worker] Failed to start connector s3-sink (org.apache.kafka.connect.runtime.Worker:406)
org.apache.kafka.connect.errors.ConnectException: Failed to find any class that implements Connector and which name matches io.confluent.connect.s3.S3SinkConnector, available connectors are: PluginDesc{klass=class io.confluent.connect.replicator.ReplicatorSourceConnector, name='io.confluent.connect.replicator.ReplicatorSourceConnector', version='7.5.2', encodedVersion=7.5.2, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSinkConnector, name='org.apache.kafka.connect.tools.MockSinkConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=sink, typeName='sink', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSourceConnector, name='org.apache.kafka.connect.tools.MockSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.SchemaSourceConnector, name='org.apache.kafka.connect.tools.SchemaSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSinkConnector, name='org.apache.kafka.connect.tools.VerifiableSinkConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=sink, typeName='sink', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSourceConnector, name='org.apache.kafka.connect.tools.VerifiableSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}
	at org.apache.kafka.connect.runtime.isolation.Plugins.connectorClass(Plugins.java:253)
	at org.apache.kafka.connect.runtime.isolation.Plugins.newConnector(Plugins.java:224)
	at org.apache.kafka.connect.runtime.Worker.startConnector(Worker.java:371)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startConnector(DistributedHerder.java:1920)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getConnectorStartingCallable$38(DistributedHerder.java:1926)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-02-05 13:49:00,020] ERROR [jdbc_sink_connector|worker] [Worker clientId=connect-1, groupId=connect-cluster] Failed to start connector 'jdbc_sink_connector' (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1928)
org.apache.kafka.connect.errors.ConnectException: Failed to start connector: jdbc_sink_connector
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$startConnector$36(DistributedHerder.java:1899)
	at org.apache.kafka.connect.runtime.Worker.startConnector(Worker.java:408)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startConnector(DistributedHerder.java:1920)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getConnectorStartingCallable$38(DistributedHerder.java:1926)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.apache.kafka.connect.errors.ConnectException: Failed to find any class that implements Connector and which name matches io.confluent.connect.jdbc.JdbcSinkConnector, available connectors are: PluginDesc{klass=class io.confluent.connect.replicator.ReplicatorSourceConnector, name='io.confluent.connect.replicator.ReplicatorSourceConnector', version='7.5.2', encodedVersion=7.5.2, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSinkConnector, name='org.apache.kafka.connect.tools.MockSinkConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=sink, typeName='sink', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSourceConnector, name='org.apache.kafka.connect.tools.MockSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.SchemaSourceConnector, name='org.apache.kafka.connect.tools.SchemaSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSinkConnector, name='org.apache.kafka.connect.tools.VerifiableSinkConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=sink, typeName='sink', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSourceConnector, name='org.apache.kafka.connect.tools.VerifiableSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}
	at org.apache.kafka.connect.runtime.isolation.Plugins.connectorClass(Plugins.java:253)
	at org.apache.kafka.connect.runtime.isolation.Plugins.newConnector(Plugins.java:224)
	at org.apache.kafka.connect.runtime.Worker.startConnector(Worker.java:371)
	... 6 more
[2024-02-05 13:49:00,020] ERROR [s3-sink|worker] [Worker clientId=connect-1, groupId=connect-cluster] Failed to start connector 's3-sink' (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1928)
org.apache.kafka.connect.errors.ConnectException: Failed to start connector: s3-sink
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$startConnector$36(DistributedHerder.java:1899)
	at org.apache.kafka.connect.runtime.Worker.startConnector(Worker.java:408)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startConnector(DistributedHerder.java:1920)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getConnectorStartingCallable$38(DistributedHerder.java:1926)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.apache.kafka.connect.errors.ConnectException: Failed to find any class that implements Connector and which name matches io.confluent.connect.s3.S3SinkConnector, available connectors are: PluginDesc{klass=class io.confluent.connect.replicator.ReplicatorSourceConnector, name='io.confluent.connect.replicator.ReplicatorSourceConnector', version='7.5.2', encodedVersion=7.5.2, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSinkConnector, name='org.apache.kafka.connect.tools.MockSinkConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=sink, typeName='sink', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSourceConnector, name='org.apache.kafka.connect.tools.MockSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.SchemaSourceConnector, name='org.apache.kafka.connect.tools.SchemaSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSinkConnector, name='org.apache.kafka.connect.tools.VerifiableSinkConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=sink, typeName='sink', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSourceConnector, name='org.apache.kafka.connect.tools.VerifiableSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}
	at org.apache.kafka.connect.runtime.isolation.Plugins.connectorClass(Plugins.java:253)
	at org.apache.kafka.connect.runtime.isolation.Plugins.newConnector(Plugins.java:224)
	at org.apache.kafka.connect.runtime.Worker.startConnector(Worker.java:371)
	... 6 more
[2024-02-05 13:49:00,021] INFO [Worker clientId=connect-1, groupId=connect-cluster] Handling task config update by stopping tasks [s3-sink-0, jdbc_sink_connector-0, jdbc_source_postgres-0], which will be restarted after rebalance if still assigned to this worker (org.apache.kafka.connect.runtime.distributed.DistributedHerder:758)
[2024-02-05 13:49:00,021] WARN [s3-sink|task-0] Ignoring stop request for unowned task s3-sink-0 (org.apache.kafka.connect.runtime.Worker:1284)
[2024-02-05 13:49:00,021] WARN [jdbc_sink_connector|task-0] Ignoring stop request for unowned task jdbc_sink_connector-0 (org.apache.kafka.connect.runtime.Worker:1284)
[2024-02-05 13:49:00,021] WARN [jdbc_source_postgres|task-0] Ignoring stop request for unowned task jdbc_source_postgres-0 (org.apache.kafka.connect.runtime.Worker:1284)
[2024-02-05 13:49:00,021] WARN [s3-sink|task-0] Ignoring await stop request for non-present task s3-sink-0 (org.apache.kafka.connect.runtime.Worker:1310)
[2024-02-05 13:49:00,022] WARN [jdbc_sink_connector|task-0] Ignoring await stop request for non-present task jdbc_sink_connector-0 (org.apache.kafka.connect.runtime.Worker:1310)
[2024-02-05 13:49:00,022] WARN [jdbc_source_postgres|task-0] Ignoring await stop request for non-present task jdbc_source_postgres-0 (org.apache.kafka.connect.runtime.Worker:1310)
[2024-02-05 13:49:00,022] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:231)
[2024-02-05 13:49:00,022] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:576)
[2024-02-05 13:49:00,235] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=10, memberId='connect-1-5626c631-09b4-4bc6-b13c-f89c6adf07d0', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:637)
[2024-02-05 13:49:00,473] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=10, memberId='connect-1-5626c631-09b4-4bc6-b13c-f89c6adf07d0', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:812)
[2024-02-05 13:49:00,473] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 10 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-5626c631-09b4-4bc6-b13c-f89c6adf07d0', leaderUrl='http://127.0.1.1:8083/', offset=21, connectorIds=[s3-sink, jdbc_sink_connector, jdbc_source_postgres, replicator-cloud], taskIds=[s3-sink-0, jdbc_sink_connector-0, jdbc_source_postgres-0, replicator-cloud-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2416)
[2024-02-05 13:49:00,474] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 21 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1776)
[2024-02-05 13:49:00,474] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting task s3-sink-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1818)
[2024-02-05 13:49:00,474] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting task jdbc_source_postgres-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1818)
[2024-02-05 13:49:00,474] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting task jdbc_sink_connector-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1818)
[2024-02-05 13:49:00,475] WARN Unable to retrieve connector type (org.apache.kafka.connect.runtime.AbstractHerder:821)
org.apache.kafka.connect.errors.ConnectException: Failed to find any class that implements Connector and which name matches io.confluent.connect.jdbc.JdbcSourceConnector, available connectors are: PluginDesc{klass=class io.confluent.connect.replicator.ReplicatorSourceConnector, name='io.confluent.connect.replicator.ReplicatorSourceConnector', version='7.5.2', encodedVersion=7.5.2, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSinkConnector, name='org.apache.kafka.connect.tools.MockSinkConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=sink, typeName='sink', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSourceConnector, name='org.apache.kafka.connect.tools.MockSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.SchemaSourceConnector, name='org.apache.kafka.connect.tools.SchemaSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSinkConnector, name='org.apache.kafka.connect.tools.VerifiableSinkConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=sink, typeName='sink', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSourceConnector, name='org.apache.kafka.connect.tools.VerifiableSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}
	at org.apache.kafka.connect.runtime.isolation.Plugins.connectorClass(Plugins.java:253)
	at org.apache.kafka.connect.runtime.isolation.Plugins.newConnector(Plugins.java:224)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$getConnector$10(AbstractHerder.java:801)
	at java.base/java.util.concurrent.ConcurrentHashMap.computeIfAbsent(ConcurrentHashMap.java:1705)
	at org.apache.kafka.connect.runtime.AbstractHerder.getConnector(AbstractHerder.java:801)
	at org.apache.kafka.connect.runtime.AbstractHerder.connectorType(AbstractHerder.java:819)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startTask(DistributedHerder.java:1820)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getTaskStartingCallable$33(DistributedHerder.java:1872)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-02-05 13:49:00,475] WARN Unable to retrieve connector type (org.apache.kafka.connect.runtime.AbstractHerder:821)
org.apache.kafka.connect.errors.ConnectException: Failed to find any class that implements Connector and which name matches io.confluent.connect.jdbc.JdbcSinkConnector, available connectors are: PluginDesc{klass=class io.confluent.connect.replicator.ReplicatorSourceConnector, name='io.confluent.connect.replicator.ReplicatorSourceConnector', version='7.5.2', encodedVersion=7.5.2, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSinkConnector, name='org.apache.kafka.connect.tools.MockSinkConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=sink, typeName='sink', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSourceConnector, name='org.apache.kafka.connect.tools.MockSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.SchemaSourceConnector, name='org.apache.kafka.connect.tools.SchemaSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSinkConnector, name='org.apache.kafka.connect.tools.VerifiableSinkConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=sink, typeName='sink', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSourceConnector, name='org.apache.kafka.connect.tools.VerifiableSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}
	at org.apache.kafka.connect.runtime.isolation.Plugins.connectorClass(Plugins.java:253)
	at org.apache.kafka.connect.runtime.isolation.Plugins.newConnector(Plugins.java:224)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$getConnector$10(AbstractHerder.java:801)
	at java.base/java.util.concurrent.ConcurrentHashMap.computeIfAbsent(ConcurrentHashMap.java:1705)
	at org.apache.kafka.connect.runtime.AbstractHerder.getConnector(AbstractHerder.java:801)
	at org.apache.kafka.connect.runtime.AbstractHerder.connectorType(AbstractHerder.java:819)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startTask(DistributedHerder.java:1820)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getTaskStartingCallable$33(DistributedHerder.java:1872)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-02-05 13:49:00,475] WARN Unable to retrieve connector type (org.apache.kafka.connect.runtime.AbstractHerder:821)
org.apache.kafka.connect.errors.ConnectException: Failed to find any class that implements Connector and which name matches io.confluent.connect.s3.S3SinkConnector, available connectors are: PluginDesc{klass=class io.confluent.connect.replicator.ReplicatorSourceConnector, name='io.confluent.connect.replicator.ReplicatorSourceConnector', version='7.5.2', encodedVersion=7.5.2, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSinkConnector, name='org.apache.kafka.connect.tools.MockSinkConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=sink, typeName='sink', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSourceConnector, name='org.apache.kafka.connect.tools.MockSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.SchemaSourceConnector, name='org.apache.kafka.connect.tools.SchemaSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSinkConnector, name='org.apache.kafka.connect.tools.VerifiableSinkConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=sink, typeName='sink', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSourceConnector, name='org.apache.kafka.connect.tools.VerifiableSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}
	at org.apache.kafka.connect.runtime.isolation.Plugins.connectorClass(Plugins.java:253)
	at org.apache.kafka.connect.runtime.isolation.Plugins.newConnector(Plugins.java:224)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$getConnector$10(AbstractHerder.java:801)
	at java.base/java.util.concurrent.ConcurrentHashMap.computeIfAbsent(ConcurrentHashMap.java:1705)
	at org.apache.kafka.connect.runtime.AbstractHerder.getConnector(AbstractHerder.java:801)
	at org.apache.kafka.connect.runtime.AbstractHerder.connectorType(AbstractHerder.java:819)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startTask(DistributedHerder.java:1820)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getTaskStartingCallable$33(DistributedHerder.java:1872)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-02-05 13:49:00,476] ERROR [Worker clientId=connect-1, groupId=connect-cluster] Couldn't instantiate task jdbc_sink_connector-0 because it has an invalid task configuration. This task will not execute until reconfigured. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1874)
org.apache.kafka.connect.errors.ConnectException: Failed to start task jdbc_sink_connector-0 since it is not a recognizable type (source or sink)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startTask(DistributedHerder.java:1865)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getTaskStartingCallable$33(DistributedHerder.java:1872)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-02-05 13:49:00,475] ERROR [Worker clientId=connect-1, groupId=connect-cluster] Couldn't instantiate task jdbc_source_postgres-0 because it has an invalid task configuration. This task will not execute until reconfigured. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1874)
org.apache.kafka.connect.errors.ConnectException: Failed to start task jdbc_source_postgres-0 since it is not a recognizable type (source or sink)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startTask(DistributedHerder.java:1865)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getTaskStartingCallable$33(DistributedHerder.java:1872)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-02-05 13:49:00,476] ERROR [Worker clientId=connect-1, groupId=connect-cluster] Couldn't instantiate task s3-sink-0 because it has an invalid task configuration. This task will not execute until reconfigured. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1874)
org.apache.kafka.connect.errors.ConnectException: Failed to start task s3-sink-0 since it is not a recognizable type (source or sink)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startTask(DistributedHerder.java:1865)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getTaskStartingCallable$33(DistributedHerder.java:1872)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-02-05 13:49:00,478] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1804)
[2024-02-05 13:49:00,574] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-localhost] Cluster ID: lkc-qpjpkm (org.apache.kafka.clients.Metadata:287)
[2024-02-05 13:49:02,853] INFO [replicator-cloud|task-0|offsets] WorkerSourceTask{id=replicator-cloud-0} Committing offsets for 82 acknowledged messages (org.apache.kafka.connect.runtime.WorkerSourceTask:232)
[2024-02-05 13:49:04,851] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-localhost] Discovered group coordinator b11-pkc-4r087.us-west2.gcp.confluent.cloud:9092 (id: 2147483636 rack: null) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:906)
[2024-02-05 13:49:06,677] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-localhost] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1025)
[2024-02-05 13:49:06,677] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-localhost] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1072)
[2024-02-05 13:49:06,678] INFO [replicator-cloud|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:49:06,679] INFO [replicator-cloud|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:49:06,679] INFO [replicator-cloud|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:49:06,685] INFO [replicator-cloud|task-0] App info kafka.consumer for replicator-cloud-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:49:06,687] INFO [replicator-cloud|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = none
	bootstrap.servers = [pkc-4r087.us-west2.gcp.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = replicator-cloud-0
	client.rack = 
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ConsumerGroup1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:370)
[2024-02-05 13:49:06,701] INFO [replicator-cloud|task-0] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:49:06,701] INFO [replicator-cloud|task-0] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:49:06,701] INFO [replicator-cloud|task-0] Kafka startTimeMs: 1707121146701 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:49:08,493] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=ConsumerGroup1] Cluster ID: lkc-qpjpkm (org.apache.kafka.clients.Metadata:287)
[2024-02-05 13:49:12,550] WARN [replicator-cloud|task-0] Could not find offset for group ConsumerGroup1, topic stream_ip, partition 0, timestamp 1704871412056:7, waiting for replication to catch up.  Please check replication lag. (io.confluent.connect.replicator.offsets.ConsumerOffsetsTranslator:426)
[2024-02-05 13:49:12,550] WARN [replicator-cloud|task-0] Could not find offset for group ConsumerGroup1, topic stream_op3, partition 0, timestamp 1704867999328, waiting for replication to catch up.  Please check replication lag. (io.confluent.connect.replicator.offsets.ConsumerOffsetsTranslator:426)
[2024-02-05 13:49:12,551] WARN [replicator-cloud|task-0] Could not find offset for group ConsumerGroup1, topic stream_op1, partition 0, timestamp 1704866647275:5, waiting for replication to catch up.  Please check replication lag. (io.confluent.connect.replicator.offsets.ConsumerOffsetsTranslator:426)
[2024-02-05 13:49:12,551] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=ConsumerGroup1] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1025)
[2024-02-05 13:49:12,552] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=ConsumerGroup1] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1072)
[2024-02-05 13:49:12,553] INFO [replicator-cloud|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:49:12,553] INFO [replicator-cloud|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:49:12,554] INFO [replicator-cloud|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:49:12,562] INFO [replicator-cloud|task-0] App info kafka.consumer for replicator-cloud-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:49:12,564] INFO [replicator-cloud|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = none
	bootstrap.servers = [pkc-4r087.us-west2.gcp.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = replicator-cloud-0
	client.rack = 
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ConsumerGroup2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:370)
[2024-02-05 13:49:12,574] INFO [replicator-cloud|task-0] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:49:12,574] INFO [replicator-cloud|task-0] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:49:12,574] INFO [replicator-cloud|task-0] Kafka startTimeMs: 1707121152574 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:49:14,275] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=ConsumerGroup2] Cluster ID: lkc-qpjpkm (org.apache.kafka.clients.Metadata:287)
[2024-02-05 13:49:18,139] WARN [replicator-cloud|task-0] Could not find offset for group ConsumerGroup2, topic stream_op3, partition 0, timestamp 1705037816254:8, waiting for replication to catch up.  Please check replication lag. (io.confluent.connect.replicator.offsets.ConsumerOffsetsTranslator:426)
[2024-02-05 13:49:18,139] WARN [replicator-cloud|task-0] Could not find offset for group ConsumerGroup2, topic stream_op1, partition 0, timestamp 1704875562566:2, waiting for replication to catch up.  Please check replication lag. (io.confluent.connect.replicator.offsets.ConsumerOffsetsTranslator:426)
[2024-02-05 13:49:18,139] WARN [replicator-cloud|task-0] Could not find offset for group ConsumerGroup2, topic stream_op2, partition 0, timestamp 1705037455440:7, waiting for replication to catch up.  Please check replication lag. (io.confluent.connect.replicator.offsets.ConsumerOffsetsTranslator:426)
[2024-02-05 13:49:18,139] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=ConsumerGroup2] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1025)
[2024-02-05 13:49:18,140] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=ConsumerGroup2] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1072)
[2024-02-05 13:49:18,140] INFO [replicator-cloud|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:49:18,140] INFO [replicator-cloud|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:49:18,140] INFO [replicator-cloud|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:49:18,142] INFO [replicator-cloud|task-0] App info kafka.consumer for replicator-cloud-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:49:18,142] INFO [replicator-cloud|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = none
	bootstrap.servers = [pkc-4r087.us-west2.gcp.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = replicator-cloud-0
	client.rack = 
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = replicator
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:370)
[2024-02-05 13:49:18,145] INFO [replicator-cloud|task-0] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:49:18,145] INFO [replicator-cloud|task-0] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:49:18,145] INFO [replicator-cloud|task-0] Kafka startTimeMs: 1707121158145 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:49:19,950] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator] Cluster ID: lkc-qpjpkm (org.apache.kafka.clients.Metadata:287)
[2024-02-05 13:49:22,873] INFO [AdminClient clientId=connect-cluster--shared-admin] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:1090)
[2024-02-05 13:49:23,482] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator] Discovered group coordinator b2-pkc-4r087.us-west2.gcp.confluent.cloud:9092 (id: 2147483645 rack: null) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:906)
[2024-02-05 13:49:25,220] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1025)
[2024-02-05 13:49:25,221] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1072)
[2024-02-05 13:49:25,221] INFO [replicator-cloud|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:49:25,222] INFO [replicator-cloud|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:49:25,222] INFO [replicator-cloud|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:49:25,227] INFO [replicator-cloud|task-0] App info kafka.consumer for replicator-cloud-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:49:25,228] INFO [replicator-cloud|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = none
	bootstrap.servers = [pkc-4r087.us-west2.gcp.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = replicator-cloud-0
	client.rack = 
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ConsumerGroup3
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:370)
[2024-02-05 13:49:25,245] INFO [replicator-cloud|task-0] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:49:25,246] INFO [replicator-cloud|task-0] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:49:25,246] INFO [replicator-cloud|task-0] Kafka startTimeMs: 1707121165245 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:49:27,121] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=ConsumerGroup3] Cluster ID: lkc-qpjpkm (org.apache.kafka.clients.Metadata:287)
[2024-02-05 13:49:30,748] WARN [replicator-cloud|task-0] Could not find offset for group ConsumerGroup3, topic output_topic, partition 0, timestamp 1705055731393:4, waiting for replication to catch up.  Please check replication lag. (io.confluent.connect.replicator.offsets.ConsumerOffsetsTranslator:426)
[2024-02-05 13:49:30,749] WARN [replicator-cloud|task-0] Could not find offset for group ConsumerGroup3, topic stream_ip, partition 0, timestamp 1705037816254:8, waiting for replication to catch up.  Please check replication lag. (io.confluent.connect.replicator.offsets.ConsumerOffsetsTranslator:426)
[2024-02-05 13:49:30,749] WARN [replicator-cloud|task-0] Could not find offset for group ConsumerGroup3, topic stream_opnew, partition 0, timestamp 1705052302916:1, waiting for replication to catch up.  Please check replication lag. (io.confluent.connect.replicator.offsets.ConsumerOffsetsTranslator:426)
[2024-02-05 13:49:30,750] WARN [replicator-cloud|task-0] Could not find offset for group ConsumerGroup3, topic stream_opt, partition 0, timestamp 1705043913303:3, waiting for replication to catch up.  Please check replication lag. (io.confluent.connect.replicator.offsets.ConsumerOffsetsTranslator:426)
[2024-02-05 13:49:30,750] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=ConsumerGroup3] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1025)
[2024-02-05 13:49:30,751] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=ConsumerGroup3] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1072)
[2024-02-05 13:49:30,752] INFO [replicator-cloud|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:49:30,752] INFO [replicator-cloud|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:49:30,753] INFO [replicator-cloud|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:49:30,770] INFO [replicator-cloud|task-0] App info kafka.consumer for replicator-cloud-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:49:30,773] INFO [replicator-cloud|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = none
	bootstrap.servers = [pkc-4r087.us-west2.gcp.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = replicator-cloud-0
	client.rack = 
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = replicator-config
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:370)
[2024-02-05 13:49:30,816] INFO [replicator-cloud|task-0] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:49:30,816] INFO [replicator-cloud|task-0] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:49:30,816] INFO [replicator-cloud|task-0] Kafka startTimeMs: 1707121170816 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:49:32,601] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-config] Cluster ID: lkc-qpjpkm (org.apache.kafka.clients.Metadata:287)
[2024-02-05 13:49:36,728] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-config] Discovered group coordinator b11-pkc-4r087.us-west2.gcp.confluent.cloud:9092 (id: 2147483636 rack: null) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:906)
[2024-02-05 13:49:38,401] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-config] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1025)
[2024-02-05 13:49:38,402] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-config] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1072)
[2024-02-05 13:49:38,403] INFO [replicator-cloud|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:49:38,403] INFO [replicator-cloud|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:49:38,404] INFO [replicator-cloud|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:49:38,408] INFO [replicator-cloud|task-0] App info kafka.consumer for replicator-cloud-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:49:38,410] INFO [replicator-cloud|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = none
	bootstrap.servers = [pkc-4r087.us-west2.gcp.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = replicator-cloud-0
	client.rack = 
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ConsumerGroup11
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:370)
[2024-02-05 13:49:38,420] INFO [replicator-cloud|task-0] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:49:38,421] INFO [replicator-cloud|task-0] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:49:38,421] INFO [replicator-cloud|task-0] Kafka startTimeMs: 1707121178420 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:49:40,234] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=ConsumerGroup11] Cluster ID: lkc-qpjpkm (org.apache.kafka.clients.Metadata:287)
[2024-02-05 13:49:43,858] WARN [replicator-cloud|task-0] Could not find offset for group ConsumerGroup11, topic kafka-streams-aggregation-count-store-changelog, partition 0, timestamp 1704800086245, waiting for replication to catch up.  Please check replication lag. (io.confluent.connect.replicator.offsets.ConsumerOffsetsTranslator:426)
[2024-02-05 13:49:43,859] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=ConsumerGroup11] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1025)
[2024-02-05 13:49:43,860] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=ConsumerGroup11] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1072)
[2024-02-05 13:49:43,861] INFO [replicator-cloud|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:49:43,861] INFO [replicator-cloud|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:49:43,862] INFO [replicator-cloud|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:49:43,866] INFO [replicator-cloud|task-0] App info kafka.consumer for replicator-cloud-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:49:43,870] INFO [replicator-cloud|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = none
	bootstrap.servers = [pkc-4r087.us-west2.gcp.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = replicator-cloud-0
	client.rack = 
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ConsumerGroup10
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:370)
[2024-02-05 13:49:43,882] INFO [replicator-cloud|task-0] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:49:43,882] INFO [replicator-cloud|task-0] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:49:43,883] INFO [replicator-cloud|task-0] Kafka startTimeMs: 1707121183882 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:49:45,752] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=ConsumerGroup10] Cluster ID: lkc-qpjpkm (org.apache.kafka.clients.Metadata:287)
[2024-02-05 13:49:49,395] WARN [replicator-cloud|task-0] Could not find offset for group ConsumerGroup10, topic kafka-streams-aggregation-count-store-changelog, partition 0, timestamp 1704800086245, waiting for replication to catch up.  Please check replication lag. (io.confluent.connect.replicator.offsets.ConsumerOffsetsTranslator:426)
[2024-02-05 13:49:49,396] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=ConsumerGroup10] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1025)
[2024-02-05 13:49:49,396] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=ConsumerGroup10] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1072)
[2024-02-05 13:49:49,397] INFO [replicator-cloud|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:49:49,398] INFO [replicator-cloud|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:49:49,399] INFO [replicator-cloud|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:49:49,403] INFO [replicator-cloud|task-0] App info kafka.consumer for replicator-cloud-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:49:49,407] WARN [replicator-cloud|task-0] Commit of offsets threw an unexpected exception: {connect-configs-0=OffsetAndMetadata{offset=152, leaderEpoch=null, metadata=''}, __consumer_timestamps-13=OffsetAndMetadata{offset=1, leaderEpoch=null, metadata=''}, __consumer_timestamps-44=OffsetAndMetadata{offset=1, leaderEpoch=null, metadata=''}, __consumer_timestamps-11=OffsetAndMetadata{offset=1, leaderEpoch=null, metadata=''}, stream_int-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog-0=OffsetAndMetadata{offset=25, leaderEpoch=null, metadata=''}, __consumer_timestamps-21=OffsetAndMetadata{offset=1, leaderEpoch=null, metadata=''}, connect-offsets-0=OffsetAndMetadata{offset=3, leaderEpoch=null, metadata=''}, __consumer_timestamps-19=OffsetAndMetadata{offset=1, leaderEpoch=null, metadata=''}, __consumer_timestamps-17=OffsetAndMetadata{offset=3, leaderEpoch=null, metadata=''}, connect-offsets-24=OffsetAndMetadata{offset=9, leaderEpoch=null, metadata=''}, postgres-userdata-0=OffsetAndMetadata{offset=24, leaderEpoch=null, metadata=''}, _confluent_balancer_api_state-0=OffsetAndMetadata{offset=2, leaderEpoch=null, metadata=''}, __consumer_timestamps-39=OffsetAndMetadata{offset=1, leaderEpoch=null, metadata=''}, postgres-data-0=OffsetAndMetadata{offset=1, leaderEpoch=null, metadata=''}, connect-status-2=OffsetAndMetadata{offset=92, leaderEpoch=null, metadata=''}, connect-offsets-16=OffsetAndMetadata{offset=7, leaderEpoch=null, metadata=''}, connect-status-0=OffsetAndMetadata{offset=97, leaderEpoch=null, metadata=''}, connect-offsets-20=OffsetAndMetadata{offset=13, leaderEpoch=null, metadata=''}, __consumer_timestamps-0=OffsetAndMetadata{offset=9, leaderEpoch=null, metadata=''}, connect-status-4=OffsetAndMetadata{offset=136, leaderEpoch=null, metadata=''}, _schemas-0=OffsetAndMetadata{offset=10, leaderEpoch=null, metadata=''}, __consumer_timestamps-43=OffsetAndMetadata{offset=2, leaderEpoch=null, metadata=''}, __consumer_timestamps-10=OffsetAndMetadata{offset=5, leaderEpoch=null, metadata=''}, postgres-userdata-replica-0=OffsetAndMetadata{offset=24, leaderEpoch=null, metadata=''}, __consumer_timestamps-8=OffsetAndMetadata{offset=10, leaderEpoch=null, metadata=''}, __consumer_timestamps-22=OffsetAndMetadata{offset=5, leaderEpoch=null, metadata=''}, __consumer_timestamps-49=OffsetAndMetadata{offset=3, leaderEpoch=null, metadata=''}, stream_ip-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog-0=OffsetAndMetadata{offset=220, leaderEpoch=null, metadata=''}, connect-status-1=OffsetAndMetadata{offset=26, leaderEpoch=null, metadata=''}, __consumer_timestamps-5=OffsetAndMetadata{offset=1, leaderEpoch=null, metadata=''}, __consumer_timestamps-36=OffsetAndMetadata{offset=1, leaderEpoch=null, metadata=''}, connect-status-3=OffsetAndMetadata{offset=40, leaderEpoch=null, metadata=''}} (io.confluent.connect.replicator.offsets.ConsumerOffsetsTopicCommitter:271)
org.apache.kafka.common.errors.WakeupException
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.maybeTriggerWakeup(ConsumerNetworkClient.java:529)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:293)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:230)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.commitOffsetsSync(ConsumerCoordinator.java:1176)
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1518)
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1465)
	at io.confluent.connect.replicator.offsets.ConsumerOffsetsTopicCommitter.commitConsumerOffset(ConsumerOffsetsTopicCommitter.java:268)
	at io.confluent.connect.replicator.offsets.ConsumerOffsetsTopicCommitter.checkCommit(ConsumerOffsetsTopicCommitter.java:253)
	at io.confluent.connect.replicator.ReplicatorSourceTask.poll(ReplicatorSourceTask.java:471)
	at org.apache.kafka.connect.runtime.AbstractWorkerSourceTask.poll(AbstractWorkerSourceTask.java:488)
	at org.apache.kafka.connect.runtime.AbstractWorkerSourceTask.execute(AbstractWorkerSourceTask.java:360)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:229)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:284)
	at org.apache.kafka.connect.runtime.AbstractWorkerSourceTask.run(AbstractWorkerSourceTask.java:80)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:181)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-02-05 13:49:49,410] INFO [replicator-cloud|task-0] Fetching destination topic metadata for destination topic _confluent-telemetry-metrics (io.confluent.connect.replicator.ReplicatorSourceTask:1128)
[2024-02-05 13:49:49,410] INFO [replicator-cloud|task-0] Fetching source topic configs for source topic _confluent-telemetry-metrics (io.confluent.connect.replicator.ReplicatorSourceTask:1135)
[2024-02-05 13:49:49,417] INFO [replicator-cloud|task-0] Using user-specified replication factor of 3 for creating destination topic _confluent-telemetry-metrics (io.confluent.connect.replicator.ReplicatorSourceTask:1151)
[2024-02-05 13:49:49,666] INFO [replicator-cloud|task-0] Creating topic _confluent-telemetry-metrics in destination cluster with 12 partitions and replication factor 3 (io.confluent.connect.replicator.ReplicatorSourceTask:1186)
[2024-02-05 13:49:49,666] INFO [replicator-cloud|task-0] Creating topic _confluent-telemetry-metrics with Optional[12] partitions, replication factor Optional[3], and config {max.message.bytes=10485760, message.timestamp.type=CreateTime, min.insync.replicas=1, retention.ms=259200000, segment.ms=14400000, retention.bytes=-1} (io.confluent.connect.replicator.util.ReplicatorAdminClient:340)
[2024-02-05 13:49:49,892] WARN [replicator-cloud|task-0] Encountered exception when trying to create destination topic _confluent-telemetry-metrics:  (io.confluent.connect.replicator.ReplicatorSourceTask:1195)
java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.PolicyViolationException: Config property 'max.message.bytes' with value '10485760' is larger than the maximum allowed value of of 8388608.
	at java.base/java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:395)
	at java.base/java.util.concurrent.CompletableFuture.get(CompletableFuture.java:2005)
	at org.apache.kafka.common.internals.KafkaFutureImpl.get(KafkaFutureImpl.java:165)
	at io.confluent.connect.replicator.util.NewReplicatorAdminClient.createTopic(NewReplicatorAdminClient.java:357)
	at io.confluent.connect.replicator.util.NewReplicatorAdminClient.createTopic(NewReplicatorAdminClient.java:330)
	at io.confluent.connect.replicator.util.NewReplicatorAdminClient.createTopic(NewReplicatorAdminClient.java:319)
	at io.confluent.connect.replicator.ReplicatorSourceTask.maybeCreateOrExpandDestTopic(ReplicatorSourceTask.java:1192)
	at io.confluent.connect.replicator.ReplicatorSourceTask.retryTopicExpansionIfNeeded(ReplicatorSourceTask.java:1009)
	at io.confluent.connect.replicator.ReplicatorSourceTask.poll(ReplicatorSourceTask.java:476)
	at org.apache.kafka.connect.runtime.AbstractWorkerSourceTask.poll(AbstractWorkerSourceTask.java:488)
	at org.apache.kafka.connect.runtime.AbstractWorkerSourceTask.execute(AbstractWorkerSourceTask.java:360)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:229)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:284)
	at org.apache.kafka.connect.runtime.AbstractWorkerSourceTask.run(AbstractWorkerSourceTask.java:80)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:181)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.apache.kafka.common.errors.PolicyViolationException: Config property 'max.message.bytes' with value '10485760' is larger than the maximum allowed value of of 8388608.
[2024-02-05 13:49:50,121] INFO [replicator-cloud|task-0] Updating configuration of destination topic connect-configs with properties {cleanup.policy=compact, message.timestamp.type=CreateTime} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:49:50,847] INFO [replicator-cloud|task-0] Updating configuration of destination topic output_topic with properties {message.timestamp.type=CreateTime} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:49:51,569] INFO [replicator-cloud|task-0] Updating configuration of destination topic kafka-streams-aggregation-count-store-changelog with properties {cleanup.policy=compact,delete, message.timestamp.type=CreateTime, retention.ms=172800000} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:49:52,256] INFO [replicator-cloud|task-0] Updating configuration of destination topic input_topic with properties {message.timestamp.type=CreateTime} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:49:52,991] INFO [replicator-cloud|task-0] Updating configuration of destination topic stream_int-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog with properties {cleanup.policy=compact, message.timestamp.type=CreateTime} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:49:53,654] INFO [replicator-cloud|task-0] Updating configuration of destination topic stream_opnew with properties {message.timestamp.type=CreateTime} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:49:54,322] INFO [replicator-cloud|task-0] Updating configuration of destination topic connect-offsets with properties {cleanup.policy=compact, message.timestamp.type=CreateTime} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:49:54,986] INFO [replicator-cloud|task-0] Updating configuration of destination topic stream_new1 with properties {message.timestamp.type=CreateTime} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:49:55,735] INFO [replicator-cloud|task-0] Updating configuration of destination topic _dek_registry_keys with properties {cleanup.policy=compact, message.timestamp.type=CreateTime} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:49:56,399] INFO [replicator-cloud|task-0] Updating configuration of destination topic postgres-userdata with properties {message.timestamp.type=CreateTime} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:49:56,814] INFO [replicator-cloud|task-0|offsets] WorkerSourceTask{id=replicator-cloud-0} Committing offsets for 275 acknowledged messages (org.apache.kafka.connect.runtime.WorkerSourceTask:232)
[2024-02-05 13:49:57,073] INFO [replicator-cloud|task-0] Updating configuration of destination topic _confluent_balancer_api_state with properties {cleanup.policy=compact, message.timestamp.type=CreateTime, retention.ms=-1} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:49:57,772] INFO [replicator-cloud|task-0] Updating configuration of destination topic _schema_encoders with properties {cleanup.policy=compact, message.timestamp.type=CreateTime} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:49:58,443] INFO [replicator-cloud|task-0] Updating configuration of destination topic connect-status with properties {cleanup.policy=compact, message.timestamp.type=CreateTime} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:49:59,138] INFO [replicator-cloud|task-0] Updating configuration of destination topic postgres-data with properties {message.timestamp.type=CreateTime} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:49:59,802] INFO [replicator-cloud|task-0] Updating configuration of destination topic stream_ip-count-store-changelog with properties {cleanup.policy=compact,delete, message.timestamp.type=CreateTime, retention.ms=172800000} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:50:00,561] INFO [replicator-cloud|task-0] Updating configuration of destination topic sgr with properties {message.timestamp.type=CreateTime} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:50:01,229] INFO [replicator-cloud|task-0] Updating configuration of destination topic postgres-userdata-replica with properties {message.timestamp.type=CreateTime} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:50:01,895] INFO [replicator-cloud|task-0] Updating configuration of destination topic _schemas with properties {cleanup.policy=compact, message.timestamp.type=CreateTime} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:50:02,572] INFO [replicator-cloud|task-0] Updating configuration of destination topic stream_ip with properties {message.timestamp.type=CreateTime} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:50:03,235] INFO [replicator-cloud|task-0] Updating configuration of destination topic _confluent-command with properties {cleanup.policy=compact, message.timestamp.type=CreateTime, min.insync.replicas=1} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:50:03,927] INFO [replicator-cloud|task-0] Updating configuration of destination topic stream_new with properties {message.timestamp.type=CreateTime} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:50:04,600] INFO [replicator-cloud|task-0] Updating configuration of destination topic my_topic with properties {message.timestamp.type=CreateTime} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:50:05,275] INFO [replicator-cloud|task-0] Updating configuration of destination topic stream_opt with properties {message.timestamp.type=CreateTime} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:50:05,955] INFO [replicator-cloud|task-0] Updating configuration of destination topic stream_ip-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog with properties {cleanup.policy=compact, message.timestamp.type=CreateTime} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:50:06,629] INFO [replicator-cloud|task-0] Updating configuration of destination topic stream_op2 with properties {message.timestamp.type=CreateTime} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:50:07,293] INFO [replicator-cloud|task-0] Updating configuration of destination topic stream_op3 with properties {message.timestamp.type=CreateTime} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:50:07,965] INFO [replicator-cloud|task-0] Updating configuration of destination topic stream_int with properties {message.timestamp.type=CreateTime} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:50:08,697] INFO [replicator-cloud|task-0] Updating configuration of destination topic stream_op1 with properties {message.timestamp.type=CreateTime} (io.confluent.connect.replicator.ReplicatorSourceTask:1069)
[2024-02-05 13:50:09,150] INFO [replicator-cloud|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = none
	bootstrap.servers = [pkc-4r087.us-west2.gcp.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = replicator-cloud-0
	client.rack = 
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ConsumerGroup1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:370)
[2024-02-05 13:50:09,199] INFO [replicator-cloud|task-0] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:50:09,199] INFO [replicator-cloud|task-0] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:50:09,200] INFO [replicator-cloud|task-0] Kafka startTimeMs: 1707121209199 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:50:10,864] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=ConsumerGroup1] Cluster ID: lkc-qpjpkm (org.apache.kafka.clients.Metadata:287)
[2024-02-05 13:50:14,534] WARN [replicator-cloud|task-0] Could not find offset for group ConsumerGroup1, topic stream_ip, partition 0, timestamp 1704871412056:7, waiting for replication to catch up.  Please check replication lag. (io.confluent.connect.replicator.offsets.ConsumerOffsetsTranslator:426)
[2024-02-05 13:50:14,534] WARN [replicator-cloud|task-0] Could not find offset for group ConsumerGroup1, topic stream_op3, partition 0, timestamp 1704867999328, waiting for replication to catch up.  Please check replication lag. (io.confluent.connect.replicator.offsets.ConsumerOffsetsTranslator:426)
[2024-02-05 13:50:14,534] WARN [replicator-cloud|task-0] Could not find offset for group ConsumerGroup1, topic stream_op1, partition 0, timestamp 1704866647275:5, waiting for replication to catch up.  Please check replication lag. (io.confluent.connect.replicator.offsets.ConsumerOffsetsTranslator:426)
[2024-02-05 13:50:14,535] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=ConsumerGroup1] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1025)
[2024-02-05 13:50:14,535] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=ConsumerGroup1] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1072)
[2024-02-05 13:50:14,535] INFO [replicator-cloud|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:50:14,536] INFO [replicator-cloud|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:50:14,536] INFO [replicator-cloud|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:50:14,543] INFO [replicator-cloud|task-0] App info kafka.consumer for replicator-cloud-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:50:14,544] INFO [replicator-cloud|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = none
	bootstrap.servers = [pkc-4r087.us-west2.gcp.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = replicator-cloud-0
	client.rack = 
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ConsumerGroup2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:370)
[2024-02-05 13:50:14,560] INFO [replicator-cloud|task-0] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:50:14,560] INFO [replicator-cloud|task-0] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:50:14,561] INFO [replicator-cloud|task-0] Kafka startTimeMs: 1707121214559 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:50:16,248] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=ConsumerGroup2] Cluster ID: lkc-qpjpkm (org.apache.kafka.clients.Metadata:287)
[2024-02-05 13:50:19,677] WARN [replicator-cloud|task-0] Could not find offset for group ConsumerGroup2, topic stream_op3, partition 0, timestamp 1705037816254:8, waiting for replication to catch up.  Please check replication lag. (io.confluent.connect.replicator.offsets.ConsumerOffsetsTranslator:426)
[2024-02-05 13:50:19,677] WARN [replicator-cloud|task-0] Could not find offset for group ConsumerGroup2, topic stream_op1, partition 0, timestamp 1704875562566:2, waiting for replication to catch up.  Please check replication lag. (io.confluent.connect.replicator.offsets.ConsumerOffsetsTranslator:426)
[2024-02-05 13:50:19,677] WARN [replicator-cloud|task-0] Could not find offset for group ConsumerGroup2, topic stream_op2, partition 0, timestamp 1705037455440:7, waiting for replication to catch up.  Please check replication lag. (io.confluent.connect.replicator.offsets.ConsumerOffsetsTranslator:426)
[2024-02-05 13:50:19,677] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=ConsumerGroup2] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1025)
[2024-02-05 13:50:19,678] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=ConsumerGroup2] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1072)
[2024-02-05 13:50:19,678] INFO [replicator-cloud|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:50:19,678] INFO [replicator-cloud|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:50:19,678] INFO [replicator-cloud|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:50:19,682] INFO [replicator-cloud|task-0] App info kafka.consumer for replicator-cloud-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:50:19,683] INFO [replicator-cloud|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = none
	bootstrap.servers = [pkc-4r087.us-west2.gcp.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = replicator-cloud-0
	client.rack = 
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ConsumerGroup3
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:370)
[2024-02-05 13:50:19,687] INFO [replicator-cloud|task-0] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:50:19,687] INFO [replicator-cloud|task-0] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:50:19,687] INFO [replicator-cloud|task-0] Kafka startTimeMs: 1707121219686 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:50:21,402] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=ConsumerGroup3] Cluster ID: lkc-qpjpkm (org.apache.kafka.clients.Metadata:287)
[2024-02-05 13:50:24,978] WARN [replicator-cloud|task-0] Could not find offset for group ConsumerGroup3, topic output_topic, partition 0, timestamp 1705055731393:4, waiting for replication to catch up.  Please check replication lag. (io.confluent.connect.replicator.offsets.ConsumerOffsetsTranslator:426)
[2024-02-05 13:50:24,979] WARN [replicator-cloud|task-0] Could not find offset for group ConsumerGroup3, topic stream_ip, partition 0, timestamp 1705037816254:8, waiting for replication to catch up.  Please check replication lag. (io.confluent.connect.replicator.offsets.ConsumerOffsetsTranslator:426)
[2024-02-05 13:50:24,979] WARN [replicator-cloud|task-0] Could not find offset for group ConsumerGroup3, topic stream_opnew, partition 0, timestamp 1705052302916:1, waiting for replication to catch up.  Please check replication lag. (io.confluent.connect.replicator.offsets.ConsumerOffsetsTranslator:426)
[2024-02-05 13:50:24,980] WARN [replicator-cloud|task-0] Could not find offset for group ConsumerGroup3, topic stream_opt, partition 0, timestamp 1705043913303:3, waiting for replication to catch up.  Please check replication lag. (io.confluent.connect.replicator.offsets.ConsumerOffsetsTranslator:426)
[2024-02-05 13:50:24,980] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=ConsumerGroup3] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1025)
[2024-02-05 13:50:24,980] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=ConsumerGroup3] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1072)
[2024-02-05 13:50:24,981] INFO [replicator-cloud|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:50:24,982] INFO [replicator-cloud|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:50:24,982] INFO [replicator-cloud|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:50:24,987] INFO [replicator-cloud|task-0] App info kafka.consumer for replicator-cloud-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:50:24,989] INFO [replicator-cloud|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = none
	bootstrap.servers = [pkc-4r087.us-west2.gcp.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = replicator-cloud-0
	client.rack = 
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ConsumerGroup11
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:370)
[2024-02-05 13:50:24,999] INFO [replicator-cloud|task-0] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:50:25,000] INFO [replicator-cloud|task-0] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:50:25,000] INFO [replicator-cloud|task-0] Kafka startTimeMs: 1707121224999 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:50:26,658] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=ConsumerGroup11] Cluster ID: lkc-qpjpkm (org.apache.kafka.clients.Metadata:287)
[2024-02-05 13:50:28,376] INFO [replicator-cloud|worker] Found matching topics: [connect-configs, output_topic, kafka-streams-aggregation-count-store-changelog, input_topic, stream_int-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog, stream_opnew, connect-offsets, stream_new1, postgres-userdata, _dek_registry_keys, _confluent_balancer_api_state, _schema_encoders, connect-status, stream_ip-count-store-changelog, postgres-data, __consumer_timestamps, sgr, postgres-userdata-replica, _schemas, stream_ip, _confluent-command, stream_new, my_topic, stream_opt, stream_ip-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog, stream_op2, stream_op3, _confluent-telemetry-metrics, stream_int, stream_op1] (io.confluent.connect.replicator.NewTopicMonitorThread:330)
[2024-02-05 13:50:28,378] INFO [replicator-cloud|worker] topic.regex is set. Replicator requires a DESCRIBE ACL on topics to match via regex. If this ACL is not present then the topic will not be replicated. (io.confluent.connect.replicator.NewTopicMonitorThread:347)
[2024-02-05 13:50:30,104] WARN [replicator-cloud|task-0] Could not find offset for group ConsumerGroup11, topic kafka-streams-aggregation-count-store-changelog, partition 0, timestamp 1704800086245, waiting for replication to catch up.  Please check replication lag. (io.confluent.connect.replicator.offsets.ConsumerOffsetsTranslator:426)
[2024-02-05 13:50:30,108] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=ConsumerGroup11] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1025)
[2024-02-05 13:50:30,108] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=ConsumerGroup11] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1072)
[2024-02-05 13:50:30,109] INFO [replicator-cloud|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:50:30,109] INFO [replicator-cloud|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:50:30,110] INFO [replicator-cloud|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:50:30,114] INFO [replicator-cloud|task-0] App info kafka.consumer for replicator-cloud-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:50:30,115] INFO [replicator-cloud|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = none
	bootstrap.servers = [pkc-4r087.us-west2.gcp.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = replicator-cloud-0
	client.rack = 
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = ConsumerGroup10
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:370)
[2024-02-05 13:50:30,124] INFO [replicator-cloud|task-0] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:50:30,124] INFO [replicator-cloud|task-0] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:50:30,124] INFO [replicator-cloud|task-0] Kafka startTimeMs: 1707121230124 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:50:31,781] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=ConsumerGroup10] Cluster ID: lkc-qpjpkm (org.apache.kafka.clients.Metadata:287)
[2024-02-05 13:50:35,156] WARN [replicator-cloud|task-0] Could not find offset for group ConsumerGroup10, topic kafka-streams-aggregation-count-store-changelog, partition 0, timestamp 1704800086245, waiting for replication to catch up.  Please check replication lag. (io.confluent.connect.replicator.offsets.ConsumerOffsetsTranslator:426)
[2024-02-05 13:50:35,157] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=ConsumerGroup10] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1025)
[2024-02-05 13:50:35,157] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=ConsumerGroup10] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1072)
[2024-02-05 13:50:35,158] INFO [replicator-cloud|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:50:35,158] INFO [replicator-cloud|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:50:35,159] INFO [replicator-cloud|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:50:35,164] INFO [replicator-cloud|task-0] App info kafka.consumer for replicator-cloud-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:50:35,167] WARN [replicator-cloud|task-0] Commit of offsets threw an unexpected exception: {connect-configs-0=OffsetAndMetadata{offset=152, leaderEpoch=null, metadata=''}, __consumer_timestamps-13=OffsetAndMetadata{offset=1, leaderEpoch=null, metadata=''}, __consumer_timestamps-44=OffsetAndMetadata{offset=1, leaderEpoch=null, metadata=''}, __consumer_timestamps-11=OffsetAndMetadata{offset=1, leaderEpoch=null, metadata=''}, stream_int-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog-0=OffsetAndMetadata{offset=25, leaderEpoch=null, metadata=''}, __consumer_timestamps-21=OffsetAndMetadata{offset=1, leaderEpoch=null, metadata=''}, connect-offsets-0=OffsetAndMetadata{offset=3, leaderEpoch=null, metadata=''}, __consumer_timestamps-19=OffsetAndMetadata{offset=1, leaderEpoch=null, metadata=''}, __consumer_timestamps-17=OffsetAndMetadata{offset=3, leaderEpoch=null, metadata=''}, connect-offsets-24=OffsetAndMetadata{offset=9, leaderEpoch=null, metadata=''}, postgres-userdata-0=OffsetAndMetadata{offset=24, leaderEpoch=null, metadata=''}, _confluent_balancer_api_state-0=OffsetAndMetadata{offset=2, leaderEpoch=null, metadata=''}, __consumer_timestamps-39=OffsetAndMetadata{offset=1, leaderEpoch=null, metadata=''}, postgres-data-0=OffsetAndMetadata{offset=1, leaderEpoch=null, metadata=''}, connect-status-2=OffsetAndMetadata{offset=92, leaderEpoch=null, metadata=''}, connect-offsets-16=OffsetAndMetadata{offset=7, leaderEpoch=null, metadata=''}, connect-status-0=OffsetAndMetadata{offset=97, leaderEpoch=null, metadata=''}, connect-offsets-20=OffsetAndMetadata{offset=13, leaderEpoch=null, metadata=''}, __consumer_timestamps-0=OffsetAndMetadata{offset=9, leaderEpoch=null, metadata=''}, connect-status-4=OffsetAndMetadata{offset=136, leaderEpoch=null, metadata=''}, _schemas-0=OffsetAndMetadata{offset=10, leaderEpoch=null, metadata=''}, __consumer_timestamps-43=OffsetAndMetadata{offset=2, leaderEpoch=null, metadata=''}, __consumer_timestamps-10=OffsetAndMetadata{offset=5, leaderEpoch=null, metadata=''}, postgres-userdata-replica-0=OffsetAndMetadata{offset=24, leaderEpoch=null, metadata=''}, __consumer_timestamps-8=OffsetAndMetadata{offset=10, leaderEpoch=null, metadata=''}, __consumer_timestamps-22=OffsetAndMetadata{offset=5, leaderEpoch=null, metadata=''}, __consumer_timestamps-49=OffsetAndMetadata{offset=3, leaderEpoch=null, metadata=''}, stream_ip-KSTREAM-AGGREGATE-STATE-STORE-0000000001-changelog-0=OffsetAndMetadata{offset=220, leaderEpoch=null, metadata=''}, connect-status-1=OffsetAndMetadata{offset=26, leaderEpoch=null, metadata=''}, __consumer_timestamps-5=OffsetAndMetadata{offset=1, leaderEpoch=null, metadata=''}, __consumer_timestamps-36=OffsetAndMetadata{offset=1, leaderEpoch=null, metadata=''}, connect-status-3=OffsetAndMetadata{offset=40, leaderEpoch=null, metadata=''}} (io.confluent.connect.replicator.offsets.ConsumerOffsetsTopicCommitter:271)
org.apache.kafka.common.errors.WakeupException
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.maybeTriggerWakeup(ConsumerNetworkClient.java:529)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:293)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:230)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:214)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.commitOffsetsSync(ConsumerCoordinator.java:1176)
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1518)
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1465)
	at io.confluent.connect.replicator.offsets.ConsumerOffsetsTopicCommitter.commitConsumerOffset(ConsumerOffsetsTopicCommitter.java:268)
	at io.confluent.connect.replicator.offsets.ConsumerOffsetsTopicCommitter.checkCommit(ConsumerOffsetsTopicCommitter.java:253)
	at io.confluent.connect.replicator.ReplicatorSourceTask.poll(ReplicatorSourceTask.java:471)
	at org.apache.kafka.connect.runtime.AbstractWorkerSourceTask.poll(AbstractWorkerSourceTask.java:488)
	at org.apache.kafka.connect.runtime.AbstractWorkerSourceTask.execute(AbstractWorkerSourceTask.java:360)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:229)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:284)
	at org.apache.kafka.connect.runtime.AbstractWorkerSourceTask.run(AbstractWorkerSourceTask.java:80)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:181)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-02-05 13:50:35,655] INFO [Worker clientId=connect-1, groupId=connect-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2284)
[2024-02-05 13:50:36,136] INFO Successfully processed removal of connector 's3-sink' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:999)
[2024-02-05 13:50:36,138] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector s3-sink config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2213)
[2024-02-05 13:50:36,138] INFO Successfully processed removal of connector 'jdbc_source_postgres' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:999)
[2024-02-05 13:50:36,139] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector jdbc_source_postgres config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2213)
[2024-02-05 13:50:36,139] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector jdbc_source_postgres config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2226)
[2024-02-05 13:50:36,141] INFO [Worker clientId=connect-1, groupId=connect-cluster] Tasks [jdbc_source_postgres-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2241)
[2024-02-05 13:50:36,142] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector s3-sink config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2226)
[2024-02-05 13:50:36,143] INFO [Worker clientId=connect-1, groupId=connect-cluster] Tasks [s3-sink-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2241)
[2024-02-05 13:50:36,144] INFO [Worker clientId=connect-1, groupId=connect-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2284)
[2024-02-05 13:50:36,144] INFO Successfully processed removal of connector 'jdbc_source_postgres' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:999)
[2024-02-05 13:50:36,144] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector jdbc_source_postgres config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2213)
[2024-02-05 13:50:36,145] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector jdbc_source_postgres config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2226)
[2024-02-05 13:50:36,146] INFO [Worker clientId=connect-1, groupId=connect-cluster] Tasks [jdbc_source_postgres-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2241)
[2024-02-05 13:50:36,147] INFO [Worker clientId=connect-1, groupId=connect-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2284)
[2024-02-05 13:50:36,147] INFO [Worker clientId=connect-1, groupId=connect-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2284)
[2024-02-05 13:50:36,148] INFO [Worker clientId=connect-1, groupId=connect-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2284)
[2024-02-05 13:50:36,149] INFO [Worker clientId=connect-1, groupId=connect-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2284)
[2024-02-05 13:50:36,149] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector replicator config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2226)
[2024-02-05 13:50:36,150] INFO Successfully processed removal of connector 'replicator' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:999)
[2024-02-05 13:50:36,150] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector replicator config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2213)
[2024-02-05 13:50:36,150] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector replicator config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2226)
[2024-02-05 13:50:36,151] INFO [Worker clientId=connect-1, groupId=connect-cluster] Tasks [replicator-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2241)
[2024-02-05 13:50:36,152] INFO [Worker clientId=connect-1, groupId=connect-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2284)
[2024-02-05 13:50:36,152] INFO Successfully processed removal of connector 'replicator' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:999)
[2024-02-05 13:50:36,152] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector replicator config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2213)
[2024-02-05 13:50:36,152] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector replicator-config config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2226)
[2024-02-05 13:50:36,153] INFO [Worker clientId=connect-1, groupId=connect-cluster] Tasks [replicator-config-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2241)
[2024-02-05 13:50:36,154] INFO Successfully processed removal of connector 'replicator-config' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:999)
[2024-02-05 13:50:36,154] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector replicator-config config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2213)
[2024-02-05 13:50:36,154] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector replicator-config config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2226)
[2024-02-05 13:50:36,155] INFO [Worker clientId=connect-1, groupId=connect-cluster] Tasks [replicator-config-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2241)
[2024-02-05 13:50:36,158] INFO [Worker clientId=connect-1, groupId=connect-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2284)
[2024-02-05 13:50:36,158] INFO Successfully processed removal of connector 'replicator-config' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:999)
[2024-02-05 13:50:36,159] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector replicator-config config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2213)
[2024-02-05 13:50:36,159] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector replicator-config config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2226)
[2024-02-05 13:50:36,160] INFO [Worker clientId=connect-1, groupId=connect-cluster] Tasks [replicator-config-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2241)
[2024-02-05 13:50:36,161] INFO Successfully processed removal of connector 'replicator-config' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:999)
[2024-02-05 13:50:36,161] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector replicator-config config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2213)
[2024-02-05 13:50:36,162] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector replicator-config config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2226)
[2024-02-05 13:50:36,163] INFO [Worker clientId=connect-1, groupId=connect-cluster] Tasks [replicator-config-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2241)
[2024-02-05 13:50:36,164] INFO Successfully processed removal of connector 'replicator-config' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:999)
[2024-02-05 13:50:36,164] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector replicator-config config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2213)
[2024-02-05 13:50:36,165] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector replicator-config config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2226)
[2024-02-05 13:50:36,166] INFO [Worker clientId=connect-1, groupId=connect-cluster] Tasks [replicator-config-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2241)
[2024-02-05 13:50:36,166] INFO Successfully processed removal of connector 'replicator-config' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:999)
[2024-02-05 13:50:36,167] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector replicator-config config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2213)
[2024-02-05 13:50:36,782] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector replicator-config config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2226)
[2024-02-05 13:50:36,788] INFO [Worker clientId=connect-1, groupId=connect-cluster] Tasks [replicator-config-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2241)
[2024-02-05 13:50:36,789] INFO Successfully processed removal of connector 'replicator-config' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:999)
[2024-02-05 13:50:36,789] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector replicator-config config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2213)
[2024-02-05 13:50:36,790] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector replicator-config config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2226)
[2024-02-05 13:50:36,793] INFO [Worker clientId=connect-1, groupId=connect-cluster] Tasks [replicator-config-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2241)
[2024-02-05 13:50:36,793] INFO [Worker clientId=connect-1, groupId=connect-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2284)
[2024-02-05 13:50:36,794] INFO Successfully processed removal of connector 'replicator-config' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:999)
[2024-02-05 13:50:36,794] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector replicator-config config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2213)
[2024-02-05 13:50:36,801] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector my-replicator config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2226)
[2024-02-05 13:50:36,801] INFO [Worker clientId=connect-1, groupId=connect-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2284)
[2024-02-05 13:50:36,802] INFO Successfully processed removal of connector 'my-replicator' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:999)
[2024-02-05 13:50:36,802] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector my-replicator config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2213)
[2024-02-05 13:50:36,804] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector my-replicator config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2226)
[2024-02-05 13:50:36,804] INFO Successfully processed removal of connector 'my-replicator' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:999)
[2024-02-05 13:50:36,804] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector my-replicator config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2213)
[2024-02-05 13:50:36,805] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector my-replicator config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2226)
[2024-02-05 13:50:36,806] INFO [Worker clientId=connect-1, groupId=connect-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2284)
[2024-02-05 13:50:36,806] INFO Successfully processed removal of connector 'my-replicator' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:999)
[2024-02-05 13:50:36,807] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector my-replicator config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2213)
[2024-02-05 13:50:36,807] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector replicator-config config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2226)
[2024-02-05 13:50:36,809] INFO [Worker clientId=connect-1, groupId=connect-cluster] Tasks [replicator-config-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2241)
[2024-02-05 13:50:36,810] INFO Successfully processed removal of connector 'replicator-config' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:999)
[2024-02-05 13:50:36,811] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector replicator-config config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2213)
[2024-02-05 13:50:36,811] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector my-replicator config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2226)
[2024-02-05 13:50:36,812] INFO Successfully processed removal of connector 'my-replicator' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:999)
[2024-02-05 13:50:36,812] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector my-replicator config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2213)
[2024-02-05 13:50:36,814] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector my-replicator config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2226)
[2024-02-05 13:50:36,815] INFO [Worker clientId=connect-1, groupId=connect-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2284)
[2024-02-05 13:50:36,816] INFO Successfully processed removal of connector 'my-replicator' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:999)
[2024-02-05 13:50:36,816] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector my-replicator config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2213)
[2024-02-05 13:50:36,816] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector my-replicator config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2226)
[2024-02-05 13:50:36,817] INFO Successfully processed removal of connector 'my-replicator' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:999)
[2024-02-05 13:50:36,818] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector my-replicator config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2213)
[2024-02-05 13:50:36,819] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector my-replicator config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2226)
[2024-02-05 13:50:36,820] INFO [Worker clientId=connect-1, groupId=connect-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2284)
[2024-02-05 13:50:36,820] INFO Successfully processed removal of connector 'my-replicator' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:999)
[2024-02-05 13:50:36,821] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector my-replicator config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2213)
[2024-02-05 13:50:36,822] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector replicator-localhost config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2226)
[2024-02-05 13:50:36,823] INFO [Worker clientId=connect-1, groupId=connect-cluster] Tasks [replicator-localhost-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2241)
[2024-02-05 13:50:36,827] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector replicator-cloud config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2226)
[2024-02-05 13:50:36,827] INFO Successfully processed removal of connector 'replicator-cloud' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:999)
[2024-02-05 13:50:36,828] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector replicator-cloud config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2213)
[2024-02-05 13:50:36,828] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector replicator-cloud config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2226)
[2024-02-05 13:50:36,834] INFO [Worker clientId=connect-1, groupId=connect-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2284)
[2024-02-05 13:50:36,835] INFO Successfully processed removal of connector 'replicator-cloud' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:999)
[2024-02-05 13:50:36,836] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector replicator-cloud config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2213)
[2024-02-05 13:50:36,839] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector replicator-cloud config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2226)
[2024-02-05 13:50:36,839] INFO Successfully processed removal of connector 'replicator-cloud' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:999)
[2024-02-05 13:50:36,839] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector replicator-cloud config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2213)
[2024-02-05 13:50:36,991] INFO [Worker clientId=connect-1, groupId=connect-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2284)
[2024-02-05 13:50:36,993] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector replicator-cloud config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2226)
[2024-02-05 13:50:36,993] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector replicator-cloud-to-cloud config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2226)
[2024-02-05 13:50:36,994] INFO [Worker clientId=connect-1, groupId=connect-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2284)
[2024-02-05 13:50:36,994] INFO Successfully processed removal of connector 'replicator-cloud' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:999)
[2024-02-05 13:50:36,995] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector replicator-cloud config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2213)
[2024-02-05 13:50:36,995] INFO Successfully processed removal of connector 'replicator-cloud-to-cloud' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:999)
[2024-02-05 13:50:36,995] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector replicator-cloud-to-cloud config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2213)
[2024-02-05 13:50:36,996] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector replicator-cloud config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2226)
[2024-02-05 13:50:36,998] INFO [Worker clientId=connect-1, groupId=connect-cluster] Handling connector-only config update by restarting connector s3-sink (org.apache.kafka.connect.runtime.distributed.DistributedHerder:693)
[2024-02-05 13:50:37,000] INFO [s3-sink|worker] Stopping connector s3-sink (org.apache.kafka.connect.runtime.Worker:492)
[2024-02-05 13:50:37,001] WARN [s3-sink|worker] Ignoring stop request for unowned connector s3-sink (org.apache.kafka.connect.runtime.Worker:495)
[2024-02-05 13:50:37,001] WARN [s3-sink|worker] Ignoring await stop request for non-present connector s3-sink (org.apache.kafka.connect.runtime.Worker:516)
[2024-02-05 13:50:37,001] INFO [Worker clientId=connect-1, groupId=connect-cluster] Handling connector-only config update by restarting connector jdbc_source_postgres (org.apache.kafka.connect.runtime.distributed.DistributedHerder:693)
[2024-02-05 13:50:37,002] INFO [jdbc_source_postgres|worker] Stopping connector jdbc_source_postgres (org.apache.kafka.connect.runtime.Worker:492)
[2024-02-05 13:50:37,002] WARN [jdbc_source_postgres|worker] Ignoring stop request for unowned connector jdbc_source_postgres (org.apache.kafka.connect.runtime.Worker:495)
[2024-02-05 13:50:37,003] WARN [jdbc_source_postgres|worker] Ignoring await stop request for non-present connector jdbc_source_postgres (org.apache.kafka.connect.runtime.Worker:516)
[2024-02-05 13:50:37,003] INFO [Worker clientId=connect-1, groupId=connect-cluster] Handling connector-only config update by restarting connector replicator-cloud (org.apache.kafka.connect.runtime.distributed.DistributedHerder:693)
[2024-02-05 13:50:37,003] INFO [replicator-cloud|worker] Stopping connector replicator-cloud (org.apache.kafka.connect.runtime.Worker:492)
[2024-02-05 13:50:37,004] INFO [replicator-cloud|worker] Scheduled shutdown for WorkerConnector{id=replicator-cloud} (org.apache.kafka.connect.runtime.WorkerConnector:268)
[2024-02-05 13:50:37,004] INFO [replicator-cloud|worker] Shutting down replicator connector replicator-cloud (io.confluent.connect.replicator.ReplicatorSourceConnector:151)
[2024-02-05 13:50:37,005] INFO [replicator-cloud|worker] Closing License Store (io.confluent.license.LicenseStore:258)
[2024-02-05 13:50:37,006] INFO [replicator-cloud|worker] Stopping KafkaBasedLog for topic _confluent-command (org.apache.kafka.connect.util.KafkaBasedLog:343)
[2024-02-05 13:50:37,013] INFO [replicator-cloud|worker] [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1311)
[2024-02-05 13:50:37,024] INFO [replicator-cloud|worker] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:50:37,025] INFO [replicator-cloud|worker] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:50:37,025] INFO [replicator-cloud|worker] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:50:37,026] INFO [replicator-cloud|worker] App info kafka.producer for producer-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:50:37,027] INFO [replicator-cloud|worker] [Consumer clientId=consumer-null-license-2, groupId=null-license] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1025)
[2024-02-05 13:50:37,028] INFO [replicator-cloud|worker] [Consumer clientId=consumer-null-license-2, groupId=null-license] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1072)
[2024-02-05 13:50:37,263] INFO [replicator-cloud|worker] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:50:37,263] INFO [replicator-cloud|worker] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:50:37,264] INFO [replicator-cloud|worker] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:50:37,269] INFO [replicator-cloud|worker] App info kafka.consumer for consumer-null-license-2 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:50:37,269] INFO [replicator-cloud|worker] Stopped KafkaBasedLog for topic _confluent-command (org.apache.kafka.connect.util.KafkaBasedLog:375)
[2024-02-05 13:50:37,269] INFO [replicator-cloud|worker] Closed License Store (io.confluent.license.LicenseStore:260)
[2024-02-05 13:50:37,272] INFO [replicator-cloud|worker] App info kafka.admin.client for adminclient-6 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:50:37,277] INFO [replicator-cloud|worker] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:50:37,277] INFO [replicator-cloud|worker] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:50:37,277] INFO [replicator-cloud|worker] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:50:37,279] INFO [replicator-cloud|worker] Completed shutdown for WorkerConnector{id=replicator-cloud} (org.apache.kafka.connect.runtime.WorkerConnector:288)
[2024-02-05 13:50:37,288] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connector s3-sink (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1893)
[2024-02-05 13:50:37,288] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connector replicator-cloud (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1893)
[2024-02-05 13:50:37,288] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connector jdbc_source_postgres (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1893)
[2024-02-05 13:50:37,289] INFO [s3-sink|worker] Creating connector s3-sink of type io.confluent.connect.s3.S3SinkConnector (org.apache.kafka.connect.runtime.Worker:370)
[2024-02-05 13:50:37,289] INFO [jdbc_source_postgres|worker] Creating connector jdbc_source_postgres of type io.confluent.connect.jdbc.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:370)
[2024-02-05 13:50:37,289] INFO [replicator-cloud|worker] Creating connector replicator-cloud of type io.confluent.connect.replicator.ReplicatorSourceConnector (org.apache.kafka.connect.runtime.Worker:370)
[2024-02-05 13:50:37,291] INFO [replicator-cloud|worker] Injecting Confluent license properties into connector 'replicator-cloud' (org.apache.kafka.connect.runtime.WorkerConfigDecorator:412)
[2024-02-05 13:50:37,292] ERROR [jdbc_source_postgres|worker] Failed to start connector jdbc_source_postgres (org.apache.kafka.connect.runtime.Worker:406)
org.apache.kafka.connect.errors.ConnectException: Failed to find any class that implements Connector and which name matches io.confluent.connect.jdbc.JdbcSourceConnector, available connectors are: PluginDesc{klass=class io.confluent.connect.replicator.ReplicatorSourceConnector, name='io.confluent.connect.replicator.ReplicatorSourceConnector', version='7.5.2', encodedVersion=7.5.2, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSinkConnector, name='org.apache.kafka.connect.tools.MockSinkConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=sink, typeName='sink', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSourceConnector, name='org.apache.kafka.connect.tools.MockSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.SchemaSourceConnector, name='org.apache.kafka.connect.tools.SchemaSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSinkConnector, name='org.apache.kafka.connect.tools.VerifiableSinkConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=sink, typeName='sink', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSourceConnector, name='org.apache.kafka.connect.tools.VerifiableSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}
	at org.apache.kafka.connect.runtime.isolation.Plugins.connectorClass(Plugins.java:253)
	at org.apache.kafka.connect.runtime.isolation.Plugins.newConnector(Plugins.java:224)
	at org.apache.kafka.connect.runtime.Worker.startConnector(Worker.java:371)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startConnector(DistributedHerder.java:1920)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getConnectorStartingCallable$38(DistributedHerder.java:1926)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-02-05 13:50:37,292] ERROR [s3-sink|worker] Failed to start connector s3-sink (org.apache.kafka.connect.runtime.Worker:406)
org.apache.kafka.connect.errors.ConnectException: Failed to find any class that implements Connector and which name matches io.confluent.connect.s3.S3SinkConnector, available connectors are: PluginDesc{klass=class io.confluent.connect.replicator.ReplicatorSourceConnector, name='io.confluent.connect.replicator.ReplicatorSourceConnector', version='7.5.2', encodedVersion=7.5.2, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSinkConnector, name='org.apache.kafka.connect.tools.MockSinkConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=sink, typeName='sink', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSourceConnector, name='org.apache.kafka.connect.tools.MockSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.SchemaSourceConnector, name='org.apache.kafka.connect.tools.SchemaSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSinkConnector, name='org.apache.kafka.connect.tools.VerifiableSinkConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=sink, typeName='sink', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSourceConnector, name='org.apache.kafka.connect.tools.VerifiableSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}
	at org.apache.kafka.connect.runtime.isolation.Plugins.connectorClass(Plugins.java:253)
	at org.apache.kafka.connect.runtime.isolation.Plugins.newConnector(Plugins.java:224)
	at org.apache.kafka.connect.runtime.Worker.startConnector(Worker.java:371)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startConnector(DistributedHerder.java:1920)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getConnectorStartingCallable$38(DistributedHerder.java:1926)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-02-05 13:50:37,294] INFO [replicator-cloud|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.replicator.ReplicatorSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	name = replicator-cloud
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:370)
[2024-02-05 13:50:37,297] ERROR [s3-sink|worker] [Worker clientId=connect-1, groupId=connect-cluster] Failed to start connector 's3-sink' (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1928)
org.apache.kafka.connect.errors.ConnectException: Failed to start connector: s3-sink
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$startConnector$36(DistributedHerder.java:1899)
	at org.apache.kafka.connect.runtime.Worker.startConnector(Worker.java:408)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startConnector(DistributedHerder.java:1920)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getConnectorStartingCallable$38(DistributedHerder.java:1926)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.apache.kafka.connect.errors.ConnectException: Failed to find any class that implements Connector and which name matches io.confluent.connect.s3.S3SinkConnector, available connectors are: PluginDesc{klass=class io.confluent.connect.replicator.ReplicatorSourceConnector, name='io.confluent.connect.replicator.ReplicatorSourceConnector', version='7.5.2', encodedVersion=7.5.2, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSinkConnector, name='org.apache.kafka.connect.tools.MockSinkConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=sink, typeName='sink', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSourceConnector, name='org.apache.kafka.connect.tools.MockSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.SchemaSourceConnector, name='org.apache.kafka.connect.tools.SchemaSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSinkConnector, name='org.apache.kafka.connect.tools.VerifiableSinkConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=sink, typeName='sink', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSourceConnector, name='org.apache.kafka.connect.tools.VerifiableSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}
	at org.apache.kafka.connect.runtime.isolation.Plugins.connectorClass(Plugins.java:253)
	at org.apache.kafka.connect.runtime.isolation.Plugins.newConnector(Plugins.java:224)
	at org.apache.kafka.connect.runtime.Worker.startConnector(Worker.java:371)
	... 6 more
[2024-02-05 13:50:37,296] ERROR [jdbc_source_postgres|worker] [Worker clientId=connect-1, groupId=connect-cluster] Failed to start connector 'jdbc_source_postgres' (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1928)
org.apache.kafka.connect.errors.ConnectException: Failed to start connector: jdbc_source_postgres
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$startConnector$36(DistributedHerder.java:1899)
	at org.apache.kafka.connect.runtime.Worker.startConnector(Worker.java:408)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startConnector(DistributedHerder.java:1920)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getConnectorStartingCallable$38(DistributedHerder.java:1926)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.apache.kafka.connect.errors.ConnectException: Failed to find any class that implements Connector and which name matches io.confluent.connect.jdbc.JdbcSourceConnector, available connectors are: PluginDesc{klass=class io.confluent.connect.replicator.ReplicatorSourceConnector, name='io.confluent.connect.replicator.ReplicatorSourceConnector', version='7.5.2', encodedVersion=7.5.2, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSinkConnector, name='org.apache.kafka.connect.tools.MockSinkConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=sink, typeName='sink', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSourceConnector, name='org.apache.kafka.connect.tools.MockSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.SchemaSourceConnector, name='org.apache.kafka.connect.tools.SchemaSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSinkConnector, name='org.apache.kafka.connect.tools.VerifiableSinkConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=sink, typeName='sink', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSourceConnector, name='org.apache.kafka.connect.tools.VerifiableSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}
	at org.apache.kafka.connect.runtime.isolation.Plugins.connectorClass(Plugins.java:253)
	at org.apache.kafka.connect.runtime.isolation.Plugins.newConnector(Plugins.java:224)
	at org.apache.kafka.connect.runtime.Worker.startConnector(Worker.java:371)
	... 6 more
[2024-02-05 13:50:37,298] INFO [replicator-cloud|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.replicator.ReplicatorSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	name = replicator-cloud
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:370)
[2024-02-05 13:50:37,317] INFO [replicator-cloud|worker] Instantiated connector replicator-cloud with version 7.5.2 of type class io.confluent.connect.replicator.ReplicatorSourceConnector (org.apache.kafka.connect.runtime.Worker:403)
[2024-02-05 13:50:37,317] INFO [replicator-cloud|worker] Finished creating connector replicator-cloud (org.apache.kafka.connect.runtime.Worker:424)
[2024-02-05 13:50:37,318] INFO [Worker clientId=connect-1, groupId=connect-cluster] Handling task config update by stopping tasks [s3-sink-0, jdbc_source_postgres-0], which will be restarted after rebalance if still assigned to this worker (org.apache.kafka.connect.runtime.distributed.DistributedHerder:758)
[2024-02-05 13:50:37,321] WARN [s3-sink|task-0] Ignoring stop request for unowned task s3-sink-0 (org.apache.kafka.connect.runtime.Worker:1284)
[2024-02-05 13:50:37,321] WARN [jdbc_source_postgres|task-0] Ignoring stop request for unowned task jdbc_source_postgres-0 (org.apache.kafka.connect.runtime.Worker:1284)
[2024-02-05 13:50:37,321] WARN [s3-sink|task-0] Ignoring await stop request for non-present task s3-sink-0 (org.apache.kafka.connect.runtime.Worker:1310)
[2024-02-05 13:50:37,322] WARN [jdbc_source_postgres|task-0] Ignoring await stop request for non-present task jdbc_source_postgres-0 (org.apache.kafka.connect.runtime.Worker:1310)
[2024-02-05 13:50:37,322] INFO [replicator-cloud|worker] ReplicatorSourceConnectorConfig values: 
	confluent.license = [hidden]
	confluent.topic = _confluent-command
	consumer.poll.timeout.interval.ms = 5000
	dest.kafka.bootstrap.servers = [pkc-4r087.us-west2.gcp.confluent.cloud:9092]
	dest.kafka.client.id = 
	dest.kafka.connections.max.idle.ms = 540000
	dest.kafka.metric.reporters = []
	dest.kafka.metrics.num.samples = 2
	dest.kafka.metrics.sample.window.ms = 30000
	dest.kafka.receive.buffer.bytes = 65536
	dest.kafka.reconnect.backoff.ms = 50
	dest.kafka.request.timeout.ms = 20000
	dest.kafka.retry.backoff.ms = 500
	dest.kafka.sasl.client.callback.handler.class = null
	dest.kafka.sasl.jaas.config = [hidden]
	dest.kafka.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	dest.kafka.sasl.kerberos.min.time.before.relogin = 60000
	dest.kafka.sasl.kerberos.service.name = null
	dest.kafka.sasl.kerberos.ticket.renew.jitter = 0.05
	dest.kafka.sasl.kerberos.ticket.renew.window.factor = 0.8
	dest.kafka.sasl.login.callback.handler.class = null
	dest.kafka.sasl.login.class = null
	dest.kafka.sasl.login.connect.timeout.ms = null
	dest.kafka.sasl.login.read.timeout.ms = null
	dest.kafka.sasl.login.refresh.buffer.seconds = 300
	dest.kafka.sasl.login.refresh.min.period.seconds = 60
	dest.kafka.sasl.login.refresh.window.factor = 0.8
	dest.kafka.sasl.login.refresh.window.jitter = 0.05
	dest.kafka.sasl.login.retry.backoff.max.ms = 10000
	dest.kafka.sasl.login.retry.backoff.ms = 100
	dest.kafka.sasl.mechanism = PLAIN
	dest.kafka.sasl.oauthbearer.clock.skew.seconds = 30
	dest.kafka.sasl.oauthbearer.expected.audience = null
	dest.kafka.sasl.oauthbearer.expected.issuer = null
	dest.kafka.sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	dest.kafka.sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	dest.kafka.sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	dest.kafka.sasl.oauthbearer.jwks.endpoint.url = null
	dest.kafka.sasl.oauthbearer.scope.claim.name = scope
	dest.kafka.sasl.oauthbearer.sub.claim.name = sub
	dest.kafka.sasl.oauthbearer.token.endpoint.url = null
	dest.kafka.security.protocol = SASL_SSL
	dest.kafka.send.buffer.bytes = 131072
	dest.kafka.ssl.cipher.suites = null
	dest.kafka.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	dest.kafka.ssl.endpoint.identification.algorithm = https
	dest.kafka.ssl.engine.factory.class = null
	dest.kafka.ssl.key.password = null
	dest.kafka.ssl.keymanager.algorithm = SunX509
	dest.kafka.ssl.keystore.certificate.chain = null
	dest.kafka.ssl.keystore.key = null
	dest.kafka.ssl.keystore.location = null
	dest.kafka.ssl.keystore.password = null
	dest.kafka.ssl.keystore.type = JKS
	dest.kafka.ssl.protocol = TLSv1.3
	dest.kafka.ssl.provider = null
	dest.kafka.ssl.secure.random.implementation = null
	dest.kafka.ssl.trustmanager.algorithm = PKIX
	dest.kafka.ssl.truststore.certificates = null
	dest.kafka.ssl.truststore.location = null
	dest.kafka.ssl.truststore.password = null
	dest.kafka.ssl.truststore.type = JKS
	dest.topic.replication.factor = 3
	header.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	key.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	offset.start = connect
	offset.timestamps.commit = true
	offset.topic.commit = true
	offset.topic.commit.batch.period.ms = 60000
	offset.translator.batch.period.ms = 60000
	offset.translator.batch.size = 2147483647
	offset.translator.tasks.max = -1
	offset.translator.tasks.separate = false
	provenance.header.enable = false
	provenance.header.filter.overrides = 
	schema.registry.client.basic.auth.credentials.source = URL
	schema.registry.client.basic.auth.user.info = [hidden]
	schema.registry.max.schemas.per.subject = 1000
	schema.registry.topic = null
	schema.registry.url = null
	schema.subject.translator.class = null
	src.consumer.check.crcs = true
	src.consumer.fetch.max.bytes = 52428800
	src.consumer.fetch.max.wait.ms = 500
	src.consumer.fetch.min.bytes = 1
	src.consumer.interceptor.classes = []
	src.consumer.max.partition.fetch.bytes = 1048576
	src.consumer.max.poll.interval.ms = 300000
	src.consumer.max.poll.records = 500
	src.header.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	src.kafka.bootstrap.servers = [{{ localhost:9092 }}]
	src.kafka.client.id = 
	src.kafka.connections.max.idle.ms = 540000
	src.kafka.metric.reporters = []
	src.kafka.metrics.num.samples = 2
	src.kafka.metrics.sample.window.ms = 30000
	src.kafka.receive.buffer.bytes = 65536
	src.kafka.reconnect.backoff.ms = 50
	src.kafka.request.timeout.ms = 20000
	src.kafka.retry.backoff.ms = 100
	src.kafka.sasl.client.callback.handler.class = null
	src.kafka.sasl.jaas.config = null
	src.kafka.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	src.kafka.sasl.kerberos.min.time.before.relogin = 60000
	src.kafka.sasl.kerberos.service.name = null
	src.kafka.sasl.kerberos.ticket.renew.jitter = 0.05
	src.kafka.sasl.kerberos.ticket.renew.window.factor = 0.8
	src.kafka.sasl.login.callback.handler.class = null
	src.kafka.sasl.login.class = null
	src.kafka.sasl.login.connect.timeout.ms = null
	src.kafka.sasl.login.read.timeout.ms = null
	src.kafka.sasl.login.refresh.buffer.seconds = 300
	src.kafka.sasl.login.refresh.min.period.seconds = 60
	src.kafka.sasl.login.refresh.window.factor = 0.8
	src.kafka.sasl.login.refresh.window.jitter = 0.05
	src.kafka.sasl.login.retry.backoff.max.ms = 10000
	src.kafka.sasl.login.retry.backoff.ms = 100
	src.kafka.sasl.mechanism = GSSAPI
	src.kafka.sasl.oauthbearer.clock.skew.seconds = 30
	src.kafka.sasl.oauthbearer.expected.audience = null
	src.kafka.sasl.oauthbearer.expected.issuer = null
	src.kafka.sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	src.kafka.sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	src.kafka.sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	src.kafka.sasl.oauthbearer.jwks.endpoint.url = null
	src.kafka.sasl.oauthbearer.scope.claim.name = scope
	src.kafka.sasl.oauthbearer.sub.claim.name = sub
	src.kafka.sasl.oauthbearer.token.endpoint.url = null
	src.kafka.security.protocol = PLAINTEXT
	src.kafka.send.buffer.bytes = 131072
	src.kafka.ssl.cipher.suites = null
	src.kafka.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	src.kafka.ssl.endpoint.identification.algorithm = https
	src.kafka.ssl.engine.factory.class = null
	src.kafka.ssl.key.password = null
	src.kafka.ssl.keymanager.algorithm = SunX509
	src.kafka.ssl.keystore.certificate.chain = null
	src.kafka.ssl.keystore.key = null
	src.kafka.ssl.keystore.location = null
	src.kafka.ssl.keystore.password = null
	src.kafka.ssl.keystore.type = JKS
	src.kafka.ssl.protocol = TLSv1.3
	src.kafka.ssl.provider = null
	src.kafka.ssl.secure.random.implementation = null
	src.kafka.ssl.trustmanager.algorithm = PKIX
	src.kafka.ssl.truststore.certificates = null
	src.kafka.ssl.truststore.location = null
	src.kafka.ssl.truststore.password = null
	src.kafka.ssl.truststore.type = JKS
	src.key.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	src.value.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	topic.auto.create = true
	topic.blacklist = []
	topic.config.sync = true
	topic.config.sync.interval.ms = 120000
	topic.create.backoff.ms = 120000
	topic.poll.interval.ms = 120000
	topic.preserve.partitions = true
	topic.regex = .*
	topic.rename.format = ${topic}
	topic.timestamp.type = CreateTime
	topic.whitelist = []
	value.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
 (io.confluent.connect.replicator.ReplicatorSourceConnectorConfig:370)
[2024-02-05 13:50:37,322] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:231)
[2024-02-05 13:50:37,324] INFO [replicator-cloud|worker] Starting replicator connector replicator-cloud (io.confluent.connect.replicator.ReplicatorSourceConnector:87)
[2024-02-05 13:50:37,324] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:576)
[2024-02-05 13:50:37,326] INFO [replicator-cloud|worker] AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [pkc-4r087.us-west2.gcp.confluent.cloud:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	confluent.lkc.id = null
	confluent.metrics.reporter.bootstrap.servers = kafka-0:9071
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	confluent.use.controller.listener = false
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	host.resolver.class = class org.apache.kafka.clients.DefaultHostResolver
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retries = 2147483647
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:370)
[2024-02-05 13:50:37,331] INFO [replicator-cloud|worker] These configurations '[replication.factor, enable.idempotence, group.id, producer.enable.idempotence]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:379)
[2024-02-05 13:50:37,331] INFO [replicator-cloud|worker] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:50:37,331] INFO [replicator-cloud|worker] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:50:37,332] INFO [replicator-cloud|worker] Kafka startTimeMs: 1707121237331 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:50:37,535] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=11, memberId='connect-1-5626c631-09b4-4bc6-b13c-f89c6adf07d0', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:637)
[2024-02-05 13:50:37,770] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=11, memberId='connect-1-5626c631-09b4-4bc6-b13c-f89c6adf07d0', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:812)
[2024-02-05 13:50:37,774] INFO [replicator-cloud|task-0] Stopping task replicator-cloud-0 (org.apache.kafka.connect.runtime.Worker:1288)
[2024-02-05 13:50:40,171] INFO [replicator-cloud|task-0] WorkerSourceTask{id=replicator-cloud-0} Committing offsets for 302 acknowledged messages (org.apache.kafka.connect.runtime.WorkerSourceTask:232)
[2024-02-05 13:50:40,437] INFO [replicator-cloud|task-0] Closing kafka replicator task replicator-cloud-0 (io.confluent.connect.replicator.ReplicatorSourceTask:1259)
[2024-02-05 13:50:40,439] INFO [replicator-cloud|task-0] App info kafka.admin.client for adminclient-8 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:50:40,442] INFO [replicator-cloud|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:50:40,443] INFO [replicator-cloud|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:50:40,443] INFO [replicator-cloud|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:50:40,444] INFO [replicator-cloud|task-0] App info kafka.admin.client for adminclient-7 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:50:40,449] INFO [replicator-cloud|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:50:40,449] INFO [replicator-cloud|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:50:40,449] INFO [replicator-cloud|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:50:40,451] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1025)
[2024-02-05 13:50:40,451] INFO [replicator-cloud|task-0] [Consumer clientId=replicator-cloud-0, groupId=replicator-cloud] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1072)
[2024-02-05 13:50:40,454] INFO [replicator-cloud|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:50:40,454] INFO [replicator-cloud|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:50:40,457] INFO [replicator-cloud|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:50:40,461] INFO [replicator-cloud|task-0] App info kafka.consumer for replicator-cloud-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:50:40,461] INFO [replicator-cloud|task-0] [Producer clientId=producer-2] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1311)
[2024-02-05 13:50:40,484] INFO [replicator-cloud|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:50:40,485] INFO [replicator-cloud|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:50:40,485] INFO [replicator-cloud|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:50:40,485] INFO [replicator-cloud|task-0] App info kafka.producer for producer-2 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:50:40,486] INFO [replicator-cloud|task-0] Shutting down metrics recording for task replicator-cloud-0 (io.confluent.connect.replicator.ReplicatorSourceTask:1281)
[2024-02-05 13:50:40,541] INFO [replicator-cloud|task-0] Unregistering Confluent Replicator metrics with JMX for task 'replicator-cloud-0' (io.confluent.connect.replicator.metrics.ConfluentReplicatorMetrics:86)
[2024-02-05 13:50:40,541] INFO [replicator-cloud|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:50:40,541] INFO [replicator-cloud|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:50:40,541] INFO [replicator-cloud|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:50:40,541] INFO [replicator-cloud|task-0] [Consumer clientId=confluent-replicator-end-offsets-consumer-client, groupId=confluent-replicator-end-offsets-consumer-group] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1025)
[2024-02-05 13:50:40,542] INFO [replicator-cloud|task-0] [Consumer clientId=confluent-replicator-end-offsets-consumer-client, groupId=confluent-replicator-end-offsets-consumer-group] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1072)
[2024-02-05 13:50:40,542] INFO [replicator-cloud|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:50:40,542] INFO [replicator-cloud|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:50:40,542] INFO [replicator-cloud|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:50:40,544] INFO [replicator-cloud|task-0] App info kafka.consumer for confluent-replicator-end-offsets-consumer-client unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:50:40,545] INFO [replicator-cloud|task-0] [Producer clientId=connector-producer-replicator-cloud-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1311)
[2024-02-05 13:50:40,549] INFO [replicator-cloud|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:50:40,549] INFO [replicator-cloud|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:50:40,549] INFO [replicator-cloud|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:50:40,549] INFO [replicator-cloud|task-0] App info kafka.producer for connector-producer-replicator-cloud-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:50:40,553] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2502)
[2024-02-05 13:50:40,739] INFO [replicator-cloud|worker] App info kafka.admin.client for adminclient-9 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:50:40,744] INFO [replicator-cloud|worker] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:50:40,744] INFO [replicator-cloud|worker] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:50:40,745] INFO [replicator-cloud|worker] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:50:40,746] INFO [replicator-cloud|worker] Starting License Store (io.confluent.license.LicenseStore:250)
[2024-02-05 13:50:40,746] INFO [replicator-cloud|worker] Starting KafkaBasedLog with topic _confluent-command (org.apache.kafka.connect.util.KafkaBasedLog:280)
[2024-02-05 13:50:40,748] INFO [replicator-cloud|worker] AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [pkc-4r087.us-west2.gcp.confluent.cloud:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	confluent.lkc.id = null
	confluent.metrics.reporter.bootstrap.servers = kafka-0:9071
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	confluent.use.controller.listener = false
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	host.resolver.class = class org.apache.kafka.clients.DefaultHostResolver
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retries = 2147483647
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:370)
[2024-02-05 13:50:40,776] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2521)
[2024-02-05 13:50:40,777] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 11 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-5626c631-09b4-4bc6-b13c-f89c6adf07d0', leaderUrl='http://127.0.1.1:8083/', offset=140, connectorIds=[replicator-localhost, s3-sink, jdbc_sink_connector, jdbc_source_postgres, replicator-cloud], taskIds=[replicator-localhost-0, s3-sink-0, jdbc_sink_connector-0, jdbc_source_postgres-0], revokedConnectorIds=[], revokedTaskIds=[replicator-cloud-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2416)
[2024-02-05 13:50:40,779] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 140 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1776)
[2024-02-05 13:50:40,781] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connector replicator-localhost (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1893)
[2024-02-05 13:50:40,785] INFO [replicator-localhost|worker] Creating connector replicator-localhost of type io.confluent.connect.replicator.ReplicatorSourceConnector (org.apache.kafka.connect.runtime.Worker:370)
[2024-02-05 13:50:40,787] INFO [replicator-localhost|worker] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.replicator.ReplicatorSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	name = replicator-localhost
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:370)
[2024-02-05 13:50:40,788] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting task jdbc_source_postgres-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1818)
[2024-02-05 13:50:40,792] INFO [replicator-localhost|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.replicator.ReplicatorSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	name = replicator-localhost
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:370)
[2024-02-05 13:50:40,788] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting task s3-sink-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1818)
[2024-02-05 13:50:40,793] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting task replicator-localhost-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1818)
[2024-02-05 13:50:40,814] INFO [replicator-localhost|task-0] Creating task replicator-localhost-0 (org.apache.kafka.connect.runtime.Worker:765)
[2024-02-05 13:50:40,793] WARN Unable to retrieve connector type (org.apache.kafka.connect.runtime.AbstractHerder:821)
org.apache.kafka.connect.errors.ConnectException: Failed to find any class that implements Connector and which name matches io.confluent.connect.jdbc.JdbcSourceConnector, available connectors are: PluginDesc{klass=class io.confluent.connect.replicator.ReplicatorSourceConnector, name='io.confluent.connect.replicator.ReplicatorSourceConnector', version='7.5.2', encodedVersion=7.5.2, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSinkConnector, name='org.apache.kafka.connect.tools.MockSinkConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=sink, typeName='sink', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSourceConnector, name='org.apache.kafka.connect.tools.MockSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.SchemaSourceConnector, name='org.apache.kafka.connect.tools.SchemaSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSinkConnector, name='org.apache.kafka.connect.tools.VerifiableSinkConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=sink, typeName='sink', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSourceConnector, name='org.apache.kafka.connect.tools.VerifiableSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}
	at org.apache.kafka.connect.runtime.isolation.Plugins.connectorClass(Plugins.java:253)
	at org.apache.kafka.connect.runtime.isolation.Plugins.newConnector(Plugins.java:224)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$getConnector$10(AbstractHerder.java:801)
	at java.base/java.util.concurrent.ConcurrentHashMap.computeIfAbsent(ConcurrentHashMap.java:1705)
	at org.apache.kafka.connect.runtime.AbstractHerder.getConnector(AbstractHerder.java:801)
	at org.apache.kafka.connect.runtime.AbstractHerder.connectorType(AbstractHerder.java:819)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startTask(DistributedHerder.java:1820)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getTaskStartingCallable$33(DistributedHerder.java:1872)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-02-05 13:50:40,817] ERROR [Worker clientId=connect-1, groupId=connect-cluster] Couldn't instantiate task jdbc_source_postgres-0 because it has an invalid task configuration. This task will not execute until reconfigured. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1874)
org.apache.kafka.connect.errors.ConnectException: Failed to start task jdbc_source_postgres-0 since it is not a recognizable type (source or sink)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startTask(DistributedHerder.java:1865)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getTaskStartingCallable$33(DistributedHerder.java:1872)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-02-05 13:50:40,804] WARN Unable to retrieve connector type (org.apache.kafka.connect.runtime.AbstractHerder:821)
org.apache.kafka.connect.errors.ConnectException: Failed to find any class that implements Connector and which name matches io.confluent.connect.s3.S3SinkConnector, available connectors are: PluginDesc{klass=class io.confluent.connect.replicator.ReplicatorSourceConnector, name='io.confluent.connect.replicator.ReplicatorSourceConnector', version='7.5.2', encodedVersion=7.5.2, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSinkConnector, name='org.apache.kafka.connect.tools.MockSinkConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=sink, typeName='sink', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSourceConnector, name='org.apache.kafka.connect.tools.MockSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.SchemaSourceConnector, name='org.apache.kafka.connect.tools.SchemaSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSinkConnector, name='org.apache.kafka.connect.tools.VerifiableSinkConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=sink, typeName='sink', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSourceConnector, name='org.apache.kafka.connect.tools.VerifiableSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}
	at org.apache.kafka.connect.runtime.isolation.Plugins.connectorClass(Plugins.java:253)
	at org.apache.kafka.connect.runtime.isolation.Plugins.newConnector(Plugins.java:224)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$getConnector$10(AbstractHerder.java:801)
	at java.base/java.util.concurrent.ConcurrentHashMap.computeIfAbsent(ConcurrentHashMap.java:1705)
	at org.apache.kafka.connect.runtime.AbstractHerder.getConnector(AbstractHerder.java:801)
	at org.apache.kafka.connect.runtime.AbstractHerder.connectorType(AbstractHerder.java:819)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startTask(DistributedHerder.java:1820)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getTaskStartingCallable$33(DistributedHerder.java:1872)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-02-05 13:50:40,798] INFO [replicator-localhost|worker] Instantiated connector replicator-localhost with version 7.5.2 of type class io.confluent.connect.replicator.ReplicatorSourceConnector (org.apache.kafka.connect.runtime.Worker:403)
[2024-02-05 13:50:40,822] INFO [replicator-cloud|worker] These configurations '[replication.factor, enable.idempotence, group.id, producer.enable.idempotence]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:379)
[2024-02-05 13:50:40,824] INFO [replicator-cloud|worker] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:50:40,824] INFO [replicator-cloud|worker] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:50:40,824] INFO [replicator-cloud|worker] Kafka startTimeMs: 1707121240823 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:50:40,825] INFO [replicator-localhost|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.replicator.ReplicatorSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	name = replicator-localhost
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:370)
[2024-02-05 13:50:40,826] INFO [replicator-localhost|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.replicator.ReplicatorSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	name = replicator-localhost
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:370)
[2024-02-05 13:50:40,827] INFO [replicator-localhost|task-0] TaskConfig values: 
	task.class = class io.confluent.connect.replicator.ReplicatorSourceTask
 (org.apache.kafka.connect.runtime.TaskConfig:370)
[2024-02-05 13:50:40,827] INFO [replicator-localhost|task-0] Instantiated task replicator-localhost-0 with version 7.5.2 of type io.confluent.connect.replicator.ReplicatorSourceTask (org.apache.kafka.connect.runtime.Worker:779)
[2024-02-05 13:50:40,828] INFO [replicator-localhost|task-0] Set up the key converter class io.confluent.connect.replicator.util.ByteArrayConverter for task replicator-localhost-0 using the connector config (org.apache.kafka.connect.runtime.Worker:797)
[2024-02-05 13:50:40,829] INFO [replicator-localhost|task-0] Set up the value converter class io.confluent.connect.replicator.util.ByteArrayConverter for task replicator-localhost-0 using the connector config (org.apache.kafka.connect.runtime.Worker:803)
[2024-02-05 13:50:40,822] ERROR [Worker clientId=connect-1, groupId=connect-cluster] Couldn't instantiate task s3-sink-0 because it has an invalid task configuration. This task will not execute until reconfigured. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1874)
org.apache.kafka.connect.errors.ConnectException: Failed to start task s3-sink-0 since it is not a recognizable type (source or sink)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startTask(DistributedHerder.java:1865)
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$getTaskStartingCallable$33(DistributedHerder.java:1872)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-02-05 13:50:40,829] INFO [replicator-localhost|worker] ReplicatorSourceConnectorConfig values: 
	confluent.license = [hidden]
	confluent.topic = _confluent-command
	consumer.poll.timeout.interval.ms = 5000
	dest.kafka.bootstrap.servers = [localhost:9092]
	dest.kafka.client.id = 
	dest.kafka.connections.max.idle.ms = 540000
	dest.kafka.metric.reporters = []
	dest.kafka.metrics.num.samples = 2
	dest.kafka.metrics.sample.window.ms = 30000
	dest.kafka.receive.buffer.bytes = 65536
	dest.kafka.reconnect.backoff.ms = 50
	dest.kafka.request.timeout.ms = 30000
	dest.kafka.retry.backoff.ms = 100
	dest.kafka.sasl.client.callback.handler.class = null
	dest.kafka.sasl.jaas.config = null
	dest.kafka.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	dest.kafka.sasl.kerberos.min.time.before.relogin = 60000
	dest.kafka.sasl.kerberos.service.name = null
	dest.kafka.sasl.kerberos.ticket.renew.jitter = 0.05
	dest.kafka.sasl.kerberos.ticket.renew.window.factor = 0.8
	dest.kafka.sasl.login.callback.handler.class = null
	dest.kafka.sasl.login.class = null
	dest.kafka.sasl.login.connect.timeout.ms = null
	dest.kafka.sasl.login.read.timeout.ms = null
	dest.kafka.sasl.login.refresh.buffer.seconds = 300
	dest.kafka.sasl.login.refresh.min.period.seconds = 60
	dest.kafka.sasl.login.refresh.window.factor = 0.8
	dest.kafka.sasl.login.refresh.window.jitter = 0.05
	dest.kafka.sasl.login.retry.backoff.max.ms = 10000
	dest.kafka.sasl.login.retry.backoff.ms = 100
	dest.kafka.sasl.mechanism = GSSAPI
	dest.kafka.sasl.oauthbearer.clock.skew.seconds = 30
	dest.kafka.sasl.oauthbearer.expected.audience = null
	dest.kafka.sasl.oauthbearer.expected.issuer = null
	dest.kafka.sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	dest.kafka.sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	dest.kafka.sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	dest.kafka.sasl.oauthbearer.jwks.endpoint.url = null
	dest.kafka.sasl.oauthbearer.scope.claim.name = scope
	dest.kafka.sasl.oauthbearer.sub.claim.name = sub
	dest.kafka.sasl.oauthbearer.token.endpoint.url = null
	dest.kafka.security.protocol = PLAINTEXT
	dest.kafka.send.buffer.bytes = 131072
	dest.kafka.ssl.cipher.suites = null
	dest.kafka.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	dest.kafka.ssl.endpoint.identification.algorithm = https
	dest.kafka.ssl.engine.factory.class = null
	dest.kafka.ssl.key.password = null
	dest.kafka.ssl.keymanager.algorithm = SunX509
	dest.kafka.ssl.keystore.certificate.chain = null
	dest.kafka.ssl.keystore.key = null
	dest.kafka.ssl.keystore.location = null
	dest.kafka.ssl.keystore.password = null
	dest.kafka.ssl.keystore.type = JKS
	dest.kafka.ssl.protocol = TLSv1.3
	dest.kafka.ssl.provider = null
	dest.kafka.ssl.secure.random.implementation = null
	dest.kafka.ssl.trustmanager.algorithm = PKIX
	dest.kafka.ssl.truststore.certificates = null
	dest.kafka.ssl.truststore.location = null
	dest.kafka.ssl.truststore.password = null
	dest.kafka.ssl.truststore.type = JKS
	dest.topic.replication.factor = 0
	header.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	key.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	offset.start = connect
	offset.timestamps.commit = true
	offset.topic.commit = true
	offset.topic.commit.batch.period.ms = 60000
	offset.translator.batch.period.ms = 60000
	offset.translator.batch.size = 2147483647
	offset.translator.tasks.max = -1
	offset.translator.tasks.separate = false
	provenance.header.enable = false
	provenance.header.filter.overrides = 
	schema.registry.client.basic.auth.credentials.source = URL
	schema.registry.client.basic.auth.user.info = [hidden]
	schema.registry.max.schemas.per.subject = 1000
	schema.registry.topic = null
	schema.registry.url = null
	schema.subject.translator.class = null
	src.consumer.check.crcs = true
	src.consumer.fetch.max.bytes = 52428800
	src.consumer.fetch.max.wait.ms = 500
	src.consumer.fetch.min.bytes = 1
	src.consumer.interceptor.classes = []
	src.consumer.max.partition.fetch.bytes = 1048576
	src.consumer.max.poll.interval.ms = 300000
	src.consumer.max.poll.records = 500
	src.header.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	src.kafka.bootstrap.servers = [localhost:9092]
	src.kafka.client.id = 
	src.kafka.connections.max.idle.ms = 540000
	src.kafka.metric.reporters = []
	src.kafka.metrics.num.samples = 2
	src.kafka.metrics.sample.window.ms = 30000
	src.kafka.receive.buffer.bytes = 65536
	src.kafka.reconnect.backoff.ms = 50
	src.kafka.request.timeout.ms = 30000
	src.kafka.retry.backoff.ms = 100
	src.kafka.sasl.client.callback.handler.class = null
	src.kafka.sasl.jaas.config = null
	src.kafka.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	src.kafka.sasl.kerberos.min.time.before.relogin = 60000
	src.kafka.sasl.kerberos.service.name = null
	src.kafka.sasl.kerberos.ticket.renew.jitter = 0.05
	src.kafka.sasl.kerberos.ticket.renew.window.factor = 0.8
	src.kafka.sasl.login.callback.handler.class = null
	src.kafka.sasl.login.class = null
	src.kafka.sasl.login.connect.timeout.ms = null
	src.kafka.sasl.login.read.timeout.ms = null
	src.kafka.sasl.login.refresh.buffer.seconds = 300
	src.kafka.sasl.login.refresh.min.period.seconds = 60
	src.kafka.sasl.login.refresh.window.factor = 0.8
	src.kafka.sasl.login.refresh.window.jitter = 0.05
	src.kafka.sasl.login.retry.backoff.max.ms = 10000
	src.kafka.sasl.login.retry.backoff.ms = 100
	src.kafka.sasl.mechanism = GSSAPI
	src.kafka.sasl.oauthbearer.clock.skew.seconds = 30
	src.kafka.sasl.oauthbearer.expected.audience = null
	src.kafka.sasl.oauthbearer.expected.issuer = null
	src.kafka.sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	src.kafka.sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	src.kafka.sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	src.kafka.sasl.oauthbearer.jwks.endpoint.url = null
	src.kafka.sasl.oauthbearer.scope.claim.name = scope
	src.kafka.sasl.oauthbearer.sub.claim.name = sub
	src.kafka.sasl.oauthbearer.token.endpoint.url = null
	src.kafka.security.protocol = PLAINTEXT
	src.kafka.send.buffer.bytes = 131072
	src.kafka.ssl.cipher.suites = null
	src.kafka.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	src.kafka.ssl.endpoint.identification.algorithm = https
	src.kafka.ssl.engine.factory.class = null
	src.kafka.ssl.key.password = null
	src.kafka.ssl.keymanager.algorithm = SunX509
	src.kafka.ssl.keystore.certificate.chain = null
	src.kafka.ssl.keystore.key = null
	src.kafka.ssl.keystore.location = null
	src.kafka.ssl.keystore.password = null
	src.kafka.ssl.keystore.type = JKS
	src.kafka.ssl.protocol = TLSv1.3
	src.kafka.ssl.provider = null
	src.kafka.ssl.secure.random.implementation = null
	src.kafka.ssl.trustmanager.algorithm = PKIX
	src.kafka.ssl.truststore.certificates = null
	src.kafka.ssl.truststore.location = null
	src.kafka.ssl.truststore.password = null
	src.kafka.ssl.truststore.type = JKS
	src.key.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	src.value.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	topic.auto.create = true
	topic.blacklist = []
	topic.config.sync = true
	topic.config.sync.interval.ms = 120000
	topic.create.backoff.ms = 120000
	topic.poll.interval.ms = 120000
	topic.preserve.partitions = true
	topic.regex = null
	topic.rename.format = ${topic}-replica
	topic.timestamp.type = CreateTime
	topic.whitelist = [postgres-userdata]
	value.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
 (io.confluent.connect.replicator.ReplicatorSourceConnectorConfig:370)
[2024-02-05 13:50:40,829] INFO [replicator-localhost|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task replicator-localhost-0 using the worker config (org.apache.kafka.connect.runtime.Worker:809)
[2024-02-05 13:50:40,823] INFO [replicator-localhost|worker] Finished creating connector replicator-localhost (org.apache.kafka.connect.runtime.Worker:424)
[2024-02-05 13:50:40,845] INFO [replicator-localhost|task-0] SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.replicator.ReplicatorSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	name = replicator-localhost
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:370)
[2024-02-05 13:50:40,853] INFO [replicator-localhost|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.replicator.ReplicatorSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	name = replicator-localhost
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:370)
[2024-02-05 13:50:40,854] INFO [replicator-localhost|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1758)
[2024-02-05 13:50:40,856] INFO [replicator-localhost|task-0] ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [pkc-4r087.us-west2.gcp.confluent.cloud:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = connector-producer-replicator-localhost-0
	compression.type = none
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 9223372036854775807
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retries = 2147483647
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:370)
[2024-02-05 13:50:40,867] INFO [replicator-localhost|task-0] These configurations '[metrics.context.resource.connector, metrics.context.resource.version, metrics.context.connect.group.id, metrics.context.resource.type, metrics.context.resource.commit.id, metrics.context.resource.task, metrics.context.connect.kafka.cluster.id]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:379)
[2024-02-05 13:50:40,867] INFO [replicator-localhost|task-0] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:50:40,867] INFO [replicator-localhost|task-0] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:50:40,867] INFO [replicator-localhost|task-0] Kafka startTimeMs: 1707121240867 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:50:40,868] INFO [replicator-localhost|task-0] TracerConfig values: 
	trace.records.enable = false
	trace.records.header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	trace.records.key.converter = class org.apache.kafka.connect.json.JsonConverter
	trace.records.predicates = []
	trace.records.topic = connect-traces
	trace.records.topic.partition = 1
	trace.records.topic.replication.factor = 3
	trace.records.transforms = []
	trace.records.value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.tracing.TracerConfig:370)
[2024-02-05 13:50:40,839] INFO [replicator-localhost|worker] Starting replicator connector replicator-localhost (io.confluent.connect.replicator.ReplicatorSourceConnector:87)
[2024-02-05 13:50:40,868] INFO [replicator-localhost|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1790)
[2024-02-05 13:50:40,871] INFO [replicator-localhost|worker] AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	confluent.lkc.id = null
	confluent.metrics.reporter.bootstrap.servers = kafka-0:9071
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	confluent.use.controller.listener = false
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	host.resolver.class = class org.apache.kafka.clients.DefaultHostResolver
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:370)
[2024-02-05 13:50:40,873] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1804)
[2024-02-05 13:50:40,873] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:231)
[2024-02-05 13:50:40,874] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:576)
[2024-02-05 13:50:40,874] INFO [replicator-localhost|worker] These configurations '[replication.factor, group.id]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:379)
[2024-02-05 13:50:40,875] INFO [replicator-localhost|worker] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:50:40,880] INFO [replicator-localhost|worker] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:50:40,880] INFO [replicator-localhost|worker] Kafka startTimeMs: 1707121240875 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:50:40,875] INFO [replicator-localhost|task-0] ReplicatorSourceTaskConfig values: 
	confluent.license = [hidden]
	confluent.topic = _confluent-command
	consumer.poll.timeout.interval.ms = 5000
	dest.kafka.bootstrap.servers = [localhost:9092]
	dest.kafka.client.id = 
	dest.kafka.connections.max.idle.ms = 540000
	dest.kafka.metric.reporters = []
	dest.kafka.metrics.num.samples = 2
	dest.kafka.metrics.sample.window.ms = 30000
	dest.kafka.receive.buffer.bytes = 65536
	dest.kafka.reconnect.backoff.ms = 50
	dest.kafka.request.timeout.ms = 30000
	dest.kafka.retry.backoff.ms = 100
	dest.kafka.sasl.client.callback.handler.class = null
	dest.kafka.sasl.jaas.config = null
	dest.kafka.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	dest.kafka.sasl.kerberos.min.time.before.relogin = 60000
	dest.kafka.sasl.kerberos.service.name = null
	dest.kafka.sasl.kerberos.ticket.renew.jitter = 0.05
	dest.kafka.sasl.kerberos.ticket.renew.window.factor = 0.8
	dest.kafka.sasl.login.callback.handler.class = null
	dest.kafka.sasl.login.class = null
	dest.kafka.sasl.login.connect.timeout.ms = null
	dest.kafka.sasl.login.read.timeout.ms = null
	dest.kafka.sasl.login.refresh.buffer.seconds = 300
	dest.kafka.sasl.login.refresh.min.period.seconds = 60
	dest.kafka.sasl.login.refresh.window.factor = 0.8
	dest.kafka.sasl.login.refresh.window.jitter = 0.05
	dest.kafka.sasl.login.retry.backoff.max.ms = 10000
	dest.kafka.sasl.login.retry.backoff.ms = 100
	dest.kafka.sasl.mechanism = GSSAPI
	dest.kafka.sasl.oauthbearer.clock.skew.seconds = 30
	dest.kafka.sasl.oauthbearer.expected.audience = null
	dest.kafka.sasl.oauthbearer.expected.issuer = null
	dest.kafka.sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	dest.kafka.sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	dest.kafka.sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	dest.kafka.sasl.oauthbearer.jwks.endpoint.url = null
	dest.kafka.sasl.oauthbearer.scope.claim.name = scope
	dest.kafka.sasl.oauthbearer.sub.claim.name = sub
	dest.kafka.sasl.oauthbearer.token.endpoint.url = null
	dest.kafka.security.protocol = PLAINTEXT
	dest.kafka.send.buffer.bytes = 131072
	dest.kafka.ssl.cipher.suites = null
	dest.kafka.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	dest.kafka.ssl.endpoint.identification.algorithm = https
	dest.kafka.ssl.engine.factory.class = null
	dest.kafka.ssl.key.password = null
	dest.kafka.ssl.keymanager.algorithm = SunX509
	dest.kafka.ssl.keystore.certificate.chain = null
	dest.kafka.ssl.keystore.key = null
	dest.kafka.ssl.keystore.location = null
	dest.kafka.ssl.keystore.password = null
	dest.kafka.ssl.keystore.type = JKS
	dest.kafka.ssl.protocol = TLSv1.3
	dest.kafka.ssl.provider = null
	dest.kafka.ssl.secure.random.implementation = null
	dest.kafka.ssl.trustmanager.algorithm = PKIX
	dest.kafka.ssl.truststore.certificates = null
	dest.kafka.ssl.truststore.location = null
	dest.kafka.ssl.truststore.password = null
	dest.kafka.ssl.truststore.type = JKS
	dest.topic.replication.factor = 0
	header.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	key.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	offset.start = connect
	offset.timestamps.commit = true
	offset.topic.commit = true
	offset.topic.commit.batch.period.ms = 60000
	offset.translator.batch.period.ms = 60000
	offset.translator.batch.size = 2147483647
	offset.translator.tasks.max = -1
	offset.translator.tasks.separate = false
	partition.assignment = AAMAAAACABVfX2NvbnN1bWVyX3RpbWVzdGFtcHMAAAAyAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAFAAAABgAAAAcAAAAIAAAACQAAAAoAAAALAAAADAAAAA0AAAAOAAAADwAAABAAAAARAAAAEgAAABMAAAAUAAAAFQAAABYAAAAXAAAAGAAAABkAAAAaAAAAGwAAABwAAAAdAAAAHgAAAB8AAAAgAAAAIQAAACIAAAAjAAAAJAAAACUAAAAmAAAAJwAAACgAAAApAAAAKgAAACsAAAAsAAAALQAAAC4AAAAvAAAAMAAAADEAEXBvc3RncmVzLXVzZXJkYXRhAAAAAQAAAAD/////
	provenance.header.enable = false
	provenance.header.filter.overrides = 
	schema.registry.client.basic.auth.credentials.source = URL
	schema.registry.client.basic.auth.user.info = [hidden]
	schema.registry.max.schemas.per.subject = 1000
	schema.registry.topic = null
	schema.registry.url = null
	schema.subject.translator.class = null
	src.consumer.check.crcs = true
	src.consumer.fetch.max.bytes = 52428800
	src.consumer.fetch.max.wait.ms = 500
	src.consumer.fetch.min.bytes = 1
	src.consumer.interceptor.classes = []
	src.consumer.max.partition.fetch.bytes = 1048576
	src.consumer.max.poll.interval.ms = 300000
	src.consumer.max.poll.records = 500
	src.header.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	src.kafka.bootstrap.servers = [localhost:9092]
	src.kafka.client.id = 
	src.kafka.connections.max.idle.ms = 540000
	src.kafka.metric.reporters = []
	src.kafka.metrics.num.samples = 2
	src.kafka.metrics.sample.window.ms = 30000
	src.kafka.receive.buffer.bytes = 65536
	src.kafka.reconnect.backoff.ms = 50
	src.kafka.request.timeout.ms = 30000
	src.kafka.retry.backoff.ms = 100
	src.kafka.sasl.client.callback.handler.class = null
	src.kafka.sasl.jaas.config = null
	src.kafka.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	src.kafka.sasl.kerberos.min.time.before.relogin = 60000
	src.kafka.sasl.kerberos.service.name = null
	src.kafka.sasl.kerberos.ticket.renew.jitter = 0.05
	src.kafka.sasl.kerberos.ticket.renew.window.factor = 0.8
	src.kafka.sasl.login.callback.handler.class = null
	src.kafka.sasl.login.class = null
	src.kafka.sasl.login.connect.timeout.ms = null
	src.kafka.sasl.login.read.timeout.ms = null
	src.kafka.sasl.login.refresh.buffer.seconds = 300
	src.kafka.sasl.login.refresh.min.period.seconds = 60
	src.kafka.sasl.login.refresh.window.factor = 0.8
	src.kafka.sasl.login.refresh.window.jitter = 0.05
	src.kafka.sasl.login.retry.backoff.max.ms = 10000
	src.kafka.sasl.login.retry.backoff.ms = 100
	src.kafka.sasl.mechanism = GSSAPI
	src.kafka.sasl.oauthbearer.clock.skew.seconds = 30
	src.kafka.sasl.oauthbearer.expected.audience = null
	src.kafka.sasl.oauthbearer.expected.issuer = null
	src.kafka.sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	src.kafka.sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	src.kafka.sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	src.kafka.sasl.oauthbearer.jwks.endpoint.url = null
	src.kafka.sasl.oauthbearer.scope.claim.name = scope
	src.kafka.sasl.oauthbearer.sub.claim.name = sub
	src.kafka.sasl.oauthbearer.token.endpoint.url = null
	src.kafka.security.protocol = PLAINTEXT
	src.kafka.send.buffer.bytes = 131072
	src.kafka.ssl.cipher.suites = null
	src.kafka.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	src.kafka.ssl.endpoint.identification.algorithm = https
	src.kafka.ssl.engine.factory.class = null
	src.kafka.ssl.key.password = null
	src.kafka.ssl.keymanager.algorithm = SunX509
	src.kafka.ssl.keystore.certificate.chain = null
	src.kafka.ssl.keystore.key = null
	src.kafka.ssl.keystore.location = null
	src.kafka.ssl.keystore.password = null
	src.kafka.ssl.keystore.type = JKS
	src.kafka.ssl.protocol = TLSv1.3
	src.kafka.ssl.provider = null
	src.kafka.ssl.secure.random.implementation = null
	src.kafka.ssl.trustmanager.algorithm = PKIX
	src.kafka.ssl.truststore.certificates = null
	src.kafka.ssl.truststore.location = null
	src.kafka.ssl.truststore.password = null
	src.kafka.ssl.truststore.type = JKS
	src.key.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	src.value.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	task.id = replicator-localhost-0
	topic.auto.create = true
	topic.blacklist = []
	topic.config.sync = true
	topic.config.sync.interval.ms = 120000
	topic.create.backoff.ms = 120000
	topic.poll.interval.ms = 120000
	topic.preserve.partitions = true
	topic.regex = null
	topic.rename.format = ${topic}-replica
	topic.timestamp.type = CreateTime
	topic.whitelist = [postgres-userdata]
	value.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
 (io.confluent.connect.replicator.ReplicatorSourceTaskConfig:370)
[2024-02-05 13:50:40,881] INFO [replicator-localhost|task-0] Starting Replicator source task replicator-localhost-0 (io.confluent.connect.replicator.ReplicatorSourceTask:314)
[2024-02-05 13:50:40,882] INFO [replicator-localhost|task-0] AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	confluent.lkc.id = null
	confluent.metrics.reporter.bootstrap.servers = kafka-0:9071
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	confluent.use.controller.listener = false
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	host.resolver.class = class org.apache.kafka.clients.DefaultHostResolver
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:370)
[2024-02-05 13:50:40,885] INFO [replicator-localhost|task-0] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:50:40,886] INFO [replicator-localhost|task-0] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:50:40,886] INFO [replicator-localhost|task-0] Kafka startTimeMs: 1707121240885 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:50:40,886] INFO [replicator-localhost|task-0] AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	confluent.lkc.id = null
	confluent.metrics.reporter.bootstrap.servers = kafka-0:9071
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	confluent.use.controller.listener = false
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	host.resolver.class = class org.apache.kafka.clients.DefaultHostResolver
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:370)
[2024-02-05 13:50:40,890] INFO [replicator-localhost|task-0] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:50:40,890] INFO [replicator-localhost|task-0] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:50:40,890] INFO [replicator-localhost|task-0] Kafka startTimeMs: 1707121240890 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:50:40,891] INFO [replicator-localhost|worker] App info kafka.admin.client for adminclient-11 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:50:40,893] INFO [replicator-localhost|worker] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:50:40,893] INFO [replicator-localhost|worker] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:50:40,893] INFO [replicator-localhost|worker] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:50:40,893] INFO [replicator-localhost|worker] Starting License Store (io.confluent.license.LicenseStore:250)
[2024-02-05 13:50:40,894] INFO [replicator-localhost|worker] Starting KafkaBasedLog with topic _confluent-command (org.apache.kafka.connect.util.KafkaBasedLog:280)
[2024-02-05 13:50:40,894] INFO [replicator-localhost|worker] AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	confluent.lkc.id = null
	confluent.metrics.reporter.bootstrap.servers = kafka-0:9071
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	confluent.use.controller.listener = false
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	host.resolver.class = class org.apache.kafka.clients.DefaultHostResolver
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:370)
[2024-02-05 13:50:40,896] INFO [replicator-localhost|worker] These configurations '[replication.factor, group.id]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:379)
[2024-02-05 13:50:40,896] INFO [replicator-localhost|worker] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:50:40,896] INFO [replicator-localhost|worker] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:50:40,896] INFO [replicator-localhost|worker] Kafka startTimeMs: 1707121240896 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:50:40,903] INFO [replicator-localhost|worker] App info kafka.admin.client for adminclient-14 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:50:40,904] WARN [replicator-localhost|task-0] The source and destination cluster IDs match. This is normal when replicating to different topics in the same cluster. Otherwise, check your source and destination cluster properties. (io.confluent.connect.replicator.ReplicatorSourceTask:429)
[2024-02-05 13:50:40,904] INFO [replicator-localhost|task-0] Source cluster ID: xq-PEpqTSoutAwe9O2TUvQ (io.confluent.connect.replicator.ReplicatorSourceTask:436)
[2024-02-05 13:50:40,904] INFO [replicator-localhost|task-0] Destination cluster ID: xq-PEpqTSoutAwe9O2TUvQ (io.confluent.connect.replicator.ReplicatorSourceTask:437)
[2024-02-05 13:50:40,904] INFO [replicator-localhost|worker] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:50:40,904] INFO [replicator-localhost|worker] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:50:40,905] INFO [replicator-localhost|worker] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:50:40,905] INFO [replicator-localhost|task-0] ConsumerConfig values: 
	allow.auto.create.topics = false
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = replicator-localhost-0
	client.rack = 
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = replicator-localhost
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:370)
[2024-02-05 13:50:40,905] INFO [replicator-localhost|worker] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-null-license-3
	client.rack = 
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = null-license
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class io.confluent.license.LicenseStore$LicenseKeySerde
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.license.LicenseStore$LicenseMessageSerde
 (org.apache.kafka.clients.consumer.ConsumerConfig:370)
[2024-02-05 13:50:40,908] INFO [replicator-localhost|task-0] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:50:40,909] INFO [replicator-localhost|task-0] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:50:40,909] INFO [replicator-localhost|task-0] Kafka startTimeMs: 1707121240908 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:50:40,909] INFO [replicator-localhost|worker] These configurations '[replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:379)
[2024-02-05 13:50:40,909] INFO [replicator-localhost|worker] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:50:40,909] INFO [replicator-localhost|worker] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:50:40,910] INFO [replicator-localhost|worker] Kafka startTimeMs: 1707121240909 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:50:40,910] INFO [replicator-localhost|task-0] ConsumerOffsetsTranslatorConfig values: 
	confluent.license = [hidden]
	confluent.topic = _confluent-command
	consumer.poll.timeout.interval.ms = 5000
	dest.kafka.bootstrap.servers = [localhost:9092]
	dest.kafka.client.id = 
	dest.kafka.connections.max.idle.ms = 540000
	dest.kafka.metric.reporters = []
	dest.kafka.metrics.num.samples = 2
	dest.kafka.metrics.sample.window.ms = 30000
	dest.kafka.receive.buffer.bytes = 65536
	dest.kafka.reconnect.backoff.ms = 50
	dest.kafka.request.timeout.ms = 30000
	dest.kafka.retry.backoff.ms = 100
	dest.kafka.sasl.client.callback.handler.class = null
	dest.kafka.sasl.jaas.config = null
	dest.kafka.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	dest.kafka.sasl.kerberos.min.time.before.relogin = 60000
	dest.kafka.sasl.kerberos.service.name = null
	dest.kafka.sasl.kerberos.ticket.renew.jitter = 0.05
	dest.kafka.sasl.kerberos.ticket.renew.window.factor = 0.8
	dest.kafka.sasl.login.callback.handler.class = null
	dest.kafka.sasl.login.class = null
	dest.kafka.sasl.login.connect.timeout.ms = null
	dest.kafka.sasl.login.read.timeout.ms = null
	dest.kafka.sasl.login.refresh.buffer.seconds = 300
	dest.kafka.sasl.login.refresh.min.period.seconds = 60
	dest.kafka.sasl.login.refresh.window.factor = 0.8
	dest.kafka.sasl.login.refresh.window.jitter = 0.05
	dest.kafka.sasl.login.retry.backoff.max.ms = 10000
	dest.kafka.sasl.login.retry.backoff.ms = 100
	dest.kafka.sasl.mechanism = GSSAPI
	dest.kafka.sasl.oauthbearer.clock.skew.seconds = 30
	dest.kafka.sasl.oauthbearer.expected.audience = null
	dest.kafka.sasl.oauthbearer.expected.issuer = null
	dest.kafka.sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	dest.kafka.sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	dest.kafka.sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	dest.kafka.sasl.oauthbearer.jwks.endpoint.url = null
	dest.kafka.sasl.oauthbearer.scope.claim.name = scope
	dest.kafka.sasl.oauthbearer.sub.claim.name = sub
	dest.kafka.sasl.oauthbearer.token.endpoint.url = null
	dest.kafka.security.protocol = PLAINTEXT
	dest.kafka.send.buffer.bytes = 131072
	dest.kafka.ssl.cipher.suites = null
	dest.kafka.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	dest.kafka.ssl.endpoint.identification.algorithm = https
	dest.kafka.ssl.engine.factory.class = null
	dest.kafka.ssl.key.password = null
	dest.kafka.ssl.keymanager.algorithm = SunX509
	dest.kafka.ssl.keystore.certificate.chain = null
	dest.kafka.ssl.keystore.key = null
	dest.kafka.ssl.keystore.location = null
	dest.kafka.ssl.keystore.password = null
	dest.kafka.ssl.keystore.type = JKS
	dest.kafka.ssl.protocol = TLSv1.3
	dest.kafka.ssl.provider = null
	dest.kafka.ssl.secure.random.implementation = null
	dest.kafka.ssl.trustmanager.algorithm = PKIX
	dest.kafka.ssl.truststore.certificates = null
	dest.kafka.ssl.truststore.location = null
	dest.kafka.ssl.truststore.password = null
	dest.kafka.ssl.truststore.type = JKS
	dest.topic.replication.factor = 0
	fetch.offset.expiry.ms = 600000
	fetch.offset.retry.backoff.ms = 100
	header.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	key.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	offset.start = connect
	offset.timestamps.commit = true
	offset.topic.commit = true
	offset.topic.commit.batch.period.ms = 60000
	offset.translator.batch.period.ms = 60000
	offset.translator.batch.size = 2147483647
	offset.translator.tasks.max = -1
	offset.translator.tasks.separate = false
	provenance.header.enable = false
	provenance.header.filter.overrides = 
	schema.registry.client.basic.auth.credentials.source = URL
	schema.registry.client.basic.auth.user.info = [hidden]
	schema.registry.max.schemas.per.subject = 1000
	schema.registry.topic = null
	schema.registry.url = null
	schema.subject.translator.class = null
	src.consumer.check.crcs = true
	src.consumer.fetch.max.bytes = 52428800
	src.consumer.fetch.max.wait.ms = 500
	src.consumer.fetch.min.bytes = 1
	src.consumer.interceptor.classes = []
	src.consumer.max.partition.fetch.bytes = 1048576
	src.consumer.max.poll.interval.ms = 300000
	src.consumer.max.poll.records = 500
	src.header.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	src.kafka.bootstrap.servers = [localhost:9092]
	src.kafka.client.id = 
	src.kafka.connections.max.idle.ms = 540000
	src.kafka.metric.reporters = []
	src.kafka.metrics.num.samples = 2
	src.kafka.metrics.sample.window.ms = 30000
	src.kafka.receive.buffer.bytes = 65536
	src.kafka.reconnect.backoff.ms = 50
	src.kafka.request.timeout.ms = 30000
	src.kafka.retry.backoff.ms = 100
	src.kafka.sasl.client.callback.handler.class = null
	src.kafka.sasl.jaas.config = null
	src.kafka.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	src.kafka.sasl.kerberos.min.time.before.relogin = 60000
	src.kafka.sasl.kerberos.service.name = null
	src.kafka.sasl.kerberos.ticket.renew.jitter = 0.05
	src.kafka.sasl.kerberos.ticket.renew.window.factor = 0.8
	src.kafka.sasl.login.callback.handler.class = null
	src.kafka.sasl.login.class = null
	src.kafka.sasl.login.connect.timeout.ms = null
	src.kafka.sasl.login.read.timeout.ms = null
	src.kafka.sasl.login.refresh.buffer.seconds = 300
	src.kafka.sasl.login.refresh.min.period.seconds = 60
	src.kafka.sasl.login.refresh.window.factor = 0.8
	src.kafka.sasl.login.refresh.window.jitter = 0.05
	src.kafka.sasl.login.retry.backoff.max.ms = 10000
	src.kafka.sasl.login.retry.backoff.ms = 100
	src.kafka.sasl.mechanism = GSSAPI
	src.kafka.sasl.oauthbearer.clock.skew.seconds = 30
	src.kafka.sasl.oauthbearer.expected.audience = null
	src.kafka.sasl.oauthbearer.expected.issuer = null
	src.kafka.sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	src.kafka.sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	src.kafka.sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	src.kafka.sasl.oauthbearer.jwks.endpoint.url = null
	src.kafka.sasl.oauthbearer.scope.claim.name = scope
	src.kafka.sasl.oauthbearer.sub.claim.name = sub
	src.kafka.sasl.oauthbearer.token.endpoint.url = null
	src.kafka.security.protocol = PLAINTEXT
	src.kafka.send.buffer.bytes = 131072
	src.kafka.ssl.cipher.suites = null
	src.kafka.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	src.kafka.ssl.endpoint.identification.algorithm = https
	src.kafka.ssl.engine.factory.class = null
	src.kafka.ssl.key.password = null
	src.kafka.ssl.keymanager.algorithm = SunX509
	src.kafka.ssl.keystore.certificate.chain = null
	src.kafka.ssl.keystore.key = null
	src.kafka.ssl.keystore.location = null
	src.kafka.ssl.keystore.password = null
	src.kafka.ssl.keystore.type = JKS
	src.kafka.ssl.protocol = TLSv1.3
	src.kafka.ssl.provider = null
	src.kafka.ssl.secure.random.implementation = null
	src.kafka.ssl.trustmanager.algorithm = PKIX
	src.kafka.ssl.truststore.certificates = null
	src.kafka.ssl.truststore.location = null
	src.kafka.ssl.truststore.password = null
	src.kafka.ssl.truststore.type = JKS
	src.key.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	src.value.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	topic.auto.create = true
	topic.blacklist = []
	topic.config.sync = true
	topic.config.sync.interval.ms = 120000
	topic.create.backoff.ms = 120000
	topic.poll.interval.ms = 120000
	topic.preserve.partitions = true
	topic.regex = null
	topic.rename.format = ${topic}-replica
	topic.timestamp.type = CreateTime
	topic.whitelist = [postgres-userdata]
	value.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
 (io.confluent.connect.replicator.offsets.ConsumerOffsetsTranslatorConfig:370)
[2024-02-05 13:50:40,911] INFO [replicator-localhost|task-0] Requesting metadata refresh after 1 new topics were added (io.confluent.connect.replicator.util.ReplicatorAdminClient:254)
[2024-02-05 13:50:40,911] INFO [replicator-localhost|task-0] ConsumerTimestampsWriterConfig values: 
	timestamps.producer.max.per.partition = 2147483647
	timestamps.producer.topic.blacklist = []
	timestamps.producer.topic.regex = null
	timestamps.producer.topic.whitelist = null
	timestamps.topic.num.partitions = 50
	timestamps.topic.replication.factor = 3
 (io.confluent.connect.replicator.offsets.ConsumerTimestampsWriterConfig:370)
[2024-02-05 13:50:40,913] INFO [replicator-localhost|worker] [Consumer clientId=consumer-null-license-3, groupId=null-license] Cluster ID: xq-PEpqTSoutAwe9O2TUvQ (org.apache.kafka.clients.Metadata:287)
[2024-02-05 13:50:40,914] INFO [replicator-localhost|worker] [Consumer clientId=consumer-null-license-3, groupId=null-license] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1025)
[2024-02-05 13:50:40,914] INFO [replicator-localhost|worker] [Consumer clientId=consumer-null-license-3, groupId=null-license] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1072)
[2024-02-05 13:50:40,914] INFO [replicator-localhost|worker] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:50:40,914] INFO [replicator-localhost|worker] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:50:40,914] INFO [replicator-localhost|worker] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:50:40,915] INFO [replicator-localhost|task-0] ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-3
	compression.type = lz4
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = true
	interceptor.classes = []
	key.serializer = class io.confluent.connect.replicator.offsets.GroupTopicPartitionSerializer
	linger.ms = 500
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 10485760
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class io.confluent.connect.replicator.offsets.TimestampAndDeltaSerializer
 (org.apache.kafka.clients.producer.ProducerConfig:370)
[2024-02-05 13:50:40,916] INFO [replicator-localhost|worker] App info kafka.consumer for consumer-null-license-3 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:50:40,916] INFO [replicator-localhost|worker] ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [localhost:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-4
	compression.type = none
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class io.confluent.license.LicenseStore$LicenseKeySerde
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class io.confluent.license.LicenseStore$LicenseMessageSerde
 (org.apache.kafka.clients.producer.ProducerConfig:370)
[2024-02-05 13:50:40,919] INFO [replicator-localhost|task-0] [Producer clientId=producer-3] Instantiated an idempotent producer. (org.apache.kafka.clients.producer.KafkaProducer:596)
[2024-02-05 13:50:40,919] INFO [replicator-localhost|worker] These configurations '[replication.factor, group.id]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:379)
[2024-02-05 13:50:40,920] INFO [replicator-localhost|worker] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:50:40,920] INFO [replicator-localhost|worker] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:50:40,920] INFO [replicator-localhost|worker] Kafka startTimeMs: 1707121240920 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:50:40,920] INFO [replicator-localhost|worker] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-null-license-4
	client.rack = 
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = null-license
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class io.confluent.license.LicenseStore$LicenseKeySerde
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.license.LicenseStore$LicenseMessageSerde
 (org.apache.kafka.clients.consumer.ConsumerConfig:370)
[2024-02-05 13:50:40,926] INFO [replicator-localhost|worker] These configurations '[replication.factor]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:379)
[2024-02-05 13:50:40,926] INFO [replicator-localhost|worker] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:50:40,926] INFO [replicator-localhost|worker] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:50:40,926] INFO [replicator-localhost|worker] Kafka startTimeMs: 1707121240926 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:50:40,929] INFO [replicator-localhost|worker] [Consumer clientId=consumer-null-license-4, groupId=null-license] Cluster ID: xq-PEpqTSoutAwe9O2TUvQ (org.apache.kafka.clients.Metadata:287)
[2024-02-05 13:50:40,929] INFO [replicator-localhost|worker] [Consumer clientId=consumer-null-license-4, groupId=null-license] Assigned to partition(s): _confluent-command-0 (org.apache.kafka.clients.consumer.KafkaConsumer:1135)
[2024-02-05 13:50:40,929] INFO [replicator-localhost|worker] [Consumer clientId=consumer-null-license-4, groupId=null-license] Seeking to earliest offset of partition _confluent-command-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:50:40,932] INFO [replicator-localhost|worker] [Producer clientId=producer-4] Cluster ID: xq-PEpqTSoutAwe9O2TUvQ (org.apache.kafka.clients.Metadata:287)
[2024-02-05 13:50:40,938] INFO [replicator-localhost|task-0] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:50:40,939] INFO [replicator-localhost|task-0] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:50:40,939] INFO [replicator-localhost|task-0] Kafka startTimeMs: 1707121240938 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:50:40,939] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Assigned to partition(s): __consumer_timestamps-0, __consumer_timestamps-1, __consumer_timestamps-2, __consumer_timestamps-3, __consumer_timestamps-4, __consumer_timestamps-5, __consumer_timestamps-6, __consumer_timestamps-7, __consumer_timestamps-8, __consumer_timestamps-9, __consumer_timestamps-10, __consumer_timestamps-11, __consumer_timestamps-12, __consumer_timestamps-13, __consumer_timestamps-14, __consumer_timestamps-15, __consumer_timestamps-16, __consumer_timestamps-17, __consumer_timestamps-18, __consumer_timestamps-19, __consumer_timestamps-20, __consumer_timestamps-21, __consumer_timestamps-22, __consumer_timestamps-23, __consumer_timestamps-24, __consumer_timestamps-25, __consumer_timestamps-26, __consumer_timestamps-27, __consumer_timestamps-28, __consumer_timestamps-29, __consumer_timestamps-30, __consumer_timestamps-31, __consumer_timestamps-32, __consumer_timestamps-33, __consumer_timestamps-34, __consumer_timestamps-35, __consumer_timestamps-36, __consumer_timestamps-37, __consumer_timestamps-38, __consumer_timestamps-39, __consumer_timestamps-40, __consumer_timestamps-41, __consumer_timestamps-42, __consumer_timestamps-43, __consumer_timestamps-44, __consumer_timestamps-45, __consumer_timestamps-46, __consumer_timestamps-47, __consumer_timestamps-48, __consumer_timestamps-49, postgres-userdata-0 (org.apache.kafka.clients.consumer.KafkaConsumer:1135)
[2024-02-05 13:50:40,940] INFO [replicator-localhost|worker] Finished reading KafkaBasedLog for topic _confluent-command (org.apache.kafka.connect.util.KafkaBasedLog:337)
[2024-02-05 13:50:40,940] INFO [replicator-localhost|worker] Started KafkaBasedLog for topic _confluent-command (org.apache.kafka.connect.util.KafkaBasedLog:339)
[2024-02-05 13:50:40,940] INFO [replicator-localhost|worker] Started License Store (io.confluent.license.LicenseStore:252)
[2024-02-05 13:50:40,940] INFO [replicator-localhost|task-0] Requesting metadata refresh after 1 new topics were added (io.confluent.connect.replicator.util.ReplicatorAdminClient:254)
[2024-02-05 13:50:40,942] INFO [replicator-localhost|worker] Validating Confluent Replicator License... (io.confluent.connect.replicator.ReplicatorSourceConnector:214)
[2024-02-05 13:50:40,955] INFO [replicator-localhost|task-0] [Producer clientId=producer-3] Cluster ID: xq-PEpqTSoutAwe9O2TUvQ (org.apache.kafka.clients.Metadata:287)
[2024-02-05 13:50:40,956] INFO [replicator-localhost|task-0] [Producer clientId=producer-3] ProducerId set to 9002 with epoch 0 (org.apache.kafka.clients.producer.internals.TransactionManager:441)
[2024-02-05 13:50:41,082] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=12, memberId='connect-1-5626c631-09b4-4bc6-b13c-f89c6adf07d0', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:637)
[2024-02-05 13:50:41,298] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=12, memberId='connect-1-5626c631-09b4-4bc6-b13c-f89c6adf07d0', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:812)
[2024-02-05 13:50:41,299] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 12 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-5626c631-09b4-4bc6-b13c-f89c6adf07d0', leaderUrl='http://127.0.1.1:8083/', offset=140, connectorIds=[replicator-localhost, s3-sink, jdbc_sink_connector, jdbc_source_postgres, replicator-cloud], taskIds=[replicator-localhost-0, s3-sink-0, jdbc_sink_connector-0, jdbc_source_postgres-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2416)
[2024-02-05 13:50:41,299] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 140 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1776)
[2024-02-05 13:50:41,299] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1804)
[2024-02-05 13:50:41,383] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Seeking to offset 24 for partition postgres-userdata-0 (org.apache.kafka.clients.consumer.KafkaConsumer:1632)
[2024-02-05 13:50:41,393] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Cluster ID: xq-PEpqTSoutAwe9O2TUvQ (org.apache.kafka.clients.Metadata:287)
[2024-02-05 13:50:41,394] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Discovered group coordinator sumo-HP-EliteBook-840-G4:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:906)
[2024-02-05 13:50:41,404] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Found no committed offset for partition __consumer_timestamps-15 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:50:41,405] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Found no committed offset for partition __consumer_timestamps-40 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:50:41,405] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Found no committed offset for partition __consumer_timestamps-23 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:50:41,406] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Found no committed offset for partition __consumer_timestamps-48 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:50:41,406] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Found no committed offset for partition __consumer_timestamps-31 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:50:41,407] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Found no committed offset for partition __consumer_timestamps-27 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:50:41,407] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Found no committed offset for partition __consumer_timestamps-6 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:50:41,407] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Found no committed offset for partition __consumer_timestamps-35 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:50:41,408] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Found no committed offset for partition __consumer_timestamps-2 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:50:41,408] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Found no committed offset for partition __consumer_timestamps-47 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:50:41,408] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Found no committed offset for partition __consumer_timestamps-14 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:50:41,409] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Found no committed offset for partition __consumer_timestamps-18 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:50:41,409] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Found no committed offset for partition __consumer_timestamps-30 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:50:41,409] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Found no committed offset for partition __consumer_timestamps-26 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:50:41,410] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Found no committed offset for partition __consumer_timestamps-38 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:50:41,410] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Found no committed offset for partition __consumer_timestamps-34 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:50:41,411] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Found no committed offset for partition __consumer_timestamps-1 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:50:41,411] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Found no committed offset for partition __consumer_timestamps-46 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:50:41,411] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Found no committed offset for partition __consumer_timestamps-42 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:50:41,412] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Found no committed offset for partition __consumer_timestamps-9 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:50:41,412] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Found no committed offset for partition __consumer_timestamps-29 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:50:41,412] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Found no committed offset for partition __consumer_timestamps-25 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:50:41,413] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Found no committed offset for partition __consumer_timestamps-37 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:50:41,413] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Found no committed offset for partition __consumer_timestamps-4 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:50:41,413] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Found no committed offset for partition __consumer_timestamps-33 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:50:41,414] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Found no committed offset for partition __consumer_timestamps-45 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:50:41,414] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Found no committed offset for partition __consumer_timestamps-12 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:50:41,414] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Found no committed offset for partition __consumer_timestamps-41 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:50:41,414] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Found no committed offset for partition __consumer_timestamps-20 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:50:41,415] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Found no committed offset for partition __consumer_timestamps-16 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:50:41,415] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Found no committed offset for partition __consumer_timestamps-28 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:50:41,416] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Found no committed offset for partition __consumer_timestamps-24 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:50:41,417] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Found no committed offset for partition __consumer_timestamps-7 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:50:41,418] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Found no committed offset for partition __consumer_timestamps-3 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:50:41,418] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Found no committed offset for partition __consumer_timestamps-32 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1545)
[2024-02-05 13:50:41,419] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Seeking to earliest offset of partition __consumer_timestamps-15 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:50:41,419] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Seeking to earliest offset of partition __consumer_timestamps-40 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:50:41,419] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Seeking to earliest offset of partition __consumer_timestamps-23 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:50:41,420] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Seeking to earliest offset of partition __consumer_timestamps-48 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:50:41,420] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Seeking to earliest offset of partition __consumer_timestamps-31 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:50:41,420] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Seeking to earliest offset of partition __consumer_timestamps-27 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:50:41,420] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Seeking to earliest offset of partition __consumer_timestamps-6 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:50:41,421] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Seeking to earliest offset of partition __consumer_timestamps-35 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:50:41,421] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Seeking to earliest offset of partition __consumer_timestamps-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:50:41,421] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Seeking to earliest offset of partition __consumer_timestamps-47 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:50:41,421] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Seeking to earliest offset of partition __consumer_timestamps-14 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:50:41,422] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Seeking to earliest offset of partition __consumer_timestamps-18 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:50:41,422] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Seeking to earliest offset of partition __consumer_timestamps-30 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:50:41,422] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Seeking to earliest offset of partition __consumer_timestamps-26 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:50:41,423] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Seeking to earliest offset of partition __consumer_timestamps-38 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:50:41,423] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Seeking to earliest offset of partition __consumer_timestamps-34 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:50:41,423] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Seeking to earliest offset of partition __consumer_timestamps-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:50:41,423] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Seeking to earliest offset of partition __consumer_timestamps-46 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:50:41,424] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Seeking to earliest offset of partition __consumer_timestamps-42 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:50:41,424] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Seeking to earliest offset of partition __consumer_timestamps-9 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:50:41,424] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Seeking to earliest offset of partition __consumer_timestamps-29 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:50:41,424] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Seeking to earliest offset of partition __consumer_timestamps-25 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:50:41,424] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Seeking to earliest offset of partition __consumer_timestamps-37 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:50:41,425] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Seeking to earliest offset of partition __consumer_timestamps-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:50:41,425] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Seeking to earliest offset of partition __consumer_timestamps-33 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:50:41,425] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Seeking to earliest offset of partition __consumer_timestamps-45 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:50:41,426] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Seeking to earliest offset of partition __consumer_timestamps-12 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:50:41,426] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Seeking to earliest offset of partition __consumer_timestamps-41 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:50:41,426] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Seeking to earliest offset of partition __consumer_timestamps-20 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:50:41,427] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Seeking to earliest offset of partition __consumer_timestamps-16 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:50:41,428] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Seeking to earliest offset of partition __consumer_timestamps-28 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:50:41,428] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Seeking to earliest offset of partition __consumer_timestamps-24 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:50:41,428] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Seeking to earliest offset of partition __consumer_timestamps-7 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:50:41,429] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Seeking to earliest offset of partition __consumer_timestamps-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:50:41,429] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Seeking to earliest offset of partition __consumer_timestamps-32 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:50:41,430] INFO [replicator-localhost|task-0] Started kafka replicator task replicator-localhost-0 replicating topic partitions [__consumer_timestamps-0, __consumer_timestamps-1, __consumer_timestamps-2, __consumer_timestamps-3, __consumer_timestamps-4, __consumer_timestamps-5, __consumer_timestamps-6, __consumer_timestamps-7, __consumer_timestamps-8, __consumer_timestamps-9, __consumer_timestamps-10, __consumer_timestamps-11, __consumer_timestamps-12, __consumer_timestamps-13, __consumer_timestamps-14, __consumer_timestamps-15, __consumer_timestamps-16, __consumer_timestamps-17, __consumer_timestamps-18, __consumer_timestamps-19, __consumer_timestamps-20, __consumer_timestamps-21, __consumer_timestamps-22, __consumer_timestamps-23, __consumer_timestamps-24, __consumer_timestamps-25, __consumer_timestamps-26, __consumer_timestamps-27, __consumer_timestamps-28, __consumer_timestamps-29, __consumer_timestamps-30, __consumer_timestamps-31, __consumer_timestamps-32, __consumer_timestamps-33, __consumer_timestamps-34, __consumer_timestamps-35, __consumer_timestamps-36, __consumer_timestamps-37, __consumer_timestamps-38, __consumer_timestamps-39, __consumer_timestamps-40, __consumer_timestamps-41, __consumer_timestamps-42, __consumer_timestamps-43, __consumer_timestamps-44, __consumer_timestamps-45, __consumer_timestamps-46, __consumer_timestamps-47, __consumer_timestamps-48, __consumer_timestamps-49, postgres-userdata-0] (io.confluent.connect.replicator.ReplicatorSourceTask:390)
[2024-02-05 13:50:41,431] INFO [replicator-localhost|task-0] Setting up metrics recording for task replicator-localhost-0... (io.confluent.connect.replicator.ReplicatorSourceTask:395)
[2024-02-05 13:50:41,431] INFO [replicator-localhost|task-0] Registering Confluent Replicator metrics with JMX for task 'replicator-localhost-0' (io.confluent.connect.replicator.metrics.ConfluentReplicatorMetrics:60)
[2024-02-05 13:50:41,433] INFO [replicator-localhost|task-0] Successfully registered Confluent Replicator metrics with JMX for task 'replicator-localhost-0' (io.confluent.connect.replicator.metrics.ConfluentReplicatorMetrics:69)
[2024-02-05 13:50:41,458] INFO [replicator-localhost|worker] AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	confluent.lkc.id = null
	confluent.metrics.reporter.bootstrap.servers = kafka-0:9071
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	confluent.use.controller.listener = false
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	host.resolver.class = class org.apache.kafka.clients.DefaultHostResolver
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:370)
[2024-02-05 13:50:41,473] INFO [replicator-localhost|worker] These configurations '[replication.factor, group.id]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:379)
[2024-02-05 13:50:41,474] INFO [replicator-localhost|worker] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:50:41,475] INFO [replicator-localhost|worker] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:50:41,475] INFO [replicator-localhost|worker] Kafka startTimeMs: 1707121241474 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:50:41,490] INFO [replicator-localhost|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = confluent-replicator-end-offsets-consumer-client
	client.rack = 
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = confluent-replicator-end-offsets-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:370)
[2024-02-05 13:50:41,495] INFO [replicator-localhost|worker] App info kafka.admin.client for adminclient-15 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:50:41,498] INFO [replicator-localhost|task-0] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:50:41,498] INFO [replicator-localhost|task-0] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:50:41,498] INFO [replicator-localhost|task-0] Kafka startTimeMs: 1707121241498 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:50:41,499] INFO [replicator-localhost|task-0] Successfully set up metrics recording for task replicator-localhost-0 (io.confluent.connect.replicator.ReplicatorSourceTask:402)
[2024-02-05 13:50:41,499] INFO [replicator-localhost|task-0] Successfully started up Replicator source task replicator-localhost-0 (io.confluent.connect.replicator.ReplicatorSourceTask:403)
[2024-02-05 13:50:41,499] INFO [replicator-localhost|task-0] WorkerSourceTask{id=replicator-localhost-0} Source task finished initialization and start (org.apache.kafka.connect.runtime.AbstractWorkerSourceTask:284)
[2024-02-05 13:50:41,503] INFO [replicator-localhost|worker] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:50:41,503] INFO [replicator-localhost|worker] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:50:41,503] INFO [replicator-localhost|worker] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:50:41,505] INFO [replicator-localhost|worker] AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	confluent.lkc.id = null
	confluent.metrics.reporter.bootstrap.servers = kafka-0:9071
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	confluent.use.controller.listener = false
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	host.resolver.class = class org.apache.kafka.clients.DefaultHostResolver
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:370)
[2024-02-05 13:50:41,508] INFO [replicator-localhost|worker] These configurations '[replication.factor, group.id]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:379)
[2024-02-05 13:50:41,508] INFO [replicator-localhost|worker] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:50:41,508] INFO [replicator-localhost|worker] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:50:41,508] INFO [replicator-localhost|worker] Kafka startTimeMs: 1707121241508 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:50:41,509] INFO [Worker clientId=connect-1, groupId=connect-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2284)
[2024-02-05 13:50:41,514] INFO [replicator-localhost|task-0] [Consumer clientId=confluent-replicator-end-offsets-consumer-client, groupId=confluent-replicator-end-offsets-consumer-group] Cluster ID: xq-PEpqTSoutAwe9O2TUvQ (org.apache.kafka.clients.Metadata:287)
[2024-02-05 13:50:41,515] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Setting offset for partition __consumer_timestamps-13 to the committed offset FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[sumo-HP-EliteBook-840-G4:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:975)
[2024-02-05 13:50:41,516] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Setting offset for partition __consumer_timestamps-44 to the committed offset FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[sumo-HP-EliteBook-840-G4:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:975)
[2024-02-05 13:50:41,516] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Setting offset for partition __consumer_timestamps-11 to the committed offset FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[sumo-HP-EliteBook-840-G4:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:975)
[2024-02-05 13:50:41,516] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Setting offset for partition __consumer_timestamps-43 to the committed offset FetchPosition{offset=2, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[sumo-HP-EliteBook-840-G4:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:975)
[2024-02-05 13:50:41,516] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Setting offset for partition __consumer_timestamps-10 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[sumo-HP-EliteBook-840-G4:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:975)
[2024-02-05 13:50:41,516] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Setting offset for partition __consumer_timestamps-8 to the committed offset FetchPosition{offset=10, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[sumo-HP-EliteBook-840-G4:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:975)
[2024-02-05 13:50:41,517] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Setting offset for partition __consumer_timestamps-22 to the committed offset FetchPosition{offset=5, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[sumo-HP-EliteBook-840-G4:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:975)
[2024-02-05 13:50:41,517] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Setting offset for partition __consumer_timestamps-21 to the committed offset FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[sumo-HP-EliteBook-840-G4:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:975)
[2024-02-05 13:50:41,519] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Setting offset for partition __consumer_timestamps-19 to the committed offset FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[sumo-HP-EliteBook-840-G4:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:975)
[2024-02-05 13:50:41,519] INFO [replicator-localhost|worker] App info kafka.admin.client for adminclient-16 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:50:41,519] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Setting offset for partition __consumer_timestamps-49 to the committed offset FetchPosition{offset=3, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[sumo-HP-EliteBook-840-G4:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:975)
[2024-02-05 13:50:41,520] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Setting offset for partition __consumer_timestamps-17 to the committed offset FetchPosition{offset=3, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[sumo-HP-EliteBook-840-G4:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:975)
[2024-02-05 13:50:41,520] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Setting offset for partition __consumer_timestamps-39 to the committed offset FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[sumo-HP-EliteBook-840-G4:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:975)
[2024-02-05 13:50:41,520] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Setting offset for partition __consumer_timestamps-5 to the committed offset FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[sumo-HP-EliteBook-840-G4:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:975)
[2024-02-05 13:50:41,520] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Setting offset for partition __consumer_timestamps-36 to the committed offset FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[sumo-HP-EliteBook-840-G4:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:975)
[2024-02-05 13:50:41,520] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Setting offset for partition __consumer_timestamps-0 to the committed offset FetchPosition{offset=9, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[sumo-HP-EliteBook-840-G4:9092 (id: 0 rack: null)], epoch=0}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:975)
[2024-02-05 13:50:41,520] INFO [replicator-localhost|worker] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:50:41,521] INFO [replicator-localhost|worker] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:50:41,521] INFO [replicator-localhost|worker] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:50:41,521] INFO [replicator-localhost|worker] License for single cluster, single node (io.confluent.license.LicenseManager:544)
[2024-02-05 13:50:41,521] INFO [replicator-localhost|worker] AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [localhost:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	confluent.lkc.id = null
	confluent.metrics.reporter.bootstrap.servers = kafka-0:9071
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	confluent.use.controller.listener = false
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	host.resolver.class = class org.apache.kafka.clients.DefaultHostResolver
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:370)
[2024-02-05 13:50:41,523] INFO [replicator-localhost|worker] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:50:41,523] INFO [replicator-localhost|worker] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:50:41,523] INFO [replicator-localhost|worker] Kafka startTimeMs: 1707121241523 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:50:41,537] INFO [replicator-localhost|worker] Found matching topics: [postgres-userdata, __consumer_timestamps] (io.confluent.connect.replicator.NewTopicMonitorThread:330)
[2024-02-05 13:50:41,990] INFO SourceConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.replicator.ReplicatorSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	name = replicator-localhost
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
 (org.apache.kafka.connect.runtime.SourceConnectorConfig:370)
[2024-02-05 13:50:41,991] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.replicator.ReplicatorSourceConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	exactly.once.support = requested
	header.converter = null
	key.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	name = replicator-localhost
	offsets.storage.topic = null
	predicates = []
	tasks.max = 1
	topic.creation.groups = []
	transaction.boundary = poll
	transaction.boundary.interval.ms = null
	transforms = []
	value.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:370)
[2024-02-05 13:50:41,991] INFO [replicator-localhost|worker] Gathering task configs... (io.confluent.connect.replicator.ReplicatorSourceConnector:110)
[2024-02-05 13:50:41,991] INFO [replicator-localhost|worker] Assigning topic partitions to 1 tasks... (io.confluent.connect.replicator.NewTopicMonitorThread:150)
[2024-02-05 13:50:41,992] INFO [replicator-localhost|worker] Finished computing task topic partition assignments: {replicator-localhost-0=Assignment(partitions=[__consumer_timestamps-0, __consumer_timestamps-1, __consumer_timestamps-2, __consumer_timestamps-3, __consumer_timestamps-4, __consumer_timestamps-5, __consumer_timestamps-6, __consumer_timestamps-7, __consumer_timestamps-8, __consumer_timestamps-9, __consumer_timestamps-10, __consumer_timestamps-11, __consumer_timestamps-12, __consumer_timestamps-13, __consumer_timestamps-14, __consumer_timestamps-15, __consumer_timestamps-16, __consumer_timestamps-17, __consumer_timestamps-18, __consumer_timestamps-19, __consumer_timestamps-20, __consumer_timestamps-21, __consumer_timestamps-22, __consumer_timestamps-23, __consumer_timestamps-24, __consumer_timestamps-25, __consumer_timestamps-26, __consumer_timestamps-27, __consumer_timestamps-28, __consumer_timestamps-29, __consumer_timestamps-30, __consumer_timestamps-31, __consumer_timestamps-32, __consumer_timestamps-33, __consumer_timestamps-34, __consumer_timestamps-35, __consumer_timestamps-36, __consumer_timestamps-37, __consumer_timestamps-38, __consumer_timestamps-39, __consumer_timestamps-40, __consumer_timestamps-41, __consumer_timestamps-42, __consumer_timestamps-43, __consumer_timestamps-44, __consumer_timestamps-45, __consumer_timestamps-46, __consumer_timestamps-47, __consumer_timestamps-48, __consumer_timestamps-49, postgres-userdata-0])} (io.confluent.connect.replicator.NewTopicMonitorThread:185)
[2024-02-05 13:50:41,992] INFO [replicator-localhost|worker] ReplicatorSourceTaskConfig values: 
	confluent.license = [hidden]
	confluent.topic = _confluent-command
	consumer.poll.timeout.interval.ms = 5000
	dest.kafka.bootstrap.servers = [localhost:9092]
	dest.kafka.client.id = 
	dest.kafka.connections.max.idle.ms = 540000
	dest.kafka.metric.reporters = []
	dest.kafka.metrics.num.samples = 2
	dest.kafka.metrics.sample.window.ms = 30000
	dest.kafka.receive.buffer.bytes = 65536
	dest.kafka.reconnect.backoff.ms = 50
	dest.kafka.request.timeout.ms = 30000
	dest.kafka.retry.backoff.ms = 100
	dest.kafka.sasl.client.callback.handler.class = null
	dest.kafka.sasl.jaas.config = null
	dest.kafka.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	dest.kafka.sasl.kerberos.min.time.before.relogin = 60000
	dest.kafka.sasl.kerberos.service.name = null
	dest.kafka.sasl.kerberos.ticket.renew.jitter = 0.05
	dest.kafka.sasl.kerberos.ticket.renew.window.factor = 0.8
	dest.kafka.sasl.login.callback.handler.class = null
	dest.kafka.sasl.login.class = null
	dest.kafka.sasl.login.connect.timeout.ms = null
	dest.kafka.sasl.login.read.timeout.ms = null
	dest.kafka.sasl.login.refresh.buffer.seconds = 300
	dest.kafka.sasl.login.refresh.min.period.seconds = 60
	dest.kafka.sasl.login.refresh.window.factor = 0.8
	dest.kafka.sasl.login.refresh.window.jitter = 0.05
	dest.kafka.sasl.login.retry.backoff.max.ms = 10000
	dest.kafka.sasl.login.retry.backoff.ms = 100
	dest.kafka.sasl.mechanism = GSSAPI
	dest.kafka.sasl.oauthbearer.clock.skew.seconds = 30
	dest.kafka.sasl.oauthbearer.expected.audience = null
	dest.kafka.sasl.oauthbearer.expected.issuer = null
	dest.kafka.sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	dest.kafka.sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	dest.kafka.sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	dest.kafka.sasl.oauthbearer.jwks.endpoint.url = null
	dest.kafka.sasl.oauthbearer.scope.claim.name = scope
	dest.kafka.sasl.oauthbearer.sub.claim.name = sub
	dest.kafka.sasl.oauthbearer.token.endpoint.url = null
	dest.kafka.security.protocol = PLAINTEXT
	dest.kafka.send.buffer.bytes = 131072
	dest.kafka.ssl.cipher.suites = null
	dest.kafka.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	dest.kafka.ssl.endpoint.identification.algorithm = https
	dest.kafka.ssl.engine.factory.class = null
	dest.kafka.ssl.key.password = null
	dest.kafka.ssl.keymanager.algorithm = SunX509
	dest.kafka.ssl.keystore.certificate.chain = null
	dest.kafka.ssl.keystore.key = null
	dest.kafka.ssl.keystore.location = null
	dest.kafka.ssl.keystore.password = null
	dest.kafka.ssl.keystore.type = JKS
	dest.kafka.ssl.protocol = TLSv1.3
	dest.kafka.ssl.provider = null
	dest.kafka.ssl.secure.random.implementation = null
	dest.kafka.ssl.trustmanager.algorithm = PKIX
	dest.kafka.ssl.truststore.certificates = null
	dest.kafka.ssl.truststore.location = null
	dest.kafka.ssl.truststore.password = null
	dest.kafka.ssl.truststore.type = JKS
	dest.topic.replication.factor = 0
	header.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	key.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	offset.start = connect
	offset.timestamps.commit = true
	offset.topic.commit = true
	offset.topic.commit.batch.period.ms = 60000
	offset.translator.batch.period.ms = 60000
	offset.translator.batch.size = 2147483647
	offset.translator.tasks.max = -1
	offset.translator.tasks.separate = false
	partition.assignment = AAMAAAACABVfX2NvbnN1bWVyX3RpbWVzdGFtcHMAAAAyAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAFAAAABgAAAAcAAAAIAAAACQAAAAoAAAALAAAADAAAAA0AAAAOAAAADwAAABAAAAARAAAAEgAAABMAAAAUAAAAFQAAABYAAAAXAAAAGAAAABkAAAAaAAAAGwAAABwAAAAdAAAAHgAAAB8AAAAgAAAAIQAAACIAAAAjAAAAJAAAACUAAAAmAAAAJwAAACgAAAApAAAAKgAAACsAAAAsAAAALQAAAC4AAAAvAAAAMAAAADEAEXBvc3RncmVzLXVzZXJkYXRhAAAAAQAAAAD/////
	provenance.header.enable = false
	provenance.header.filter.overrides = 
	schema.registry.client.basic.auth.credentials.source = URL
	schema.registry.client.basic.auth.user.info = [hidden]
	schema.registry.max.schemas.per.subject = 1000
	schema.registry.topic = null
	schema.registry.url = null
	schema.subject.translator.class = null
	src.consumer.check.crcs = true
	src.consumer.fetch.max.bytes = 52428800
	src.consumer.fetch.max.wait.ms = 500
	src.consumer.fetch.min.bytes = 1
	src.consumer.interceptor.classes = []
	src.consumer.max.partition.fetch.bytes = 1048576
	src.consumer.max.poll.interval.ms = 300000
	src.consumer.max.poll.records = 500
	src.header.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	src.kafka.bootstrap.servers = [localhost:9092]
	src.kafka.client.id = 
	src.kafka.connections.max.idle.ms = 540000
	src.kafka.metric.reporters = []
	src.kafka.metrics.num.samples = 2
	src.kafka.metrics.sample.window.ms = 30000
	src.kafka.receive.buffer.bytes = 65536
	src.kafka.reconnect.backoff.ms = 50
	src.kafka.request.timeout.ms = 30000
	src.kafka.retry.backoff.ms = 100
	src.kafka.sasl.client.callback.handler.class = null
	src.kafka.sasl.jaas.config = null
	src.kafka.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	src.kafka.sasl.kerberos.min.time.before.relogin = 60000
	src.kafka.sasl.kerberos.service.name = null
	src.kafka.sasl.kerberos.ticket.renew.jitter = 0.05
	src.kafka.sasl.kerberos.ticket.renew.window.factor = 0.8
	src.kafka.sasl.login.callback.handler.class = null
	src.kafka.sasl.login.class = null
	src.kafka.sasl.login.connect.timeout.ms = null
	src.kafka.sasl.login.read.timeout.ms = null
	src.kafka.sasl.login.refresh.buffer.seconds = 300
	src.kafka.sasl.login.refresh.min.period.seconds = 60
	src.kafka.sasl.login.refresh.window.factor = 0.8
	src.kafka.sasl.login.refresh.window.jitter = 0.05
	src.kafka.sasl.login.retry.backoff.max.ms = 10000
	src.kafka.sasl.login.retry.backoff.ms = 100
	src.kafka.sasl.mechanism = GSSAPI
	src.kafka.sasl.oauthbearer.clock.skew.seconds = 30
	src.kafka.sasl.oauthbearer.expected.audience = null
	src.kafka.sasl.oauthbearer.expected.issuer = null
	src.kafka.sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	src.kafka.sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	src.kafka.sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	src.kafka.sasl.oauthbearer.jwks.endpoint.url = null
	src.kafka.sasl.oauthbearer.scope.claim.name = scope
	src.kafka.sasl.oauthbearer.sub.claim.name = sub
	src.kafka.sasl.oauthbearer.token.endpoint.url = null
	src.kafka.security.protocol = PLAINTEXT
	src.kafka.send.buffer.bytes = 131072
	src.kafka.ssl.cipher.suites = null
	src.kafka.ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	src.kafka.ssl.endpoint.identification.algorithm = https
	src.kafka.ssl.engine.factory.class = null
	src.kafka.ssl.key.password = null
	src.kafka.ssl.keymanager.algorithm = SunX509
	src.kafka.ssl.keystore.certificate.chain = null
	src.kafka.ssl.keystore.key = null
	src.kafka.ssl.keystore.location = null
	src.kafka.ssl.keystore.password = null
	src.kafka.ssl.keystore.type = JKS
	src.kafka.ssl.protocol = TLSv1.3
	src.kafka.ssl.provider = null
	src.kafka.ssl.secure.random.implementation = null
	src.kafka.ssl.trustmanager.algorithm = PKIX
	src.kafka.ssl.truststore.certificates = null
	src.kafka.ssl.truststore.location = null
	src.kafka.ssl.truststore.password = null
	src.kafka.ssl.truststore.type = JKS
	src.key.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	src.value.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
	task.id = replicator-localhost-0
	topic.auto.create = true
	topic.blacklist = []
	topic.config.sync = true
	topic.config.sync.interval.ms = 120000
	topic.create.backoff.ms = 120000
	topic.poll.interval.ms = 120000
	topic.preserve.partitions = true
	topic.regex = null
	topic.rename.format = ${topic}-replica
	topic.timestamp.type = CreateTime
	topic.whitelist = [postgres-userdata]
	value.converter = class io.confluent.connect.replicator.util.ByteArrayConverter
 (io.confluent.connect.replicator.ReplicatorSourceTaskConfig:370)
[2024-02-05 13:50:42,676] INFO [replicator-localhost|task-0] [Producer clientId=connector-producer-replicator-localhost-0] Cluster ID: lkc-qpjpkm (org.apache.kafka.clients.Metadata:287)
[2024-02-05 13:50:44,341] INFO [replicator-cloud|worker] App info kafka.admin.client for adminclient-10 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:50:44,346] INFO [replicator-cloud|worker] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:50:44,346] INFO [replicator-cloud|worker] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:50:44,346] INFO [replicator-cloud|worker] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:50:44,347] INFO [replicator-cloud|worker] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = latest
	bootstrap.servers = [pkc-4r087.us-west2.gcp.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-null-license-5
	client.rack = 
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = null-license
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class io.confluent.license.LicenseStore$LicenseKeySerde
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.license.LicenseStore$LicenseMessageSerde
 (org.apache.kafka.clients.consumer.ConsumerConfig:370)
[2024-02-05 13:50:44,370] INFO [replicator-cloud|worker] These configurations '[replication.factor, enable.idempotence, producer.enable.idempotence]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:379)
[2024-02-05 13:50:44,371] INFO [replicator-cloud|worker] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:50:44,371] INFO [replicator-cloud|worker] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:50:44,371] INFO [replicator-cloud|worker] Kafka startTimeMs: 1707121244371 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:50:46,479] INFO [replicator-cloud|worker] [Consumer clientId=consumer-null-license-5, groupId=null-license] Cluster ID: lkc-qpjpkm (org.apache.kafka.clients.Metadata:287)
[2024-02-05 13:50:46,481] INFO [replicator-cloud|worker] [Consumer clientId=consumer-null-license-5, groupId=null-license] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1025)
[2024-02-05 13:50:46,481] INFO [replicator-cloud|worker] [Consumer clientId=consumer-null-license-5, groupId=null-license] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1072)
[2024-02-05 13:50:46,482] INFO [replicator-cloud|worker] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:50:46,483] INFO [replicator-cloud|worker] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:50:46,483] INFO [replicator-cloud|worker] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:50:46,491] INFO [replicator-cloud|worker] App info kafka.consumer for consumer-null-license-5 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:50:46,493] INFO [replicator-cloud|worker] ProducerConfig values: 
	acks = -1
	auto.include.jmx.reporter = true
	batch.size = 16384
	bootstrap.servers = [pkc-4r087.us-west2.gcp.confluent.cloud:9092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-5
	compression.type = none
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class io.confluent.license.LicenseStore$LicenseKeySerde
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.adaptive.partitioning.enable = true
	partitioner.availability.timeout.ms = 0
	partitioner.class = null
	partitioner.ignore.keys = false
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retries = 2147483647
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class io.confluent.license.LicenseStore$LicenseMessageSerde
 (org.apache.kafka.clients.producer.ProducerConfig:370)
[2024-02-05 13:50:46,503] INFO [replicator-cloud|worker] These configurations '[replication.factor, group.id, producer.enable.idempotence]' were supplied but are not used yet. (org.apache.kafka.clients.producer.ProducerConfig:379)
[2024-02-05 13:50:46,504] INFO [replicator-cloud|worker] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:50:46,504] INFO [replicator-cloud|worker] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:50:46,504] INFO [replicator-cloud|worker] Kafka startTimeMs: 1707121246504 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:50:46,506] INFO [replicator-cloud|worker] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = earliest
	bootstrap.servers = [pkc-4r087.us-west2.gcp.confluent.cloud:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-null-license-6
	client.rack = 
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = null-license
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class io.confluent.license.LicenseStore$LicenseKeySerde
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.license.LicenseStore$LicenseMessageSerde
 (org.apache.kafka.clients.consumer.ConsumerConfig:370)
[2024-02-05 13:50:46,513] INFO [replicator-cloud|worker] These configurations '[replication.factor, enable.idempotence, producer.enable.idempotence]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:379)
[2024-02-05 13:50:46,513] INFO [replicator-cloud|worker] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:50:46,513] INFO [replicator-cloud|worker] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:50:46,513] INFO [replicator-cloud|worker] Kafka startTimeMs: 1707121246513 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:50:48,184] INFO [replicator-cloud|worker] [Consumer clientId=consumer-null-license-6, groupId=null-license] Cluster ID: lkc-qpjpkm (org.apache.kafka.clients.Metadata:287)
[2024-02-05 13:50:48,186] INFO [replicator-cloud|worker] [Consumer clientId=consumer-null-license-6, groupId=null-license] Assigned to partition(s): _confluent-command-0 (org.apache.kafka.clients.consumer.KafkaConsumer:1135)
[2024-02-05 13:50:48,187] INFO [replicator-cloud|worker] [Consumer clientId=consumer-null-license-6, groupId=null-license] Seeking to earliest offset of partition _confluent-command-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:646)
[2024-02-05 13:50:48,229] INFO [replicator-cloud|worker] [Producer clientId=producer-5] Cluster ID: lkc-qpjpkm (org.apache.kafka.clients.Metadata:287)
[2024-02-05 13:50:54,911] INFO [replicator-cloud|worker] Finished reading KafkaBasedLog for topic _confluent-command (org.apache.kafka.connect.util.KafkaBasedLog:337)
[2024-02-05 13:50:54,911] INFO [replicator-cloud|worker] Started KafkaBasedLog for topic _confluent-command (org.apache.kafka.connect.util.KafkaBasedLog:339)
[2024-02-05 13:50:54,912] INFO [replicator-cloud|worker] Started License Store (io.confluent.license.LicenseStore:252)
[2024-02-05 13:50:54,912] INFO [replicator-cloud|worker] Validating Confluent Replicator License... (io.confluent.connect.replicator.ReplicatorSourceConnector:214)
[2024-02-05 13:50:56,001] INFO [replicator-cloud|worker] AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [pkc-4r087.us-west2.gcp.confluent.cloud:9092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	confluent.lkc.id = null
	confluent.metrics.reporter.bootstrap.servers = kafka-0:9071
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	confluent.use.controller.listener = false
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	host.resolver.class = class org.apache.kafka.clients.DefaultHostResolver
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retries = 2147483647
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:370)
[2024-02-05 13:50:56,006] INFO [replicator-cloud|worker] These configurations '[replication.factor, enable.idempotence, group.id, producer.enable.idempotence]' were supplied but are not used yet. (org.apache.kafka.clients.admin.AdminClientConfig:379)
[2024-02-05 13:50:56,006] INFO [replicator-cloud|worker] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:50:56,007] INFO [replicator-cloud|worker] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:50:56,007] INFO [replicator-cloud|worker] Kafka startTimeMs: 1707121256006 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:51:01,964] INFO [replicator-cloud|worker] App info kafka.admin.client for adminclient-18 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:51:01,968] INFO [replicator-cloud|worker] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:51:01,969] INFO [replicator-cloud|worker] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:51:01,969] INFO [replicator-cloud|worker] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:51:01,970] INFO [replicator-cloud|worker] Trial license for Confluent Enterprise expires in 29 days on 2024-03-06. (io.confluent.license.LicenseManager:559)
[2024-02-05 13:51:01,972] INFO [replicator-cloud|worker] AdminClientConfig values: 
	auto.include.jmx.reporter = true
	bootstrap.servers = [{{ localhost:9092 }}]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	confluent.lkc.id = null
	confluent.metrics.reporter.bootstrap.servers = kafka-0:9071
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	confluent.use.controller.listener = false
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	host.resolver.class = class org.apache.kafka.clients.DefaultHostResolver
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 20000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:370)
[2024-02-05 13:51:01,973] ERROR [replicator-cloud|worker] WorkerConnector{id=replicator-cloud} Error while starting connector (org.apache.kafka.connect.runtime.WorkerConnector:201)
org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:694)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:621)
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:144)
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:49)
	at io.confluent.connect.replicator.NewTopicMonitorThread.<init>(NewTopicMonitorThread.java:82)
	at io.confluent.connect.replicator.ReplicatorSourceConnector.monitorThread(ReplicatorSourceConnector.java:188)
	at io.confluent.connect.replicator.ReplicatorSourceConnector.start(ReplicatorSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:193)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:218)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:377)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:358)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:145)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:123)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:181)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.apache.kafka.common.config.ConfigException: Invalid url in bootstrap.servers: {{ localhost:9092 }}
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:76)
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:65)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:648)
	... 18 more
[2024-02-05 13:51:01,977] ERROR [replicator-cloud|worker] [Worker clientId=connect-1, groupId=connect-cluster] Failed to start connector 'replicator-cloud' (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1928)
org.apache.kafka.connect.errors.ConnectException: Failed to start connector: replicator-cloud
	at org.apache.kafka.connect.runtime.distributed.DistributedHerder.lambda$startConnector$36(DistributedHerder.java:1899)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:361)
	at org.apache.kafka.connect.runtime.WorkerConnector.doRun(WorkerConnector.java:145)
	at org.apache.kafka.connect.runtime.WorkerConnector.run(WorkerConnector.java:123)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:181)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
Caused by: org.apache.kafka.connect.errors.ConnectException: Failed to transition connector replicator-cloud to state STARTED
	... 9 more
Caused by: org.apache.kafka.common.KafkaException: Failed to create new KafkaAdminClient
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:694)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:621)
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:144)
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:49)
	at io.confluent.connect.replicator.NewTopicMonitorThread.<init>(NewTopicMonitorThread.java:82)
	at io.confluent.connect.replicator.ReplicatorSourceConnector.monitorThread(ReplicatorSourceConnector.java:188)
	at io.confluent.connect.replicator.ReplicatorSourceConnector.start(ReplicatorSourceConnector.java:95)
	at org.apache.kafka.connect.runtime.WorkerConnector.doStart(WorkerConnector.java:193)
	at org.apache.kafka.connect.runtime.WorkerConnector.start(WorkerConnector.java:218)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:377)
	at org.apache.kafka.connect.runtime.WorkerConnector.doTransitionTo(WorkerConnector.java:358)
	... 8 more
Caused by: org.apache.kafka.common.config.ConfigException: Invalid url in bootstrap.servers: {{ localhost:9092 }}
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:76)
	at org.apache.kafka.clients.ClientUtils.parseAndValidateAddresses(ClientUtils.java:65)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:648)
	... 18 more
[2024-02-05 13:51:24,936] ERROR Uncaught exception in REST call to /connectors (org.apache.kafka.connect.runtime.rest.errors.ConnectExceptionMapper:64)
org.apache.kafka.connect.errors.ConnectException: Failed to find any class that implements Connector and which name matches io.confluent.connect.jdbc.JdbcSourceConnector, available connectors are: PluginDesc{klass=class io.confluent.connect.replicator.ReplicatorSourceConnector, name='io.confluent.connect.replicator.ReplicatorSourceConnector', version='7.5.2', encodedVersion=7.5.2, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorCheckpointConnector, name='org.apache.kafka.connect.mirror.MirrorCheckpointConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorHeartbeatConnector, name='org.apache.kafka.connect.mirror.MirrorHeartbeatConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.mirror.MirrorSourceConnector, name='org.apache.kafka.connect.mirror.MirrorSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSinkConnector, name='org.apache.kafka.connect.tools.MockSinkConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=sink, typeName='sink', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.MockSourceConnector, name='org.apache.kafka.connect.tools.MockSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.SchemaSourceConnector, name='org.apache.kafka.connect.tools.SchemaSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSinkConnector, name='org.apache.kafka.connect.tools.VerifiableSinkConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=sink, typeName='sink', location='file:/usr/share/java/kafka-connect-replicator/'}, PluginDesc{klass=class org.apache.kafka.connect.tools.VerifiableSourceConnector, name='org.apache.kafka.connect.tools.VerifiableSourceConnector', version='7.5.3-ce', encodedVersion=7.5.3-ce, type=source, typeName='source', location='file:/usr/share/java/kafka-connect-replicator/'}
	at org.apache.kafka.connect.runtime.isolation.Plugins.connectorClass(Plugins.java:253)
	at org.apache.kafka.connect.runtime.isolation.Plugins.newConnector(Plugins.java:224)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$getConnector$10(AbstractHerder.java:801)
	at java.base/java.util.concurrent.ConcurrentHashMap.computeIfAbsent(ConcurrentHashMap.java:1705)
	at org.apache.kafka.connect.runtime.AbstractHerder.getConnector(AbstractHerder.java:801)
	at org.apache.kafka.connect.runtime.AbstractHerder.validateConnectorConfig(AbstractHerder.java:551)
	at org.apache.kafka.connect.runtime.AbstractHerder.lambda$validateConnectorConfig$6(AbstractHerder.java:470)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-02-05 13:51:24,943] INFO 127.0.0.1 - - [05/Feb/2024:08:21:24 +0000] "POST /connectors HTTP/1.1" 500 2610 "-" "curl/7.68.0" 24 (org.apache.kafka.connect.runtime.rest.RestServer:62)
[2024-02-05 13:51:45,963] INFO [replicator-localhost|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.include.jmx.reporter = true
	auto.offset.reset = none
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = replicator-localhost-0
	client.rack = 
	confluent.lkc.id = null
	confluent.proxy.protocol.client.address = null
	confluent.proxy.protocol.client.mode = PROXY
	confluent.proxy.protocol.client.port = null
	confluent.proxy.protocol.client.version = NONE
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = replicator-cloud
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:370)
[2024-02-05 13:51:45,977] INFO [replicator-localhost|task-0] Kafka version: 7.5.3-ce (org.apache.kafka.common.utils.AppInfoParser:119)
[2024-02-05 13:51:45,978] INFO [replicator-localhost|task-0] Kafka commitId: 0839c07804ceca10 (org.apache.kafka.common.utils.AppInfoParser:120)
[2024-02-05 13:51:45,978] INFO [replicator-localhost|task-0] Kafka startTimeMs: 1707121305977 (org.apache.kafka.common.utils.AppInfoParser:121)
[2024-02-05 13:51:45,978] WARN [replicator-localhost|task-0] Error registering AppInfo mbean (org.apache.kafka.common.utils.AppInfoParser:68)
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=replicator-localhost-0
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:828)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:671)
	at io.confluent.connect.replicator.offsets.ConsumerOffsetsTranslator.buildDestConsumer(ConsumerOffsetsTranslator.java:322)
	at io.confluent.connect.replicator.offsets.ConsumerOffsetsTranslator.commitOffsets(ConsumerOffsetsTranslator.java:264)
	at io.confluent.connect.replicator.offsets.ConsumerOffsetsTranslator.translateOffsets(ConsumerOffsetsTranslator.java:232)
	at io.confluent.connect.replicator.offsets.ConsumerOffsetsTranslator.translateCollectedRecords(ConsumerOffsetsTranslator.java:186)
	at io.confluent.connect.replicator.ReplicatorSourceTask.translateCollectedRecords(ReplicatorSourceTask.java:652)
	at io.confluent.connect.replicator.ReplicatorSourceTask.poll(ReplicatorSourceTask.java:604)
	at org.apache.kafka.connect.runtime.AbstractWorkerSourceTask.poll(AbstractWorkerSourceTask.java:488)
	at org.apache.kafka.connect.runtime.AbstractWorkerSourceTask.execute(AbstractWorkerSourceTask.java:360)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:229)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:284)
	at org.apache.kafka.connect.runtime.AbstractWorkerSourceTask.run(AbstractWorkerSourceTask.java:80)
	at org.apache.kafka.connect.runtime.isolation.Plugins.lambda$withClassLoader$1(Plugins.java:181)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
[2024-02-05 13:51:46,007] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-cloud] Cluster ID: xq-PEpqTSoutAwe9O2TUvQ (org.apache.kafka.clients.Metadata:287)
[2024-02-05 13:51:46,018] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-cloud] Discovered group coordinator sumo-HP-EliteBook-840-G4:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:906)
[2024-02-05 13:51:46,028] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-cloud] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1025)
[2024-02-05 13:51:46,028] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-cloud] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1072)
[2024-02-05 13:51:46,028] INFO [replicator-localhost|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:51:46,028] INFO [replicator-localhost|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:51:46,029] INFO [replicator-localhost|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:51:46,031] INFO [replicator-localhost|task-0] App info kafka.consumer for replicator-localhost-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:52:18,366] INFO Kafka Connect stopping (org.apache.kafka.connect.runtime.Connect:67)
[2024-02-05 13:52:18,370] INFO Stopping REST server (org.apache.kafka.connect.runtime.rest.RestServer:369)
[2024-02-05 13:52:18,379] INFO Stopped http_8083@4de5ceac{HTTP/1.1, (http/1.1)}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:383)
[2024-02-05 13:52:18,379] INFO node0 Stopped scavenging (org.eclipse.jetty.server.session:149)
[2024-02-05 13:52:18,393] INFO REST server stopped (org.apache.kafka.connect.runtime.rest.RestServer:386)
[2024-02-05 13:52:18,393] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder stopping (org.apache.kafka.connect.runtime.distributed.DistributedHerder:804)
[2024-02-05 13:52:18,394] INFO [Worker clientId=connect-1, groupId=connect-cluster] Stopping connectors and tasks that are still assigned to this worker. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:767)
[2024-02-05 13:52:18,394] INFO [replicator-localhost|worker] Stopping connector replicator-localhost (org.apache.kafka.connect.runtime.Worker:492)
[2024-02-05 13:52:18,395] INFO [replicator-localhost|worker] Scheduled shutdown for WorkerConnector{id=replicator-localhost} (org.apache.kafka.connect.runtime.WorkerConnector:268)
[2024-02-05 13:52:18,395] INFO [replicator-localhost|worker] Shutting down replicator connector replicator-localhost (io.confluent.connect.replicator.ReplicatorSourceConnector:151)
[2024-02-05 13:52:18,395] INFO [replicator-cloud|worker] Stopping connector replicator-cloud (org.apache.kafka.connect.runtime.Worker:492)
[2024-02-05 13:52:18,395] INFO [replicator-localhost|worker] Closing License Store (io.confluent.license.LicenseStore:258)
[2024-02-05 13:52:18,396] INFO [replicator-localhost|worker] Stopping KafkaBasedLog for topic _confluent-command (org.apache.kafka.connect.util.KafkaBasedLog:343)
[2024-02-05 13:52:18,395] INFO [replicator-cloud|worker] Scheduled shutdown for WorkerConnector{id=replicator-cloud} (org.apache.kafka.connect.runtime.WorkerConnector:268)
[2024-02-05 13:52:18,396] INFO [replicator-localhost|worker] [Producer clientId=producer-4] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1311)
[2024-02-05 13:52:18,398] INFO [replicator-cloud|worker] Completed shutdown for WorkerConnector{id=replicator-cloud} (org.apache.kafka.connect.runtime.WorkerConnector:288)
[2024-02-05 13:52:18,402] INFO [replicator-localhost|worker] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:52:18,403] INFO [replicator-localhost|worker] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:52:18,404] INFO [replicator-localhost|worker] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:52:18,404] INFO [replicator-localhost|worker] App info kafka.producer for producer-4 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:52:18,405] INFO [replicator-localhost|worker] [Consumer clientId=consumer-null-license-4, groupId=null-license] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1025)
[2024-02-05 13:52:18,406] INFO [replicator-localhost|worker] [Consumer clientId=consumer-null-license-4, groupId=null-license] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1072)
[2024-02-05 13:52:18,742] INFO [replicator-localhost|worker] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:52:18,742] INFO [replicator-localhost|worker] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:52:18,742] INFO [replicator-localhost|worker] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:52:18,743] INFO [replicator-localhost|worker] App info kafka.consumer for consumer-null-license-4 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:52:18,744] INFO [replicator-localhost|worker] Stopped KafkaBasedLog for topic _confluent-command (org.apache.kafka.connect.util.KafkaBasedLog:375)
[2024-02-05 13:52:18,744] INFO [replicator-localhost|worker] Closed License Store (io.confluent.license.LicenseStore:260)
[2024-02-05 13:52:18,745] INFO [replicator-localhost|worker] App info kafka.admin.client for adminclient-17 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:52:18,746] INFO [replicator-localhost|worker] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:52:18,746] INFO [replicator-localhost|worker] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:52:18,746] INFO [replicator-localhost|worker] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:52:18,746] INFO [replicator-localhost|worker] Completed shutdown for WorkerConnector{id=replicator-localhost} (org.apache.kafka.connect.runtime.WorkerConnector:288)
[2024-02-05 13:52:18,746] INFO [replicator-localhost|task-0] Stopping task replicator-localhost-0 (org.apache.kafka.connect.runtime.Worker:1288)
[2024-02-05 13:52:20,968] INFO [replicator-localhost|task-0] Closing kafka replicator task replicator-localhost-0 (io.confluent.connect.replicator.ReplicatorSourceTask:1259)
[2024-02-05 13:52:20,968] INFO [replicator-localhost|task-0] App info kafka.admin.client for adminclient-13 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:52:20,969] INFO [replicator-localhost|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:52:20,969] INFO [replicator-localhost|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:52:20,969] INFO [replicator-localhost|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:52:20,970] INFO [replicator-localhost|task-0] App info kafka.admin.client for adminclient-12 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:52:20,971] INFO [replicator-localhost|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:52:20,971] INFO [replicator-localhost|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:52:20,971] INFO [replicator-localhost|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:52:20,971] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1025)
[2024-02-05 13:52:20,971] INFO [replicator-localhost|task-0] [Consumer clientId=replicator-localhost-0, groupId=replicator-localhost] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1072)
[2024-02-05 13:52:20,973] INFO [replicator-localhost|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:52:20,973] INFO [replicator-localhost|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:52:20,973] INFO [replicator-localhost|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:52:20,975] INFO [replicator-localhost|task-0] App info kafka.consumer for replicator-localhost-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:52:20,975] INFO [replicator-localhost|task-0] [Producer clientId=producer-3] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1311)
[2024-02-05 13:52:20,976] INFO [replicator-localhost|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:52:20,977] INFO [replicator-localhost|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:52:20,977] INFO [replicator-localhost|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:52:20,977] INFO [replicator-localhost|task-0] App info kafka.producer for producer-3 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:52:20,977] INFO [replicator-localhost|task-0] Shutting down metrics recording for task replicator-localhost-0 (io.confluent.connect.replicator.ReplicatorSourceTask:1281)
[2024-02-05 13:52:20,986] INFO [replicator-localhost|task-0] Unregistering Confluent Replicator metrics with JMX for task 'replicator-localhost-0' (io.confluent.connect.replicator.metrics.ConfluentReplicatorMetrics:86)
[2024-02-05 13:52:20,986] INFO [replicator-localhost|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:52:20,986] INFO [replicator-localhost|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:52:20,986] INFO [replicator-localhost|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:52:20,986] INFO [replicator-localhost|task-0] [Consumer clientId=confluent-replicator-end-offsets-consumer-client, groupId=confluent-replicator-end-offsets-consumer-group] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1025)
[2024-02-05 13:52:20,987] INFO [replicator-localhost|task-0] [Consumer clientId=confluent-replicator-end-offsets-consumer-client, groupId=confluent-replicator-end-offsets-consumer-group] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1072)
[2024-02-05 13:52:20,987] INFO [replicator-localhost|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:52:20,987] INFO [replicator-localhost|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:52:20,987] INFO [replicator-localhost|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:52:20,990] INFO [replicator-localhost|task-0] App info kafka.consumer for confluent-replicator-end-offsets-consumer-client unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:52:20,990] INFO [replicator-localhost|task-0] [Producer clientId=connector-producer-replicator-localhost-0] Closing the Kafka producer with timeoutMillis = 30000 ms. (org.apache.kafka.clients.producer.KafkaProducer:1311)
[2024-02-05 13:52:20,992] INFO [replicator-localhost|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:52:20,992] INFO [replicator-localhost|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:52:20,992] INFO [replicator-localhost|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:52:20,992] INFO [replicator-localhost|task-0] App info kafka.producer for connector-producer-replicator-localhost-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:52:21,000] INFO [Worker clientId=connect-1, groupId=connect-cluster] Member connect-1-5626c631-09b4-4bc6-b13c-f89c6adf07d0 sending LeaveGroup request to coordinator b6-pkc-4r087.us-west2.gcp.confluent.cloud:9092 (id: 2147483641 rack: null) due to the consumer is being closed (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1133)
[2024-02-05 13:52:21,001] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1025)
[2024-02-05 13:52:21,001] WARN [Worker clientId=connect-1, groupId=connect-cluster] Close timed out with 1 pending requests to coordinator, terminating client connections (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:1110)
[2024-02-05 13:52:21,001] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:52:21,002] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:52:21,002] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:52:21,004] INFO App info kafka.connect for connect-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:52:21,004] INFO Stopping KafkaBasedLog for topic connect-statuses (org.apache.kafka.connect.util.KafkaBasedLog:343)
[2024-02-05 13:52:21,005] INFO [Producer clientId=connect-cluster--statuses] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1311)
[2024-02-05 13:52:21,261] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:52:21,261] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:52:21,262] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:52:21,262] INFO App info kafka.producer for connect-cluster--statuses unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:52:21,262] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1025)
[2024-02-05 13:52:21,262] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1072)
[2024-02-05 13:52:21,263] INFO [Consumer clientId=connect-cluster--statuses, groupId=connect-cluster] Node 1 sent an invalid full fetch response with extraIds=(ESugP4KEQ3mDImucPy3dkQ), response=() (org.apache.kafka.clients.FetchSessionHandler:555)
[2024-02-05 13:52:21,716] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:52:21,716] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:52:21,717] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:52:21,719] INFO App info kafka.consumer for connect-cluster--statuses unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:52:21,719] INFO Stopped KafkaBasedLog for topic connect-statuses (org.apache.kafka.connect.util.KafkaBasedLog:375)
[2024-02-05 13:52:21,719] INFO Closing KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:399)
[2024-02-05 13:52:21,720] INFO Stopping KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:343)
[2024-02-05 13:52:21,720] INFO [Producer clientId=connect-cluster--configs] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1311)
[2024-02-05 13:52:21,723] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:52:21,723] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:52:21,723] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:52:21,723] INFO App info kafka.producer for connect-cluster--configs unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:52:21,723] INFO [Consumer clientId=connect-cluster--configs, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1025)
[2024-02-05 13:52:21,723] INFO [Consumer clientId=connect-cluster--configs, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1072)
[2024-02-05 13:52:22,883] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:52:22,883] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:52:22,884] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:52:22,886] INFO App info kafka.consumer for connect-cluster--configs unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:52:22,886] INFO Stopped KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:375)
[2024-02-05 13:52:22,886] INFO Closed KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:412)
[2024-02-05 13:52:22,886] INFO Worker stopping (org.apache.kafka.connect.runtime.Worker:289)
[2024-02-05 13:52:22,887] INFO Stopping KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:295)
[2024-02-05 13:52:22,888] INFO Stopping KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:343)
[2024-02-05 13:52:22,888] INFO [Producer clientId=connect-cluster--offsets] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms. (org.apache.kafka.clients.producer.KafkaProducer:1311)
[2024-02-05 13:52:22,900] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:52:22,900] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:52:22,900] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:52:22,900] INFO App info kafka.producer for connect-cluster--offsets unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:52:22,900] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1025)
[2024-02-05 13:52:22,901] INFO [Consumer clientId=connect-cluster--offsets, groupId=connect-cluster] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1072)
[2024-02-05 13:52:24,821] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:52:24,821] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:52:24,822] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:52:24,830] INFO App info kafka.consumer for connect-cluster--offsets unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:52:24,831] INFO Stopped KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:375)
[2024-02-05 13:52:24,831] INFO Stopped KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:303)
[2024-02-05 13:52:24,831] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:52:24,831] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:52:24,832] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:52:24,832] INFO App info kafka.connect for 127.0.1.1:8083 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:52:24,832] INFO Worker stopped (org.apache.kafka.connect.runtime.Worker:312)
[2024-02-05 13:52:24,840] INFO App info kafka.admin.client for connect-cluster--shared-admin unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2024-02-05 13:52:24,847] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:710)
[2024-02-05 13:52:24,847] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:714)
[2024-02-05 13:52:24,847] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:720)
[2024-02-05 13:52:24,847] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:374)
[2024-02-05 13:52:24,849] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder stopped (org.apache.kafka.connect.runtime.distributed.DistributedHerder:824)
[2024-02-05 13:52:24,849] INFO Kafka Connect stopped (org.apache.kafka.connect.runtime.Connect:72)
